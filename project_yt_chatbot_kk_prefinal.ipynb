{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install pytube\\n!pip install openai-whisper\\n!pip install langchain\\n!pip install openai\\n!pip install python-dotenv '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install pytube\n",
    "!pip install openai-whisper\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install python-dotenv \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install -U langchain-community\\n!pip install pinecone-client\\n!pip install --upgrade pytube\\n!pip install yt-dlp\\n!pip install imageio[ffmpeg] '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install -U langchain-community\n",
    "!pip install pinecone-client\n",
    "!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "!pip install imageio[ffmpeg] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, torch\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load Environment Variable\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the environment variable directly in the script\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Langsmith (make sure it's installed first)\n",
    "import langsmith  # Importing Langsmith's library\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"prj-yt-chatbot-qa\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter LANGCHAIN_API_KEY\")        # Authenticate with Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/8: https://www.youtube.com/watch?v=-RIfno4Sp0g\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=-RIfno4Sp0g\n",
      "[youtube] -RIfno4Sp0g: Downloading webpage\n",
      "[youtube] -RIfno4Sp0g: Downloading ios player API JSON\n",
      "[youtube] -RIfno4Sp0g: Downloading mweb player API JSON\n",
      "[youtube] -RIfno4Sp0g: Downloading player 81ef9024\n",
      "[youtube] -RIfno4Sp0g: Downloading m3u8 information\n",
      "[info] -RIfno4Sp0g: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of   48.70MiB in 00:00:00 at 51.13MiB/s    \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 57.6MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed transcription for video 1\n",
      "Processing video 2/8: https://www.youtube.com/watch?v=3SCOVB1KDFc\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=3SCOVB1KDFc\n",
      "[youtube] 3SCOVB1KDFc: Downloading webpage\n",
      "[youtube] 3SCOVB1KDFc: Downloading ios player API JSON\n",
      "[youtube] 3SCOVB1KDFc: Downloading mweb player API JSON\n",
      "[youtube] 3SCOVB1KDFc: Downloading m3u8 information\n",
      "[info] 3SCOVB1KDFc: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   54.16MiB in 00:00:02 at 18.42MiB/s    \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n",
      "Completed transcription for video 2\n",
      "Processing video 3/8: https://www.youtube.com/watch?v=qMqP2IwhSnA\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=qMqP2IwhSnA\n",
      "[youtube] qMqP2IwhSnA: Downloading webpage\n",
      "[youtube] qMqP2IwhSnA: Downloading ios player API JSON\n",
      "[youtube] qMqP2IwhSnA: Downloading mweb player API JSON\n",
      "[youtube] qMqP2IwhSnA: Downloading m3u8 information\n",
      "[info] qMqP2IwhSnA: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_2\n",
      "[download] 100% of   60.30MiB in 00:00:03 at 19.41MiB/s    \n",
      "[ExtractAudio] Destination: audio_2.mp3\n",
      "Deleting original file audio_2 (pass -k to keep)\n",
      "Completed transcription for video 3\n",
      "Processing video 4/8: https://www.youtube.com/watch?v=5u9jOA3LCdU\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=5u9jOA3LCdU\n",
      "[youtube] 5u9jOA3LCdU: Downloading webpage\n",
      "[youtube] 5u9jOA3LCdU: Downloading ios player API JSON\n",
      "[youtube] 5u9jOA3LCdU: Downloading mweb player API JSON\n",
      "[youtube] 5u9jOA3LCdU: Downloading m3u8 information\n",
      "[info] 5u9jOA3LCdU: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_3\n",
      "[download] 100% of   65.24MiB in 00:00:02 at 28.32MiB/s  \n",
      "[ExtractAudio] Destination: audio_3.mp3\n",
      "Deleting original file audio_3 (pass -k to keep)\n",
      "Completed transcription for video 4\n",
      "Processing video 5/8: https://www.youtube.com/watch?v=xeYEGePVaks\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xeYEGePVaks\n",
      "[youtube] xeYEGePVaks: Downloading webpage\n",
      "[youtube] xeYEGePVaks: Downloading ios player API JSON\n",
      "[youtube] xeYEGePVaks: Downloading mweb player API JSON\n",
      "[youtube] xeYEGePVaks: Downloading m3u8 information\n",
      "[info] xeYEGePVaks: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_4\n",
      "[download] 100% of   60.71MiB in 00:00:02 at 24.18MiB/s    \n",
      "[ExtractAudio] Destination: audio_4.mp3\n",
      "Deleting original file audio_4 (pass -k to keep)\n",
      "Completed transcription for video 5\n",
      "Processing video 6/8: https://www.youtube.com/watch?v=EGGUg054ciI\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=EGGUg054ciI\n",
      "[youtube] EGGUg054ciI: Downloading webpage\n",
      "[youtube] EGGUg054ciI: Downloading ios player API JSON\n",
      "[youtube] EGGUg054ciI: Downloading mweb player API JSON\n",
      "[youtube] EGGUg054ciI: Downloading m3u8 information\n",
      "[info] EGGUg054ciI: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_5\n",
      "[download] 100% of   63.79MiB in 00:00:02 at 25.76MiB/s    \n",
      "[ExtractAudio] Destination: audio_5.mp3\n",
      "Deleting original file audio_5 (pass -k to keep)\n",
      "Completed transcription for video 6\n",
      "Processing video 7/8: https://www.youtube.com/watch?v=3f1iv7nsIsA\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=3f1iv7nsIsA\n",
      "[youtube] 3f1iv7nsIsA: Downloading webpage\n",
      "[youtube] 3f1iv7nsIsA: Downloading ios player API JSON\n",
      "[youtube] 3f1iv7nsIsA: Downloading mweb player API JSON\n",
      "[youtube] 3f1iv7nsIsA: Downloading m3u8 information\n",
      "[info] 3f1iv7nsIsA: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_6\n",
      "[download] 100% of   51.37MiB in 00:00:07 at 7.01MiB/s     \n",
      "[ExtractAudio] Destination: audio_6.mp3\n",
      "Deleting original file audio_6 (pass -k to keep)\n",
      "Completed transcription for video 7\n",
      "Processing video 8/8: https://www.youtube.com/watch?v=WPSaiShNutU\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=WPSaiShNutU\n",
      "[youtube] WPSaiShNutU: Downloading webpage\n",
      "[youtube] WPSaiShNutU: Downloading ios player API JSON\n",
      "[youtube] WPSaiShNutU: Downloading mweb player API JSON\n",
      "[youtube] WPSaiShNutU: Downloading m3u8 information\n",
      "[info] WPSaiShNutU: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_7\n",
      "[download] 100% of   42.03MiB in 00:00:01 at 23.17MiB/s  \n",
      "[ExtractAudio] Destination: audio_7.mp3\n",
      "Deleting original file audio_7 (pass -k to keep)\n",
      "Completed transcription for video 8\n",
      "Individual transcription files are ready in the transcriptions folder.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Load VIDEO, Download Audio, Transcribe into different text files!!!\n",
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Default configurations\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}\"\n",
    "WHISPER_MODEL = \"base\"\n",
    "TRANSCRIPT_DIR = \"transcriptions\"\n",
    "\n",
    "# Ensure directory exists for transcriptions\n",
    "os.makedirs(TRANSCRIPT_DIR, exist_ok=True)\n",
    "\n",
    "# Load YouTube links from the file\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        return [link.strip() for link in file.readlines() if link.strip()]\n",
    "\n",
    "# Download audio from YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],\n",
    "        'outtmpl': f\"{output_name}\",\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return f\"{output_name}.mp3\"\n",
    "\n",
    "# Transcribe audio using Whisper\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Process each video and save individual transcriptions\n",
    "def transcribe_all_videos():\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        \n",
    "        # Transcribe the audio and save each transcription to a separate file\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        transcript_file = os.path.join(TRANSCRIPT_DIR, f\"transcription_{i+1}.txt\")\n",
    "        \n",
    "        with open(transcript_file, 'w') as f:\n",
    "            f.write(transcription)\n",
    "        \n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "\n",
    "# Execute transcription process only, without consolidation\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe_all_videos()\n",
    "    print(\"Individual transcription files are ready in the transcriptions folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Define Pinecone as Vector DB & Define Index\n",
    "\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely fetch Pinecone API keys                    \n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ[\"PINECONE_API_KEY\"])\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index statistics: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create INDEX \n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone client with the updated API\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "#spec = ServerlessSpec(cloud=\"aws\", region=\"us-west-1\")          # Specify Pinecone environment\n",
    "index_name = \"transcription-accnt-earn-index-no-consol\"             # Create New Index\n",
    "\n",
    "# Check if the index exists; create if it doesn’t\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI embedding dimension\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for the index to be ready\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        print(\"Waiting for index to be ready...\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for upsertion\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "print(\"Index statistics:\", index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete for transcription_1.txt.\n",
      "Vectorization complete for transcription_2.txt.\n",
      "Vectorization complete for transcription_3.txt.\n",
      "Vectorization complete for transcription_4.txt.\n",
      "Vectorization complete for transcription_5.txt.\n",
      "Vectorization complete for transcription_6.txt.\n",
      "Vectorization complete for transcription_7.txt.\n",
      "Vectorization complete for transcription_8.txt.\n",
      "All transcription files have been vectorized. Ready for storage in Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Vectorize and Embed each Transcription file\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Function to split and vectorize text from each transcription file\n",
    "def vectorize_individual_transcriptions(transcription_dir=\"transcriptions\"):\n",
    "    # Initialize list to hold vectorized segments for all files\n",
    "    all_vectorized_segments = []\n",
    "    \n",
    "    # Iterate through each transcription file in the directory\n",
    "    for filename in sorted(os.listdir(transcription_dir)):\n",
    "        file_path = os.path.join(transcription_dir, filename)\n",
    "        \n",
    "        # Skip directories and hidden files\n",
    "        if not os.path.isfile(file_path) or filename.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        # Read transcription text\n",
    "        with open(file_path, 'r') as f:\n",
    "            transcription_text = f.read()\n",
    "        \n",
    "        # Split text into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "        chunks = text_splitter.split_text(transcription_text)\n",
    "        \n",
    "        # Vectorize each chunk with metadata\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            embedding = embedding_model.embed_documents([chunk])[0]  # Get embedding\n",
    "            \n",
    "            # Metadata includes file identifier and chunk index for reference\n",
    "            metadata = {\n",
    "                \"file_name\": filename,\n",
    "                \"file_id\": filename.replace(\"transcription_\", \"\").replace(\".txt\", \"\"),\n",
    "                \"chunk_idx\": chunk_idx,\n",
    "            }\n",
    "            all_vectorized_segments.append({\n",
    "                \"embedding\": embedding,\n",
    "                \"text\": chunk,\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "        \n",
    "        print(f\"Vectorization complete for {filename}.\")\n",
    "\n",
    "    return all_vectorized_segments\n",
    "\n",
    "# Execute the vectorization task\n",
    "if __name__ == \"__main__\":\n",
    "    vectorized_segments = vectorize_individual_transcriptions()\n",
    "    print(\"All transcription files have been vectorized. Ready for storage in Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0035a0fd4b477bbd8e021367b77162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserting segments to Pinecone:   0%|          | 0/349 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments upserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 - UPSERT embeddings to Pinecone\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Function to upsert vectorized segments to Pinecone\n",
    "def upsert_embeddings_to_pinecone(vectorized_segments, index):\n",
    "    for segment in tqdm(vectorized_segments, desc=\"Upserting segments to Pinecone\"):\n",
    "        # Prepare data for upsert\n",
    "        segment_id = segment[\"metadata\"][\"file_id\"] + \"_\" + str(segment[\"metadata\"][\"chunk_idx\"])  # Unique ID for each chunk\n",
    "        embedding = segment[\"embedding\"]\n",
    "        metadata = segment[\"metadata\"]\n",
    "        metadata[\"text\"] = segment[\"text\"]  # Adds the chunk's text content\n",
    "\n",
    "        # Upsert the segment into Pinecone\n",
    "        try:\n",
    "            index.upsert(vectors=[(segment_id, embedding, metadata)])\n",
    "        except Exception as e:\n",
    "            print(f\"Error upserting segment {segment_id}: {e}\")\n",
    "\n",
    "    print(\"All segments upserted into Pinecone.\")\n",
    "\n",
    "# Example usage:\n",
    "upsert_embeddings_to_pinecone(vectorized_segments, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "# Fetch the SerpAPI key securely\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\") or getpass.getpass(\"Enter SerpAPI key: \")\n",
    "\n",
    "# Example usage in SerpAPI tool setup\n",
    "serp_api_key = os.environ[\"SERPAPI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE ROUTER, RETRIEVE from VectorstoreDB and Retrieve from Google search functions!\n",
    "\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from serpapi import GoogleSearch\n",
    "import os\n",
    "\n",
    "# Initialize the embedding model and vector store\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Pinecone index is already set up and embeddings are upserted\n",
    "vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "\n",
    "# Initialize the router instructions\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to Accenture company Quarterly results, Revenue, Earnings for the last four quarters, sales, digital projects, cloud projects and employee details.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with a single key, \"datasource\", that is either 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Function to route query based on instructions\n",
    "def route_query(query):\n",
    "    routing_response = chat_model.invoke(\n",
    "        [SystemMessage(content=router_instructions), HumanMessage(content=query)]\n",
    "    )\n",
    "    route_decision = json.loads(routing_response.content)\n",
    "    return route_decision[\"datasource\"]\n",
    "\n",
    "# Function to retrieve from vector database\n",
    "def retrieve_from_vectorstore(query):\n",
    "    retriever = vector_store.as_retriever()\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    document_text = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "    # Summarize the retrieved documents using LLM \n",
    "    prompt = (\n",
    "        \"Based on the following documents, provide a concise answer to the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Documents:\\n\"\n",
    "        f\"{document_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )    \n",
    "    answer_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return answer_response.content\n",
    "    \n",
    "# Function to retrieve from Google search\n",
    "def web_search(query):\n",
    "    search = GoogleSearch({\n",
    "        \"q\": query,\n",
    "        \"api_key\": serp_api_key, \n",
    "        \"num\": 3  # Limit to top 3 results for conciseness\n",
    "    })\n",
    "    results = search.get_dict()\n",
    "\n",
    "    # Extract relevant text from search results\n",
    "    combined_text = \"\\n\".join(\n",
    "        result.get(\"snippet\", \"No snippet available\")\n",
    "        for result in results.get(\"organic_results\", [])\n",
    "    )\n",
    "    \n",
    "    # Summarize results using the LLM\n",
    "    prompt = (\n",
    "        f\"Summarize the following search results to answer the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Results:\\n{combined_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    summary_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return summary_response.content  \n",
    "\n",
    "# Main function to handle the query routing and retrieval\n",
    "def handle_query(query):\n",
    "    datasource = route_query(query)\n",
    "    \n",
    "    if datasource == \"vectorstore\":\n",
    "        print(\"Routing to Vectorstore...\")\n",
    "        return retrieve_from_vectorstore(query)\n",
    "    elif datasource == \"websearch\":\n",
    "        print(\"Routing to Web Search...\")\n",
    "        return web_search(query)\n",
    "    else:\n",
    "        return \"Unknown data source. Please check the router configuration.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE ALL THE TOOLS for ReACT agent! \n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from serpapi import GoogleSearch\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "\n",
    "# Define the Web search tool using SerpAPI\n",
    "web_search_tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    func=web_search,\n",
    "    description=\"Retrieve relevant information using google web search for general or current event questions.\"\n",
    ")\n",
    "\n",
    "# Define tool for vector store retrieval\n",
    "vector_store_tool = Tool(\n",
    "    name=\"VectorStore Retrieval\",\n",
    "    func=retrieve_from_vectorstore,\n",
    "    description=\"Retrieve relevant documents from the vector store for questions about Accenture's earnings, revenue, sales, projects, and employee details.\",\n",
    ")\n",
    "\n",
    "# Revised prompt for the agent with improved answer formatting\n",
    "agent_prompt = \"\"\"\n",
    "You are an expert assistant specializing in Accenture's financial data and competitor analysis.\n",
    "\n",
    "For each user query:\n",
    "1. Answer strictly based on provided context or vector data.\n",
    "2. Be concise and use up to three sentences.\n",
    "3. If the answer is found, respond directly by starting with \"Final Answer:\" without additional steps or thoughts.\n",
    "\n",
    "Now, respond to the question:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the ReAct agent with the custom prompt in each tool\n",
    "react_agent = initialize_agent(\n",
    "    tools=[vector_store_tool, web_search_tool],\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    llm=chat_model,\n",
    "    memory=memory,  # Integrate conversation memory\n",
    "    verbose=True,\n",
    "    max_iterations=5,  # Restrict maximum depth to avoid infinite loops\n",
    "    handle_parsing_errors=True  # Retry on output parsing errors\n",
    ")\n",
    "\n",
    "# Main function to handle the query using the ReAct agent with the custom prompt\n",
    "def handle_query_with_agent(query):\n",
    "    # Format the query with the agent's prompt\n",
    "    formatted_prompt = agent_prompt.format(user_query=query)\n",
    "    \n",
    "    # Use the prompt in the agent invocation\n",
    "    try:\n",
    "        response = react_agent({\"input\": formatted_prompt})\n",
    "        # If a valid answer is provided, return it\n",
    "        if \"output\" in response:\n",
    "            return response[\"output\"]\n",
    "        else:\n",
    "            # Fallback message if no answer found within the max iterations\n",
    "            return \"I don't know. Unable to find the answer within the provided context.\"\n",
    "    except Exception as e:\n",
    "        # In case of unexpected errors, provide a helpful message\n",
    "        return f\"Error encountered: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Accenture Q&A Chatbot! Ask any question about Accenture.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should retrieve the revenue information for Q3 2024 from the vector store.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Q3 2024 revenue Accenture\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe projected revenue for Accenture in Q3 2024 is expected to be in the range of 15.85 to 16.45 billion, with an estimated 2 to 5 percent growth in local currency compared to the previous year.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the revenue information for Q3 2024.\n",
      "Final Answer: The projected revenue for Accenture in Q3 2024 is expected to be in the range of 15.85 to 16.45 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent (using VectorDB):\n",
      "Question: revenue of Q3 2024?\n",
      "Answer: The projected revenue for Accenture in Q3 2024 is expected to be in the range of 15.85 to 16.45 billion.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Agent: Thank you for using the Q&A chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# INTERACTIVE CHAT FUNCTION using ReACT Agent - REFINED 3! Works perfect! TUESDAY\n",
    "\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Initialize chat model and memory\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Function to clear memory\n",
    "def reset_memory():\n",
    "    memory.clear()\n",
    "    print(\"Memory has been reset.\")\n",
    "\n",
    "# Interactive chat function with datasource-based source tagging\n",
    "def chatbot_interaction():\n",
    "    print(\"Welcome to the Accenture Q&A Chatbot! Ask any question about Accenture.\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"no\"]:\n",
    "            print(\"Agent: Thank you for using the Q&A chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Determine the datasource\n",
    "        datasource = route_query(user_query)\n",
    "        \n",
    "        # Tag source based on datasource\n",
    "        source_label = \"VectorDB\" if datasource == \"vectorstore\" else \"Google Search\" if datasource == \"websearch\" else \"Unknown Source\"        \n",
    "        \n",
    "        try:\n",
    "            # Get response from the handle_query_with_agent function instead of calling react_agent directly\n",
    "            answer = handle_query_with_agent(user_query)\n",
    "            print(f\"\\nAgent (using {source_label}):\\nQuestion: {user_query}\\nAnswer: {answer}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}\")\n",
    "            print(\"Agent: Unable to process the request. Please try again.\")\n",
    "        \n",
    "        print(\"\\nAgent: Do you have more questions?\")\n",
    "\n",
    "# Start the chatbot interaction\n",
    "chatbot_interaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://05e3852bb6023b35a3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://05e3852bb6023b35a3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find this specific financial information.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture EPS fourth quarter 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Accenture EPS for the fourth quarter of 2024 is not provided in the documents.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Google Search to find this specific financial information.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture EPS fourth quarter 2024\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture reported an adjusted EPS of $2.79 for the fourth quarter of fiscal 2024, which was a 3% increase over the previous quarter.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the final answer.\n",
      "Final Answer: The EPS of Accenture in the fourth quarter of 2024 was $2.79.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information about Accenture's earnings.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture earnings Q3 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong growth in FY25, with full fiscal year bookings of $81 billion and revenues of $65 billion. For the third quarter of fiscal 2024, they expect revenues to be in the range of 16.1 billion to 16.7 billion, with an estimated 3 to 7 percent growth in local currency. For the full fiscal year 2024, they expect revenue to be in the range of 2 to 5 percent growth in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need more specific information about the EPS.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture EPS Q3 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Q3 2024, Accenture is expecting revenues to be in the range of 16.1 billion to 16.7 billion, with an estimated 3 to 7 percent growth in local currency. Adjusted earnings per share for FY24 was $11.67, reflecting a 9% growth over FY22 EPS. The company is committed to delivering enduring shareholder value proposition and creating value for all stakeholders.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The EPS of Accenture in the third quarter of 2024 is expected to be in the range of $11.67.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find specific financial information about Accenture's revenue for the third quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture revenue Q3 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported revenues of $65 billion for FY24, representing 2% growth in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find out if there are any more recent updates on Accenture's revenue for Q3 2024.\n",
      "Action: Google Search\n",
      "Action Input: Accenture revenue Q3 2024 latest news\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn the third quarter of fiscal 2024, Accenture reported new bookings of $21.06 billion, showing a significant increase. The company's revenue is forecasted to grow at an average rate of 6.8% over the next 3 years, slightly lower than the 9.0% growth forecast for the IT industry in the US.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe revenue of Accenture in the third quarter of 2024 is $21.06 billion, with a forecasted growth rate of 6.8% over the next 3 years.\n",
      "Final Answer: The revenue of Accenture in the third quarter of 2024 is $21.06 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to figure out what the original question is before I can answer it.\n",
      "Action: Google Search\n",
      "Action Input: \"original question\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAn original question is one that demonstrates an attempt to connect different ideas or identify a conflict. The phrase \"original question\" is acceptable in written English and can be used when referring to a question being answered or considered.\u001b[0m\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information on Accenture's earnings in the fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture earnings Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported revenues of $65 billion for the full fiscal year 2023, representing 2 percent growth in local currency. They expect revenue growth of 2 to 5 percent for the full fiscal year 2024. They have positioned themselves for strong growth in FY25, focusing on transformative technology like Generative AI. They have also received accolades for their environmental initiatives and community work, such as supporting refugees.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need more specific information for the earnings in the fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture earnings Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong results for the 4th quarter of fiscal 2023, with full fiscal year bookings of $81 billion and revenues of $65 billion. They also announced a business outlook for the first quarter of fiscal 2024, expecting revenues to be in the range of 15.85 to 16.45 billion. For the full fiscal year 2024, they expect revenue to be in the range of 2 to 5% growth in local currency. They emphasized their focus on Gen AI technology and their commitment to sustainability and community initiatives.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Accenture reported revenues of $65 billion for the full fiscal year 2023 and had strong results in the 4th quarter of fiscal 2023, with bookings of $81 billion and revenues of $65 billion. They expect revenue growth of 2 to 5 percent for the full fiscal year 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the VectorStore Retrieval tool to find this specific financial information.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture EPS fourth quarter 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong growth in FY24, positioning the company for continued growth in FY25. Revenues for the year were $65 billion, representing a 2% growth in local currency. The company also reported full fiscal year bookings of $81 billion, a 14% growth in local currency. Additionally, Accenture has increased its base of deep client relationships, with 310 diamond clients, an increase of 10 from the previous year. The company expects to see continued growth in the next fiscal year.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe information provided did not specifically mention the EPS in the fourth quarter of 2024. I should try another query to find this specific number.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture EPS Q4 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the documents provided, Accenture's EPS for Q4 2024 is expected to be positive, with a strong growth outlook for the full fiscal year. The company has demonstrated strong financial performance and is well-positioned for growth in the coming year.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe specific EPS number for Q4 2024 was not found in the documents. I should try to find this information using a different approach.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture EPS Q4 2024\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture reported adjusted EPS of $2.79 for Q4 2024, representing a 3% increase over the previous quarter. The GAAP EPS for Q4 2024 was $2.66, compared to $2.15 in Q4 2023. The financial results were reported for the fourth quarter and full fiscal year ended August 31, 2024.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The EPS of Accenture in the fourth quarter of 2024 was $2.79 (adjusted EPS) and $2.66 (GAAP EPS).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Google Search to find a list of Accenture's competitors\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture competitors\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSome of Accenture's top competitors and alternatives include IBM, PwC, Tata Consultancy Services (TCS), Capgemini, Deloitte, Cognizant, SAP, and DXC Technology. Other notable competitors are KPMG and Ernst & Young (EY). Deloitte Consulting, Capgemini Services, and Cognizant are considered some of the best alternatives to Accenture.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have a list of Accenture's competitors\n",
      "Final Answer: Some of Accenture's competitors include IBM, PwC, Tata Consultancy Services (TCS), Capgemini, Deloitte, Cognizant, SAP, DXC Technology, KPMG, and Ernst & Young (EY).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for a list of top consulting companies to find out who else is in the consulting space.\n",
      "Action: Google Search\n",
      "Action Input: top consulting companies list\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe search results provide a list of top consulting firms, with McKinsey, Boston Consulting Group (BCG), and Bain & Company being commonly mentioned as the top firms. The results advise aspiring consultants not to limit themselves to just the top three firms and explore other top consulting companies as well.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should consider exploring other top consulting companies mentioned in the search results.\n",
      "Action: Google Search\n",
      "Action Input: top consulting companies other than McKinsey, BCG, and Bain\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn addition to McKinsey, BCG, and Bain, some other top consulting companies include EY (Ernst & Young), PwC, Deloitte, and KPMG, which are known as the Big 4 consulting firms.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know some of the other top consulting companies in the space.\n",
      "Final Answer: Some other top consulting companies besides McKinsey, BCG, and Bain include EY, PwC, Deloitte, and KPMG.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to understand what the question is asking for.\n",
      "Action: Ask for clarification.\n",
      "Action Input: \"Can you please provide more context or rephrase the question?\"\u001b[0m\n",
      "Observation: Ask for clarification. is not a valid tool, try one of [VectorStore Retrieval, Google Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try to use either VectorStore Retrieval or Google Search to find the answer to the question. Let me rephrase the question to see if it is more specific.\n",
      "Action: Google Search\n",
      "Action Input: The rephrased question\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mRephrasing a question allows for a more clear and direct answer by changing the wording or structure of the original question.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should now try to find the answer based on the rephrased question.\n",
      "Final Answer: The final answer to the original input question.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to compare the EPS of Q3 and Q4 for Accenture.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: EPS Q3, EPS Q4 Accenture\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Q3, Accenture reported revenues of $65 billion for the year, representing 2% growth in local currency, while continuing to take market share. In Q4, Accenture reported revenues of $64 billion for the year, representing 8% growth in local currency and delivering adjusted EPS growth of 9%.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe EPS for Q4 is higher than Q3 for Accenture.\n",
      "Final Answer: The EPS for Q4 is higher than Q3 for Accenture.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information about Accenture's earnings for Q3 and Q4 in 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: EPS Q3 2024, EPS Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEPS Q3 2024: Adjusted EPS of $2.69, 6% growth over EPS last year, adjusted operating margin of 13.8%, free cash flow of $2.2 billion, returned $1.8 billion to shareholders.\n",
      "\n",
      "EPS Q4 2024: Adjusted EPS of $11.67, 9% growth over FY22 EPS, adjusted operating margin of 15.4%, free cash flow of $9 billion, returned $7.2 billion to shareholders, invested $2.5 billion in acquisitions, revenue growth of 9% in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the EPS of Q3 and Q4 in 2024.\n",
      "Final Answer: EPS of Q3 2024 was $2.69 and EPS of Q4 2024 was $11.67.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find the earnings per share (EPS) information for Q3 and Q4 in 2023 for Accenture.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: EPS Q3 2023, EPS Q4 2023 Accenture\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFor Q3 2023, Accenture expects revenues to be in the range of 16.1 billion to 16.7 billion, with an estimated 3 to 7 percent growth in local currency. For Q4 2023, Accenture anticipates revenues in the range of 15.85 to 16.45 billion, with an estimated negative 2% to positive 2% growth in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to extract the specific EPS values for Q3 and Q4 from the information I found.\n",
      "Action: Extraction\n",
      "Action Input: EPS Q3 2023, EPS Q4 2023\u001b[0m\n",
      "Observation: Extraction is not a valid tool, try one of [VectorStore Retrieval, Google Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find the specific EPS values for Q3 and Q4 in 2023 for Accenture.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: EPS Q3 2023 Accenture, EPS Q4 2023 Accenture\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEPS Q3 2023 for Accenture was not provided in the documents. EPS Q4 2023 for Accenture was 9% growth.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The EPS growth for Q3 2023 was not provided, and the EPS growth for Q4 2023 was 9% for Accenture.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the VectorStore Retrieval tool to find information specifically about Accenture's revenue for the fourth quarter of 2023.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture revenue Q4 2023\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture is expected to have revenues in the range of $15.75 billion to $16.35 billion for Q4 2023.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the specific revenue range for Accenture's fourth quarter 2023.\n",
      "Final Answer: Accenture is expected to have revenues in the range of $15.75 billion to $16.35 billion for Q4 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to get information on Accenture's revenue for a specific quarter.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture revenue Q3 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported revenues of $65 billion for FY24, representing 2% growth in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find out what percentage of Accenture's revenue comes from digital services.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture digital services revenue percentage\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture digital services revenue percentage is not explicitly mentioned in the provided documents.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Google Search to find the percentage of Accenture's revenue that comes from digital services.\n",
      "Action: Google Search\n",
      "Action Input: Accenture digital services revenue percentage\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe Accenture digital services revenue percentage for the fourth quarter of fiscal 2024 was 4% for Communications, Media & Technology and 3% for Financial Services.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The revenue of Accenture for the third quarter of 2024 was $65 billion, with digital services contributing 4% for Communications, Media & Technology and 3% for Financial Services.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# GRADIO only with TEXT - REFINED! Works Perfect!\n",
    "\n",
    "import json\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "def gradio_chatbot(user_query):\n",
    "    # Determine the source using the routing function\n",
    "    datasource = route_query(user_query)\n",
    "    \n",
    "    # Tag source based on the datasource returned\n",
    "    source_label = \"VectorDB\" if datasource == \"vectorstore\" else \"Google Search\" if datasource == \"websearch\" else \"Unknown Source\"\n",
    "    \n",
    "    try:\n",
    "        # Get response from the ReAct agent\n",
    "        response = react_agent({\"input\": user_query})\n",
    "\n",
    "        # Check if the response is not empty and parse the response JSON if possible\n",
    "        if response and \"output\" in response:\n",
    "            output_content = response[\"output\"]\n",
    "            \n",
    "            # Attempt to parse JSON response if available\n",
    "            try:\n",
    "                parsed_response = json.loads(output_content) if isinstance(output_content, str) else output_content\n",
    "                answer = parsed_response.get(\"answer\", output_content) if isinstance(parsed_response, dict) else output_content\n",
    "            except json.JSONDecodeError:\n",
    "                answer = output_content  # Fallback to raw output if JSON parsing fails\n",
    "\n",
    "            return f\"Answer (from {source_label}):\\n{answer}\"\n",
    "\n",
    "        else:\n",
    "            return \"Error: Received an empty or unexpected response format from the agent.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capture any other errors\n",
    "        return f\"Error encountered: {str(e)}\"\n",
    "\n",
    "# Create the Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_chatbot,  # Function to call\n",
    "    inputs=\"text\",      # Input type: text\n",
    "    outputs=\"text\",     # Output type: text\n",
    "    title=\"Accenture Q&A Chatbot\",\n",
    "    description=\"Ask any question about Accenture and get answers with sourced information.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
