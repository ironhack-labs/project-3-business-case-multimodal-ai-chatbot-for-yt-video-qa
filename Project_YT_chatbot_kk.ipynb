{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install pytube\\n!pip install openai-whisper\\n!pip install langchain\\n!pip install openai '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install pytube\n",
    "!pip install openai-whisper\n",
    "!pip install langchain\n",
    "!pip install openai \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, torch\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import langchain.output_parsers as parsers\\ndir(parsers) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import langchain.output_parsers as parsers\n",
    "dir(parsers) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from pytube import YouTube\n",
    "\n",
    "def download_audio_from_youtube(url):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    audio_path = audio_stream.download(filename=\"audio.mp3\")\n",
    "    return audio_path\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import whisper\n",
    "\n",
    "def transcribe_audio_with_whisper(audio_path):\n",
    "    model = whisper.load_model(\"base\")  # or \"small\", \"medium\", \"large\" depending on needs\n",
    "    transcription = model.transcribe(audio_path)\n",
    "    return transcription['text'] \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from langchain.tools import Tool\n",
    "\n",
    "def youtube_to_text_tool(url):\n",
    "    audio_path = download_audio_from_youtube(url)\n",
    "    transcription = transcribe_audio_with_whisper(audio_path)\n",
    "    return transcription\n",
    "\n",
    "youtube_transcription_tool = Tool(\n",
    "    name=\"YouTubeTranscriptionTool\",\n",
    "    func=youtube_to_text_tool,\n",
    "    description=\"Converts YouTube video audio to text.\"\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load Environment Variable\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the environment variable directly in the script\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "#OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "#PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") # or \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the environment variable with os.environ\n",
    "#print(os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting yt-dlp\n",
      "  Downloading yt_dlp-2024.10.22-py3-none-any.whl.metadata (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.6/171.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting brotli (from yt-dlp)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from yt-dlp) (2020.6.20)\n",
      "Collecting mutagen (from yt-dlp)\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt-dlp)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting requests<3,>=2.32.2 (from yt-dlp)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.11/dist-packages (from yt-dlp) (2.0.7)\n",
      "Collecting websockets>=13.0 (from yt-dlp)\n",
      "  Downloading websockets-13.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3)\n",
      "Downloading yt_dlp-2024.10.22-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mmm\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-13.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: brotli, websockets, requests, pycryptodomex, mutagen, yt-dlp\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.21.0 requests-2.32.3 websockets-13.1 yt-dlp-2024.10.22\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (1.26.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (9.5.0)\n",
      "Collecting imageio-ffmpeg (from imageio[ffmpeg])\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio-ffmpeg->imageio[ffmpeg]) (69.0.3)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\"\"\" !pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "!pip install imageio[ffmpeg] \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/.local/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "# TO DEBUG THE FFMPEG location issue!\n",
    "\n",
    "\"\"\" import os\n",
    "print(os.environ[\"PATH\"])\n",
    "\n",
    "import subprocess\n",
    "subprocess.run([\"ffmpeg\", \"-version\"]) \"\"\"\n",
    "\n",
    "#!apt-get update && apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/ffmpeg\n"
     ]
    }
   ],
   "source": [
    "#!which ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/1: https://www.youtube.com/watch?v=kgldqMlCh78\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=kgldqMlCh78\n",
      "[youtube] kgldqMlCh78: Downloading webpage\n",
      "[youtube] kgldqMlCh78: Downloading ios player API JSON\n",
      "[youtube] kgldqMlCh78: Downloading mweb player API JSON\n",
      "[youtube] kgldqMlCh78: Downloading m3u8 information\n",
      "[info] kgldqMlCh78: Downloading 1 format(s): 251\n",
      "[download] audio_0.mp3 has already been downloaded\n",
      "[download] 100% of    8.07MiB\n",
      "[ExtractAudio] Not converting audio audio_0.mp3; file is already in target format mp3\n",
      "Completed transcription for video 1\n"
     ]
    }
   ],
   "source": [
    "# using TEXT file that has multiple YOUTUBE video links!\n",
    "\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "\n",
    "# Default configurations for easy modification\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"  # Text file with newline-separated YouTube links\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}.mp3\"  # Template for audio filenames with .mp3 extension\n",
    "WHISPER_MODEL = \"turbo\"  # Use Whisper turbo for faster processing, if available\n",
    "\n",
    "# Load YouTube links from file with newline separation\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        video_links = [link.strip() for link in file.readlines() if link.strip()]\n",
    "    return video_links\n",
    "\n",
    "# Download audio from a YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': output_name,  # Ensure the filename includes .mp3 extension\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'  # Update for Paperspace\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return output_name  # Return the filename with .mp3 extension\n",
    "\n",
    "# Transcribe audio using Whisper turbo model\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)  # Use turbo model for faster processing\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Process each video link\n",
    "def process_videos(filename=VIDEO_LINKS_FILE):\n",
    "    video_links = load_video_links(filename)\n",
    "    all_transcriptions = []\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, output_name=AUDIO_OUTPUT_TEMPLATE.format(i))  # Use .mp3 extension\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        all_transcriptions.append(transcription)\n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "    return all_transcriptions\n",
    "\n",
    "# Run the process\n",
    "all_transcriptions = process_videos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved as consolidated_transcription.html\n"
     ]
    }
   ],
   "source": [
    "# Default configuration for consolidated transcription output\n",
    "CONSOLIDATED_TRANSCRIPTION_FILE = \"consolidated_transcription.html\"  # Name for the HTML file\n",
    "\n",
    "# Save consolidated transcription to a single HTML file\n",
    "def save_consolidated_transcription(transcriptions=all_transcriptions):\n",
    "    with open(CONSOLIDATED_TRANSCRIPTION_FILE, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"<html><body><h1>Consolidated Transcription</h1><ol>\")\n",
    "        for i, transcription in enumerate(transcriptions):\n",
    "            file.write(f\"<h2>Video {i+1}</h2>\")\n",
    "            for line in transcription.splitlines():\n",
    "                file.write(f\"<li>{line}</li>\")\n",
    "        file.write(\"</ol></body></html>\")\n",
    "    print(f\"Transcription saved as {CONSOLIDATED_TRANSCRIPTION_FILE}\")\n",
    "\n",
    "# Save all transcriptions to the consolidated HTML file\n",
    "save_consolidated_transcription()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=rhiYfBctLOI\n",
      "[youtube] rhiYfBctLOI: Downloading webpage\n",
      "[youtube] rhiYfBctLOI: Downloading ios player API JSON\n",
      "[youtube] rhiYfBctLOI: Downloading mweb player API JSON\n",
      "[youtube] rhiYfBctLOI: Downloading player 4e23410d\n",
      "[youtube] rhiYfBctLOI: Downloading m3u8 information\n",
      "[info] rhiYfBctLOI: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_accent_1hr\n",
      "[download] 100% of   51.43MiB in 00:00:01 at 30.88MiB/s    \n",
      "[ExtractAudio] Destination: audio_accent_1hr.mp3\n",
      "Deleting original file audio_accent_1hr (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 179MiB/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # to run it on PAPERSPACE! Youtube link IN-LINE!\n",
    "\n",
    "import yt_dlp\n",
    "\n",
    "def download_audio(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': 'audio_accent_1hr',\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'  # Updated path to ffmpeg on Paperspace\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return 'audio_accent_1hr.mp3'\n",
    "\n",
    "# Assuming transcribe_audio_with_whisper is a function that takes an audio path and transcribes it with Whisper\n",
    "video_url = \"https://www.youtube.com/watch?v=rhiYfBctLOI\"\n",
    "audio_path = download_audio(video_url)\n",
    "transcription = transcribe_audio_with_whisper(audio_path)\n",
    "#print(transcription) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved as HTML.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Save transcription to HTML\n",
    "with open('transcription.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(\"<html><body><h1>Transcription</h1><ol>\")\n",
    "    for line in transcription.splitlines():  # Split by lines if it's a long string\n",
    "        file.write(f\"<li>{line}</li>\")\n",
    "    file.write(\"</ol></body></html>\")\n",
    "\n",
    "print(\"Transcription saved as HTML.\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.9.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.6)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.138)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.3)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.4-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 2.21.0\n",
      "    Uninstalling marshmallow-2.21.0:\n",
      "      Successfully uninstalled marshmallow-2.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\n",
      "gradient 2.0.6 requires marshmallow<3.0, but you have marshmallow 3.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.4 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete. Ready for storage in a vector database.\n"
     ]
    }
   ],
   "source": [
    "# SEGMENT and VECTORIZE the Transcription with Langchain\n",
    "\n",
    "# Join all transcriptions into a single string (Conversion of List to String)\n",
    "consolidated_text = \"\\n\\n\".join(all_transcriptions)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the OpenAI embedding model \n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=400)\n",
    "segments = text_splitter.split_text(consolidated_text)\n",
    "\n",
    "# Vectorize each segment and store in a list with segment metadata\n",
    "vectorized_segments = []\n",
    "embeddings = embedding_model.embed_documents(segments)  # Generate embeddings for all segments\n",
    "\n",
    "for i, (segment, vector) in enumerate(zip(segments, embeddings)):\n",
    "    vectorized_segments.append({\n",
    "        \"id\": f\"segment_{i}\",\n",
    "        \"text\": segment,\n",
    "        \"embedding\": vector\n",
    "    })\n",
    "\n",
    "print(\"Vectorization complete. Ready for storage in a vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/lib/python3/dist-packages (from pinecone-client) (2020.6.20)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.0.7)\n",
      "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\n",
      "Successfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely fetch OpenAI and Pinecone API keys                    \n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")\n",
    "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ[\"PINECONE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMBEDDINGS OpenAI-ada-002\n",
    "\n",
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Securely fetch OpenAI and Pinecone API keys\n",
    "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OpenAI API key: \")\n",
    "#os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")\n",
    "#os.environ[\"PINECONE_ENV\"] = os.getenv(\"PINECONE_ENV\") or \"us-west1-gcp\"  # Example environment\n",
    "\n",
    "# Initialize OpenAI embeddings model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Initialize Pinecone client with the updated API\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "#spec = ServerlessSpec(cloud=\"aws\", region=\"us-west-1\")  # Specify Pinecone environment\n",
    "index_name = \"transcription-diwali-qa-index\"\n",
    "\n",
    "# Check if the index exists; create if it doesn’t\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI embedding dimension\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for the index to be ready\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for upsertion\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4db0aaaf6b499cb64b6bb6efcd11cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments upserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Upsert embeddings to Pinecone in batches\n",
    "batch_size = 50\n",
    "for i in tqdm(range(0, len(vectorized_segments), batch_size)):\n",
    "    batch = vectorized_segments[i:i + batch_size]\n",
    "    ids = [segment[\"id\"] for segment in batch]\n",
    "    embeds = [segment[\"embedding\"] for segment in batch]\n",
    "    metadatas = [{\"text\": segment[\"text\"]} for segment in batch]\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "\n",
    "print(\"All segments upserted into Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 10}},\n",
       " 'total_vector_count': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Subject: Summarize the following: Time now for our Entrenews segment and today we're going to learn a little more about the Festival of Lights. Diwali is celebrated in India and is starting to gain popularity around the world. And to talk more about this, let's bring in our very own Delano D'Souza. Delano, let's start at the beginning. What exactly is Diwali? Hi, Jeannie. Good to see you. Well, Diwali is a festival that celebrates essentially the triumph of good over evil, knowledge over ignorance. It's a holiday that's popular amongst Hindus over in India, but is celebrated across religious lines. So Christians, Muslims, Buddhists, Sikhs, everyone celebrates Diwali. But like everything in India, there is a divide between the north and the south over how it is celebrated or even what it is called. But what is common in India is you have a lot of these little lights called diyas that are lit and they're pretty much everywhere. Now, there's also this belief that if you gamble during Diwali, you will be prosperous for Sikhs, everyone celebrates Diwali. But like everything in India, there is a divide between the north and the south over how it is celebrated or even what it is called. But what is common in India is you have a lot of these little lights called diyas that are lit and they're pretty much everywhere. Now, there's also this belief that if you gamble during Diwali, you will be prosperous for the next year. But I don't know how true this is. I did gamble last year. It wasn't very prosperous. Maybe that was because I got wiped out. Now, over the years, there has been this effort to clean up Diwali, if you will, and crack down on the lighting of firecrackers, which leads to both air and noise pollution. So this time around, we have several Indian states who are trying to get ahead of the problem, including Delhi, Haryana, Punjab and Tamil Nadu. And they've taken measures to essentially ban the production, the sale and the use of firecrackers. But of course, it remains to be seen if those bans the skin tone of the average Indian girl. And all the feedback that we received from all of the world, such emotional feedback, saying that finally mothers have written to me, sent voice notes to me, saying that I can finally gift my daughter a doll, a doll that she can relate to, and a doll that looks like her, a doll that a skin color like her. So that was Anita Dongre speaking to me on Access Asia about how she was involved in the process to create Diwali Barbie. For now, Diwali here in Paris is more amongst the diaspora at home. It's not really taking on the global dimensions we're seeing in places like London and New York. But there are members of the community here who want to change that. In any case, it sounds like a lot of fun. Thank you for telling us all about it. That's Friends 24's Delana D'Souza. a tradition. If she does win the presidency, she may continue as president of the United States. Now, the reason we are seeing Diwali take on this international dimension is simply because of the Indian diaspora being so widespread. In the United States, for instance, we have heads of Fortune 500 companies who are of Indian origin. For instance, Alphabet, Microsoft, Adobe. These are just some companies that have Indian heads. In the past, Indians would be more personal about how they celebrated their holidays. But things have started to change in recent years. We have big celebrations taking place in New York, attended by the likes of Padman Lakshmi, Mindy Kaling, well-known Indian Americans. This past weekend over in London, in fact, we had Conde Nast Traveler who held its third installment of its Diwali celebrations, which it co-hosted with French luxury jeweler Cartier. Now, I reached out to the global editorial director, Divya Tani, and asked her why a magazine would want to place in New York, attended by the likes of Padman Lakshmi, Mindy Kaling, well-known Indian Americans. This past weekend over in London, in fact, we had Conde Nast Traveler who held its third installment of its Diwali celebrations, which it co-hosted with French luxury jeweler Cartier. Now, I reached out to the global editorial director, Divya Tani, and asked her why a magazine would want to celebrate Diwali. And she told me when she first arrived in London, she didn't feel that the Diwali celebrations which existed matched the power and the influence of the Indian community in the UK. So, essentially, she decided to go ahead and start her own. She contacted Anna Wintour, who told her, just run with it. And she decided to partner with brands which have a long history with India. So, this is why Cartier jumped into the picture. She told me something interesting. She said that a lot of luxury brands are looking at India in a positive way. The smart ones recognize the power of the Indian\n"
     ]
    }
   ],
   "source": [
    "# EMBED user QUERY and retrieve RELEVANT SEGMENTS (K-5)\n",
    "# generate a SUMMARY at first # NEED TO relook at this requirement, as it is only appending the segments. or use GPT4>\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Step 1: Embed User Query and Retrieve Relevant Segments\n",
    "def retrieve_relevant_segments(query):\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    results = index.query(vector=query_embedding, top_k=5, include_metadata=True)\n",
    "    segments = [match['metadata']['text'] for match in results['matches']]\n",
    "    return segments\n",
    "\n",
    "\n",
    "# Step 2: Generate Summary from Retrieved Segments\n",
    "def generate_summary(segments):\n",
    "    # Concatenate segments to prepare for summarization\n",
    "    context = \" \".join(segments)\n",
    "    summary_prompt = PromptTemplate(input_variables=[\"context\"], template=\"Summarize the following: {context}\")\n",
    "    summary = summary_prompt.format(context=context)\n",
    "    return summary\n",
    "\n",
    "# Sample user query\n",
    "user_query = \"Tell me about this subject in simple terms.\"\n",
    "segments = retrieve_relevant_segments(user_query)\n",
    "summary = generate_summary(segments)\n",
    "\n",
    "print(\"Summary of Subject:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/1154057344.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "/tmp/ipykernel_40/1154057344.py:11: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
      "/tmp/ipykernel_40/1154057344.py:14: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")  # Specify \"text\" as the key for document content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Subject: Summarize the following: Time now for our Entrenews segment and today we're going to learn a little more about the Festival of Lights. Diwali is celebrated in India and is starting to gain popularity around the world. And to talk more about this, let's bring in our very own Delano D'Souza. Delano, let's start at the beginning. What exactly is Diwali? Hi, Jeannie. Good to see you. Well, Diwali is a festival that celebrates essentially the triumph of good over evil, knowledge over ignorance. It's a holiday that's popular amongst Hindus over in India, but is celebrated across religious lines. So Christians, Muslims, Buddhists, Sikhs, everyone celebrates Diwali. But like everything in India, there is a divide between the north and the south over how it is celebrated or even what it is called. But what is common in India is you have a lot of these little lights called diyas that are lit and they're pretty much everywhere. Now, there's also this belief that if you gamble during Diwali, you will be prosperous for Sikhs, everyone celebrates Diwali. But like everything in India, there is a divide between the north and the south over how it is celebrated or even what it is called. But what is common in India is you have a lot of these little lights called diyas that are lit and they're pretty much everywhere. Now, there's also this belief that if you gamble during Diwali, you will be prosperous for the next year. But I don't know how true this is. I did gamble last year. It wasn't very prosperous. Maybe that was because I got wiped out. Now, over the years, there has been this effort to clean up Diwali, if you will, and crack down on the lighting of firecrackers, which leads to both air and noise pollution. So this time around, we have several Indian states who are trying to get ahead of the problem, including Delhi, Haryana, Punjab and Tamil Nadu. And they've taken measures to essentially ban the production, the sale and the use of firecrackers. But of course, it remains to be seen if those bans the skin tone of the average Indian girl. And all the feedback that we received from all of the world, such emotional feedback, saying that finally mothers have written to me, sent voice notes to me, saying that I can finally gift my daughter a doll, a doll that she can relate to, and a doll that looks like her, a doll that a skin color like her. So that was Anita Dongre speaking to me on Access Asia about how she was involved in the process to create Diwali Barbie. For now, Diwali here in Paris is more amongst the diaspora at home. It's not really taking on the global dimensions we're seeing in places like London and New York. But there are members of the community here who want to change that. In any case, it sounds like a lot of fun. Thank you for telling us all about it. That's Friends 24's Delana D'Souza. a tradition. If she does win the presidency, she may continue as president of the United States. Now, the reason we are seeing Diwali take on this international dimension is simply because of the Indian diaspora being so widespread. In the United States, for instance, we have heads of Fortune 500 companies who are of Indian origin. For instance, Alphabet, Microsoft, Adobe. These are just some companies that have Indian heads. In the past, Indians would be more personal about how they celebrated their holidays. But things have started to change in recent years. We have big celebrations taking place in New York, attended by the likes of Padman Lakshmi, Mindy Kaling, well-known Indian Americans. This past weekend over in London, in fact, we had Conde Nast Traveler who held its third installment of its Diwali celebrations, which it co-hosted with French luxury jeweler Cartier. Now, I reached out to the global editorial director, Divya Tani, and asked her why a magazine would want to place in New York, attended by the likes of Padman Lakshmi, Mindy Kaling, well-known Indian Americans. This past weekend over in London, in fact, we had Conde Nast Traveler who held its third installment of its Diwali celebrations, which it co-hosted with French luxury jeweler Cartier. Now, I reached out to the global editorial director, Divya Tani, and asked her why a magazine would want to celebrate Diwali. And she told me when she first arrived in London, she didn't feel that the Diwali celebrations which existed matched the power and the influence of the Indian community in the UK. So, essentially, she decided to go ahead and start her own. She contacted Anna Wintour, who told her, just run with it. And she decided to partner with brands which have a long history with India. So, this is why Cartier jumped into the picture. She told me something interesting. She said that a lot of luxury brands are looking at India in a positive way. The smart ones recognize the power of the Indian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/1154057344.py:34: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"question\": follow_up_query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent's Response: Diwali is celebrated outside India by the Indian diaspora in various countries where there is a significant Hindu population. The celebrations usually include lighting diyas (small oil lamps), decorating homes with colorful rangoli designs, exchanging gifts, wearing new clothes, enjoying festive meals, and setting off fireworks. The cultural significance of Diwali is shared through community events, religious ceremonies, and cultural performances. In recent years, some places have also recognized Diwali as an official holiday, allowing for wider participation and acknowledgment of the festival's importance.\n"
     ]
    }
   ],
   "source": [
    "# AGENT setup for QA interaction:\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize memory to track conversation context\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialize the Chat model (e.g., GPT-3.5)\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Wrap Pinecone index with LangChain's Pinecone vector store\n",
    "vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")  # Specify \"text\" as the key for document content\n",
    "\n",
    "# Create Conversational Retrieval Chain using the wrapped vector store and memory\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=chat_model,\n",
    "    retriever=vector_store.as_retriever(),  # Use the vector store as the retriever\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Define a function to handle the initial interaction\n",
    "def initial_interaction(user_query):\n",
    "    # Step 1: Retrieve and summarize\n",
    "    segments = retrieve_relevant_segments(user_query)\n",
    "    summary = generate_summary(segments)\n",
    "    \n",
    "    # Step 2: Present the summary to the user and prompt for follow-ups\n",
    "    print(\"Summary of Subject:\", summary)\n",
    "    follow_up_query = input(\"Do you have any further questions on this topic? \")\n",
    "    \n",
    "    # Step 3: Run the follow-up query through the agent\n",
    "    response = qa_chain({\"question\": follow_up_query})\n",
    "    print(\"Agent's Response:\", response['answer'])\n",
    "\n",
    "# Example call to start the interaction\n",
    "user_query = \"Tell me about this subject in simple terms.\"\n",
    "initial_interaction(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Q&A Chatbot! Ask me anything.\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " The U.S. state that recently signed a bill recognizing Diwali as a state holiday is Pennsylvania.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " Diwali is typically celebrated in the autumn, usually in October or November, depending on the lunar calendar.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " Diwali is typically celebrated in the autumn, usually between mid-October and mid-November.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " Diwali is primarily celebrated by Hindus in India, but it is also celebrated by people of other faiths such as Christians, Muslims, Buddhists, and Sikhs. It is a festival that is celebrated across religious lines.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " Diwali is primarily celebrated by Hindus in India, but it is also celebrated by people from various other religious backgrounds such as Christians, Muslims, Buddhists, Sikhs, and others. The festival has gained popularity globally and is now celebrated in countries with significant Hindu populations like Singapore, Malaysia, Sri Lanka, and even in some parts of the United States and the United Kingdom.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " In the context provided, it is mentioned that there is a divide between the north and the south of India on how Diwali is celebrated or even what it is called. However, the specific difference between the terms \"Diwali\" and \"Deepavali\" is not explicitly mentioned. Therefore, based on this information, it is clear that there may be regional variations in the naming and celebration of the festival, but the exact difference between Diwali and Deepavali is not specified.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " In the context provided, it is mentioned that there is a divide between the north and the south of India over how Diwali is celebrated or even what it is called. In the north, it is commonly known as Diwali, while in the south, it is often referred to as Deepavali. The differences between Diwali and Deepavali are primarily regional and linguistic variations within India.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Agent: Thank you for using the Q&A chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "# Define a simple response schema with only the main answer\n",
    "response_schema = [\n",
    "    ResponseSchema(name=\"answer\", description=\"Main response text in a complete paragraph\")\n",
    "]\n",
    "\n",
    "# Initialize the StructuredOutputParser\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "# Define the prompt template with stricter JSON formatting instructions\n",
    "response_template = PromptTemplate(\n",
    "    template=(\n",
    "        \"Answer the question below in a complete paragraph and respond in *strict JSON* format:\\n\\n\"\n",
    "        \"{format_instructions}\\n\\n\"\n",
    "        \"Question: {question}\"\n",
    "    ),\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Interactive chat function with improved parsing logic\n",
    "def interactive_chat():\n",
    "    print(\"Welcome to the Q&A Chatbot! Ask me anything.\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() == \"no\":\n",
    "            print(\"Agent: Thank you for using the Q&A chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Generate response with format instructions\n",
    "        formatted_prompt = response_template.format(question=user_query)\n",
    "        response = qa_chain({\"question\": formatted_prompt})\n",
    "        \n",
    "        # Check for JSON format; fallback to raw response if JSON parsing fails\n",
    "        try:\n",
    "            parsed_response = output_parser.parse(response['answer'])\n",
    "            print(\"Agent's Response:\\n\", parsed_response['answer'])\n",
    "        except Exception:\n",
    "            print(\"Error parsing response, displaying raw answer instead.\")\n",
    "            print(\"Raw Response:\\n\", response['answer'])\n",
    "        \n",
    "        print(\"\\nAgent: Do you have more questions?\")\n",
    "\n",
    "# Start the interactive chat\n",
    "interactive_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [00:53<00:00, 57.4MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " இப்போது புதிய அறிமுகம் அச்சி ஹோட்டல் சாம்பார் 50 கிராம் ரும்பாய் 20 மட்டுமே சென்னை பெருநகர் மற்றும் புரனகரில் சுமார் ஒரு மணி நேரமாக வெளித்து வாங்கும் கணமழை ராயப் பேட்டை, தியாகராய நகர், எழும்பூர், அண்ணாசாலை, அண்ணா நகர் meantime anchor உள்ளிட்ட பகுதிகளில் இடி மின்னவுடன் கொட்டி தீர்க்கும் கணமழை சென்னையில் மேற்கு அண்ணா நகர் பகுதியில் ஒரு மணி நேரத்துயில் 90 cómbing kindergarten அளவிருக்கு கணமழை பதிபு கொளத்தூர் பெரம்பூர் அம்பத்தூர் அமைந்தகரை ஆகிய இடங்கள் அதிக மழை பொழிவு எதிர்க்கொண்டதாக வானிலை மயம் தகவன் பசும்புன் முத்துராமலிங்க தேவரி 117. ஜெயன்தி மற்றும் 62. குருபுஜகி உட்டி முதல்மைச்சர் முக்கு ச்டாலின் மரியாது பசும்புன்னில் உள்ள தேவரி நினிவிடத்தில் மளர்த்தூபி சிலைக்கு மாலை நிவித்த மரியாதை சொல்றினார் பசும்புன்னில் தேவர் வாழ்ந்த இளம் புதுப்பிக்கப்பட்டு 100 ஆண்டு அலங்கाர வளைவு நினைவிடத்தில் அணயா விளக்கு அமைப்பு தேவர் ஜெயன்தியின் போது பசும்புன்னில் கூட நரிசலை தவிர்க தேவர் அரங்கம் திருக்கப்பட்டுள்ளதாக முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி பத்தன்புதாயிரம் கிலோ பட்டாசுகள் பரிவுது தீபாவலி பண்டிகைக்கு பட்டாசு விடிக்க தடி விடிக்கப்பட்டுள நிலையில் சேவித்து வைத்ததால் நடபிடிக்கு வண்ண மின்விளக்குகளால் ஒளிந்த அமரிகாவின் ஞூயார்க் நகரில் உள்ள உலக வர்த்தகமைய கட்டடம் தீபாவலியை உட்டி மின்விளக்குகளால் உலிரூட்டப்பட்ட அமரிகாவின் மிக உயரமான கட்டடம் தீபாவலியை உட்டி அமரிகாவின் ஞூயார்க் நகரில் உள்ள பள்ளிகளுக்கு நவம்பர் ஒண்ராம் தேதி விடுமுரை அறிவிப்ப confidential நியோ யார்க் நகர வரலாட்டில் முதன் முறையாக விடுமுறை அறிவிக்கப்படுவதாக நகரமேயிர் அலுவலகம் தகவுள் நியூஸிலாந்துக்கு எதிரான கடைசி ஒரு நாள் கிரிக்கெட் போட்டிகள் இந்திய மகலிரணி வெற்றி மூன்று போட்டிகள் கொண்ட தொடரை இரண்டுக்கு ஒன்று என்ற கணக்கில் வென்றது இந்தியா திருப்பத்தூர் மாவட்டம் ஆம்பூரருகே அரச தொடர்கப்பட்டி என்றuciónல NFT dzенного சதவிட்டதால் போய்ப்பட்ட<|az|> stata எல்லனும் அலேகம் பேருந்து உட்டுமல்்றும் ஏ öğசி நினைக்கள தீவிறக் கணக்கானிப்பில் ஆதிப commit அரைக்கோணம் ரைல் நிலையத்தில் சிங்ணல் கோலாரு காரணமாக சென்னை மார்க்கத்தில் மின்சார ரைல்கள் தாமதம் ஒரு மணி நேரத்திற்கு மேலாக தாமதமானதால் நிலைய மேலாளர் அளுவலகத்தை முற்றுகையிட்டு வாக்குவாதம் செய்த பயனிகள் அரசு பொக்குவரத்தக்கழகங்களில் גாOohy whilst an அரசு பொக்குவரத்தக்கழகங்களில் காலியாகவுள்ளு 2777 இடங்களை நிறப்பully ஆறப் 움ட்டு நzyst்ல்து Hills பணியாளர்கள் 637 பணியாளர்களை நிற הס்து நடபுடிக்கு ரசிகர் ரெனுகாஸ்வாமி கொலை விழக்கில் கண்ணட நடிகர் pentru இடைகால ஜாமின் ஜாமின்\n"
     ]
    }
   ],
   "source": [
    "# TAMIL TRANSCRIPTION GENERATION \n",
    "\n",
    "\n",
    "\"\"\" from whisper import load_model\n",
    "\n",
    "# Load the Whisper model\n",
    "model1 = load_model(\"large\")  # or use \"small\" or \"base\" for faster processing with lower accuracy\n",
    "\n",
    "\n",
    "# Transcribe the Tamil audio file\n",
    "result = model1.transcribe(\"audio_tamil.mp3\", language=\"ta\")\n",
    "transcription = result[\"text\"]\n",
    "\n",
    "print(transcription) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # to run it on CPU!\\n\\nimport yt_dlp\\n\\ndef download_audio(url):\\n    ydl_opts = {\\n        \\'format\\': \\'bestaudio/best\\',\\n        \\'postprocessors\\': [\\n            {\\n                \\'key\\': \\'FFmpegExtractAudio\\',\\n                \\'preferredcodec\\': \\'mp3\\',\\n                \\'preferredquality\\': \\'192\\',\\n            }\\n        ],\\n        \\'outtmpl\\': \\'audio.mp3\\',\\n        \\'ffmpeg_location\\': \\'C:/Users/KK/AppData/Local/ffmpeg-essentials_build/bin\\'  # Explicit path to ffmpeg\\n    }\\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\\n        ydl.download([url])\\n    return \\'audio.mp3\\'\\n\\n# Assuming transcribe_audio_with_whisper is a function that takes an audio path and transcribes it with Whisper\\nvideo_url = \"https://www.youtube.com/watch?v=RRk9QlCjul0\"\\naudio_path = download_audio(video_url)\\ntranscription = transcribe_audio_with_whisper(audio_path)\\nprint(transcription) '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # to run it on CPU!\n",
    "\n",
    "import yt_dlp\n",
    "\n",
    "def download_audio(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': 'audio.mp3',\n",
    "        'ffmpeg_location': 'C:/Users/KK/AppData/Local/ffmpeg-essentials_build/bin'  # Explicit path to ffmpeg\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return 'audio.mp3'\n",
    "\n",
    "# Assuming transcribe_audio_with_whisper is a function that takes an audio path and transcribes it with Whisper\n",
    "video_url = \"https://www.youtube.com/watch?v=RRk9QlCjul0\"\n",
    "audio_path = download_audio(video_url)\n",
    "transcription = transcribe_audio_with_whisper(audio_path)\n",
    "print(transcription) \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
