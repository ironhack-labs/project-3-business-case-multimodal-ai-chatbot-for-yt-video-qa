{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install pytube\\n!pip install openai-whisper\\n!pip install langchain\\n!pip install openai\\n!pip install python-dotenv '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install pytube\n",
    "!pip install openai-whisper\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install python-dotenv \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install -U langchain-community\\n!pip install pinecone-client\\n!pip install --upgrade pytube\\n!pip install yt-dlp\\n!pip install imageio[ffmpeg] '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install -U langchain-community\n",
    "!pip install pinecone-client\n",
    "!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "!pip install imageio[ffmpeg] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, torch\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load Environment Variable\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the environment variable directly in the script\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the environment variable with os.environ\n",
    "# print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install langsmith '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install langsmith \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Langsmith (make sure it's installed first)\n",
    "import langsmith  # Importing Langsmith's library\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"prj-yt-chatbot-qa\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter LANGCHAIN_API_KEY\")        # Authenticate with Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/8: https://www.youtube.com/watch?v=-RIfno4Sp0g\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=-RIfno4Sp0g\n",
      "[youtube] -RIfno4Sp0g: Downloading webpage\n",
      "[youtube] -RIfno4Sp0g: Downloading ios player API JSON\n",
      "[youtube] -RIfno4Sp0g: Downloading mweb player API JSON\n",
      "[youtube] -RIfno4Sp0g: Downloading player dad5a960\n",
      "[youtube] -RIfno4Sp0g: Downloading m3u8 information\n",
      "[info] -RIfno4Sp0g: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of   48.70MiB in 00:00:02 at 19.60MiB/s  \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 62.8MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed transcription for video 1\n",
      "Processing video 2/8: https://www.youtube.com/watch?v=3SCOVB1KDFc\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=3SCOVB1KDFc\n",
      "[youtube] 3SCOVB1KDFc: Downloading webpage\n",
      "[youtube] 3SCOVB1KDFc: Downloading ios player API JSON\n",
      "[youtube] 3SCOVB1KDFc: Downloading mweb player API JSON\n",
      "[youtube] 3SCOVB1KDFc: Downloading player 81ef9024\n",
      "[youtube] 3SCOVB1KDFc: Downloading m3u8 information\n",
      "[info] 3SCOVB1KDFc: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   54.16MiB in 00:00:05 at 9.54MiB/s     \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n",
      "Completed transcription for video 2\n",
      "Processing video 3/8: https://www.youtube.com/watch?v=qMqP2IwhSnA\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=qMqP2IwhSnA\n",
      "[youtube] qMqP2IwhSnA: Downloading webpage\n",
      "[youtube] qMqP2IwhSnA: Downloading ios player API JSON\n",
      "[youtube] qMqP2IwhSnA: Downloading mweb player API JSON\n",
      "[youtube] qMqP2IwhSnA: Downloading m3u8 information\n",
      "[info] qMqP2IwhSnA: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_2\n",
      "[download] 100% of   60.30MiB in 00:00:10 at 5.93MiB/s     \n",
      "[ExtractAudio] Destination: audio_2.mp3\n",
      "Deleting original file audio_2 (pass -k to keep)\n",
      "Completed transcription for video 3\n",
      "Processing video 4/8: https://www.youtube.com/watch?v=5u9jOA3LCdU\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=5u9jOA3LCdU\n",
      "[youtube] 5u9jOA3LCdU: Downloading webpage\n",
      "[youtube] 5u9jOA3LCdU: Downloading ios player API JSON\n",
      "[youtube] 5u9jOA3LCdU: Downloading mweb player API JSON\n",
      "[youtube] 5u9jOA3LCdU: Downloading m3u8 information\n",
      "[info] 5u9jOA3LCdU: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_3\n",
      "[download] 100% of   65.24MiB in 00:00:07 at 9.13MiB/s     \n",
      "[ExtractAudio] Destination: audio_3.mp3\n",
      "Deleting original file audio_3 (pass -k to keep)\n",
      "Completed transcription for video 4\n",
      "Processing video 5/8: https://www.youtube.com/watch?v=xeYEGePVaks\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xeYEGePVaks\n",
      "[youtube] xeYEGePVaks: Downloading webpage\n",
      "[youtube] xeYEGePVaks: Downloading ios player API JSON\n",
      "[youtube] xeYEGePVaks: Downloading mweb player API JSON\n",
      "[youtube] xeYEGePVaks: Downloading m3u8 information\n",
      "[info] xeYEGePVaks: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_4\n",
      "[download] 100% of   60.71MiB in 00:00:05 at 11.98MiB/s  \n",
      "[ExtractAudio] Destination: audio_4.mp3\n",
      "Deleting original file audio_4 (pass -k to keep)\n",
      "Completed transcription for video 5\n",
      "Processing video 6/8: https://www.youtube.com/watch?v=EGGUg054ciI\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=EGGUg054ciI\n",
      "[youtube] EGGUg054ciI: Downloading webpage\n",
      "[youtube] EGGUg054ciI: Downloading ios player API JSON\n",
      "[youtube] EGGUg054ciI: Downloading mweb player API JSON\n",
      "[youtube] EGGUg054ciI: Downloading m3u8 information\n",
      "[info] EGGUg054ciI: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_5\n",
      "[download] 100% of   63.79MiB in 00:00:07 at 8.79MiB/s   \n",
      "[ExtractAudio] Destination: audio_5.mp3\n",
      "Deleting original file audio_5 (pass -k to keep)\n",
      "Completed transcription for video 6\n",
      "Processing video 7/8: https://www.youtube.com/watch?v=3f1iv7nsIsA\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=3f1iv7nsIsA\n",
      "[youtube] 3f1iv7nsIsA: Downloading webpage\n",
      "[youtube] 3f1iv7nsIsA: Downloading ios player API JSON\n",
      "[youtube] 3f1iv7nsIsA: Downloading mweb player API JSON\n",
      "[youtube] 3f1iv7nsIsA: Downloading m3u8 information\n",
      "[info] 3f1iv7nsIsA: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_6\n",
      "[download] 100% of   51.37MiB in 00:00:12 at 4.09MiB/s     \n",
      "[ExtractAudio] Destination: audio_6.mp3\n",
      "Deleting original file audio_6 (pass -k to keep)\n",
      "Completed transcription for video 7\n",
      "Processing video 8/8: https://www.youtube.com/watch?v=WPSaiShNutU\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=WPSaiShNutU\n",
      "[youtube] WPSaiShNutU: Downloading webpage\n",
      "[youtube] WPSaiShNutU: Downloading ios player API JSON\n",
      "[youtube] WPSaiShNutU: Downloading mweb player API JSON\n",
      "[youtube] WPSaiShNutU: Downloading m3u8 information\n",
      "[info] WPSaiShNutU: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_7\n",
      "[download] 100% of   42.03MiB in 00:00:02 at 15.02MiB/s  \n",
      "[ExtractAudio] Destination: audio_7.mp3\n",
      "Deleting original file audio_7 (pass -k to keep)\n",
      "Completed transcription for video 8\n",
      "Consolidation Complete. Transcriptions are ready for vectorization and further processing.\n"
     ]
    }
   ],
   "source": [
    "# Sunday 3-Nov - FINAL!\n",
    "# STEP 1: Transcription and Consolidation Tasks (without agent to improve the process and reduce the time)\n",
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Default configurations\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}\"\n",
    "WHISPER_MODEL = \"base\"\n",
    "TRANSCRIPT_DIR = \"transcriptions\"\n",
    "\n",
    "# Ensure directory exists for transcriptions\n",
    "os.makedirs(TRANSCRIPT_DIR, exist_ok=True)\n",
    "\n",
    "# Load YouTube links from the file\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        return [link.strip() for link in file.readlines() if link.strip()]\n",
    "\n",
    "# Download audio from YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],\n",
    "        'outtmpl': f\"{output_name}\",\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return f\"{output_name}.mp3\"\n",
    "\n",
    "# Transcribe audio using Whisper\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Process each video, saving individual transcriptions\n",
    "def transcribe_all_videos():\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "    all_transcriptions = []\n",
    "\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        \n",
    "        # Transcribe in chunks to prevent reprocessing, saving each transcription file\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        transcript_file = os.path.join(TRANSCRIPT_DIR, f\"transcription_{i+1}.txt\")\n",
    "        \n",
    "        with open(transcript_file, 'w') as f:\n",
    "            f.write(transcription)\n",
    "        \n",
    "        all_transcriptions.append({\"title\": f\"Video {i+1}\", \"transcription\": transcription})\n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "\n",
    "    return all_transcriptions\n",
    "\n",
    "# Consolidate transcriptions for LLM analysis\n",
    "def consolidate_transcriptions():\n",
    "    consolidated_text = \"\"\n",
    "    for file in sorted(os.listdir(TRANSCRIPT_DIR)):\n",
    "        file_path = os.path.join(TRANSCRIPT_DIR, file)\n",
    "        \n",
    "        # Check if the file_path is a file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                consolidated_text += f.read() + \"\\n\"\n",
    "    return consolidated_text\n",
    "\n",
    "\n",
    "# Execute process\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe_all_videos()\n",
    "    consolidated_text = consolidate_transcriptions()\n",
    "    print(\"Consolidation Complete. Transcriptions are ready for vectorization and further processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/2334790274.py:14: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
      "/tmp/ipykernel_40/2334790274.py:15: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipykernel_40/2334790274.py:18: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete. Ready for storage in a vector database.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Chunk the consolidated text and Vectorization!\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# Split consolidated text into manageable chunks\n",
    "def split_text_for_vectorization(consolidated_text, max_tokens=1500):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=max_tokens, chunk_overlap=200)\n",
    "    return text_splitter.split_text(consolidated_text)\n",
    "\n",
    "# Function to perform vectorization on each chunk\n",
    "def perform_vectorization_task(consolidated_text):\n",
    "    chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    memory = ConversationBufferMemory()\n",
    "    \n",
    "    # Initialize the embedding model and the agent with vectorization tool\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    chunks = split_text_for_vectorization(consolidated_text)\n",
    "    \n",
    "    vectorized_segments = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # print(f\"Vectorizing chunk {i+1}/{len(chunks)}\")\n",
    "        \n",
    "        # Generate embeddings for this chunk\n",
    "        embeddings = embedding_model.embed_documents([chunk])\n",
    "        \n",
    "        # Store each embedding\n",
    "        vectorized_segments.append({\n",
    "            \"id\": f\"segment_{i}\",\n",
    "            \"text\": chunk,\n",
    "            \"embedding\": embeddings[0]  # embedding_model.embed_documents returns a list\n",
    "        })\n",
    "\n",
    "    print(\"Vectorization complete. Ready for storage in a vector database.\")\n",
    "    return vectorized_segments\n",
    "\n",
    "# Run vectorization task after consolidation\n",
    "if __name__ == \"__main__\":    \n",
    "    vectorized_segments = perform_vectorization_task(consolidated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - define Pinecone as Vector DB & Define Index & Embeddings.\n",
    "\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely fetch Pinecone API keys                    \n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ[\"PINECONE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index statistics: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Create INDEX using EMBEDDINGS OpenAI-ada-002 - creating the Index for 'Accenture Earnings'\n",
    "\n",
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize OpenAI embeddings model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Initialize Pinecone client with the updated API\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "#spec = ServerlessSpec(cloud=\"aws\", region=\"us-west-1\")  # Specify Pinecone environment\n",
    "index_name = \"transcription-accnt-earn-index-2years\"             # Create New Index\n",
    "\n",
    "# Check if the index exists; create if it doesn’t\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI embedding dimension\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for the index to be ready\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        print(\"Waiting for index to be ready...\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for upsertion\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "print(\"Index statistics:\", index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542ccdc6a78f4d0983efa4cfc1cdc994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments upserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5 - UPSERT embeddings to Pinecone in batches\n",
    "\n",
    "batch_size = 50\n",
    "for i in tqdm(range(0, len(vectorized_segments), batch_size)):\n",
    "    batch = vectorized_segments[i:i + batch_size]\n",
    "    ids = [segment[\"id\"] for segment in batch]\n",
    "    embeds = [segment[\"embedding\"] for segment in batch]\n",
    "    metadatas = [{\"text\": segment[\"text\"]} for segment in batch]\n",
    "\n",
    "    # Upsert each batch to Pinecone\n",
    "    try:\n",
    "        index.upsert(vectors=list(zip(ids, embeds, metadatas)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error upserting batch {i // batch_size + 1}: {e}\")\n",
    "\n",
    "print(\"All segments upserted into Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index statistics: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 349}},\n",
      " 'total_vector_count': 349}\n"
     ]
    }
   ],
   "source": [
    "print(\"Index statistics:\", index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the revenue of Accenture last quarter?\n",
      "Routed to: vectorstore\n",
      "\n",
      "Query: What is the EPS for last quarter?\n",
      "Routed to: vectorstore\n",
      "\n",
      "Query: What is the total no of employee count in Accenture company?\n",
      "Routed to: vectorstore\n",
      "\n",
      "Query: Who are the competitors of Accenture?\n",
      "Routed to: websearch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define ROUTER for query to be passed to VectorDB or Websearch (google search) -  Example to demonstrate\n",
    "\n",
    "\"\"\" import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize LLM in JSON mode (replace 'gpt-3.5-turbo' with any model configured for JSON output)\n",
    "llm_json_mode = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Define the routing instructions\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to Accenture company Earnings results, Revenue, Earnings for last four quarters, sales, cloud projects, Genai projects and employee details.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with a single key, \"datasource\", that is either 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Function to route based on the instructions\n",
    "def route_query(query):\n",
    "    routing_response = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=router_instructions), HumanMessage(content=query)]\n",
    "    )\n",
    "    route_decision = json.loads(routing_response.content)\n",
    "    return route_decision[\"datasource\"]\n",
    "\n",
    "# Example queries to test the router\n",
    "test_queries = [\n",
    "    \"What is the revenue of Accenture last quarter?\",\n",
    "    \"What is the EPS for last quarter?\",\n",
    "    \"What is the total no of employee count in Accenture company?\",\n",
    "    \"Who are the competitors of Accenture?\",\n",
    "]\n",
    "\n",
    "# Execute the router on test queries\n",
    "for query in test_queries:\n",
    "    datasource = route_query(query)\n",
    "    print(f\"Query: {query}\\nRouted to: {datasource}\\n\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-search-results\n",
    "\n",
    "## !pip install tavily-python (not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "#os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\") or getpass.getpass(\"Enter Tavily API key: \")\n",
    "\n",
    "# Fetch the SerpAPI key securely\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\") or getpass.getpass(\"Enter SerpAPI key: \")\n",
    "\n",
    "# Example usage in SerpAPI tool setup\n",
    "serp_api_key = os.environ[\"SERPAPI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ[\"SERPAPI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3440100285.py:20: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing to Vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3440100285.py:42: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Accenture's revenue last quarter was $16.4 billion.\n",
      "Routing to Vectorstore...\n",
      "Response: The EPS of Accenture last quarter was $3.19.\n",
      "Routing to Vectorstore...\n",
      "Response: The change in Revenue between Fourth and Third quarters was an increase.\n",
      "Routing to Web Search...\n",
      "Response: The main competitors of Accenture in the consulting industry include IBM, PwC, Tata Consultancy Services (TCS), Capgemini, Deloitte, Cognizant, SAP, DXC Technology, McKinsey & Co., Boston Consulting Group, Inc., and Bain & Co.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE ROUTER, RETRIEVE from VectorstoreDB and Retrieve from Google search functions!\n",
    "\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "import os\n",
    "\n",
    "# Initialize the embedding model and vector store\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "#from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "# Assuming Pinecone index is already set up and embeddings are upserted\n",
    "vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "\n",
    "# Initialize the router instructions\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to Accenture company Quarterly results, Revenue, Earnings for the last four quarters, sales, digital projects, cloud projects and employee details.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with a single key, \"datasource\", that is either 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Function to route query based on instructions\n",
    "def route_query(query):\n",
    "    routing_response = chat_model.invoke(\n",
    "        [SystemMessage(content=router_instructions), HumanMessage(content=query)]\n",
    "    )\n",
    "    route_decision = json.loads(routing_response.content)\n",
    "    return route_decision[\"datasource\"]\n",
    "\n",
    "# Function to retrieve from vector database\n",
    "def retrieve_from_vectorstore(query):\n",
    "    retriever = vector_store.as_retriever()\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    document_text = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "    # Summarize the retrieved documents using LLM \n",
    "    prompt = (\n",
    "        \"Based on the following documents, provide a concise answer to the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Documents:\\n\"\n",
    "        f\"{document_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    \n",
    "    answer_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return answer_response.content\n",
    "    # return \"\\n\\n\".join([doc.page_content for doc in results]) # can be removed if this modules functions right!\n",
    "\n",
    "# Function to retrieve from Google search using SerpaAPI\n",
    "def web_search(query):\n",
    "    search = GoogleSearch({\n",
    "        \"q\": query,\n",
    "        \"api_key\": serp_api_key, \n",
    "        \"num\": 3  # Limit to top 3 results for conciseness\n",
    "    })\n",
    "    results = search.get_dict()\n",
    "\n",
    "    # Extract relevant text from search results\n",
    "    combined_text = \"\\n\".join(\n",
    "        result.get(\"snippet\", \"No snippet available\")\n",
    "        for result in results.get(\"organic_results\", [])\n",
    "    )\n",
    "    \n",
    "    # Summarize results using the LLM\n",
    "    prompt = (\n",
    "        f\"Summarize the following search results to answer the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Results:\\n{combined_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    summary_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return summary_response.content\n",
    "\n",
    "\n",
    "# Function to perform web search (e.g., using Tavily - NOT USING IT)\n",
    "\"\"\" def web_search(query):\n",
    "    # Fetch results using Tavily\n",
    "    results = web_search_tool.run(query)\n",
    "    print(\"Results:\", results)  # Inspect the structure\n",
    "    combined_text = \"\\n\".join(result.get('text', 'No text available') for result in results if 'text' in result)\n",
    "\n",
    "    # Summarize results if multiple documents are returned\n",
    "    prompt = (\n",
    "        f\"Summarize the following web search results to answer the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Results:\\n{combined_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    summary_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return summary_response.content \"\"\"\n",
    "    \n",
    "\n",
    "# Main function to handle the query routing and retrieval\n",
    "def handle_query(query):\n",
    "    datasource = route_query(query)\n",
    "    \n",
    "    if datasource == \"vectorstore\":\n",
    "        print(\"Routing to Vectorstore...\")\n",
    "        return retrieve_from_vectorstore(query)\n",
    "    elif datasource == \"websearch\":\n",
    "        print(\"Routing to Web Search...\")\n",
    "        return web_search(query)\n",
    "    else:\n",
    "        return \"Unknown data source. Please check the router configuration.\"\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the revenue of Accenture last quarter??\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"What is the EPS of Accenture last quarter?\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"What is the change in Revenue between Fourth and Third quarters?\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"Who is the main competitor of Accenture?\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Control the recursive depth to avoid Web_search error\\n\\nimport sys\\nsys.setrecursionlimit(2000)  # Limit to a reasonable depth '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Control the recursive depth to avoid Web_search error\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(2000)  # Limit to a reasonable depth \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/1385710895.py:33: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  react_agent = initialize_agent(\n",
      "/tmp/ipykernel_40/1385710895.py:44: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = react_agent({\"input\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should start by using the VectorStore Retrieval tool to see if there is specific information on Accenture's revenue for the fourth quarter of 2024. If I don't find anything, I can use Google Search to look for recent financial reports or news articles.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture revenue Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe revenue for Accenture in Q4 2024 is $65 billion, representing 2% growth in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should also verify this information by using Google Search to see if there are any recent news articles or official reports confirming this revenue figure.\n",
      "Action: Google Search\n",
      "Action Input: Accenture Q4 2024 revenue\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture's Q4 2024 revenue was $16.41 billion.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe information from the VectorStore Retrieval seems to be inaccurate. I should rely on the Google Search result for the most up-to-date revenue figure.\n",
      "Final Answer: Accenture's revenue for the fourth quarter of 2024 was $16.41 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Accenture's revenue for the fourth quarter of 2024 was $16.41 billion.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question is specific to Accenture's projects, so I should use VectorStore Retrieval to find relevant information.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture Genai project deals size 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture's Gen AI project is expected to experience significant growth in 2024, with $450 million in sales and two billion dollars in sales year to date. The company is focused on transitioning clients from experimentation to scale with Gen AI, positioning themselves as leaders in this transformative technology. Additionally, Accenture has invested in expanding their workforce in data and AI, reaching approximately 57,000 practitioners, with a goal of 80,000 by the end of FY26. Their talent strategy includes investing in training and fostering a diverse and inclusive workplace, leading to global recognition for diversity and inclusion. The company has also made strategic acquisitions to expand into new growth areas and continue to build strength in industry and functional consulting.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe information provided includes details on Accenture's Genai project deals for 2024.\n",
      "Final Answer: Accenture's Genai project deals size for 2024 is expected to be $450 million.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Accenture's Genai project deals size for 2024 is expected to be $450 million.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information on Accenture's earnings in the third quarter of 2023.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture earnings Q3 2023\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture expects revenues for the third quarter of fiscal 2023 to be in the range of 16.1 billion to 16.7 billion with an estimated 3-7% growth in local currency. For the full fiscal year 2023, they anticipate revenue growth of 8-10% in local currency, with an inorganic contribution of 2%. They also expect business optimization actions to impact fiscal 2023 gap operating margins by 120 basis points. Additionally, they have positioned themselves for strong growth in fiscal year 2025 and are focusing on being a leading trusted AI partner for enterprises.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe EPS information was not directly provided in the observation, I should try a different approach.\n",
      "Action: Google Search\n",
      "Action Input: Accenture EPS Q3 2023\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn the third quarter of fiscal 2023, Accenture reported adjusted EPS of $3.13, a decrease of 2% from the previous quarter. New bookings for the quarter were $21.1 billion.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the EPS information for Accenture in the third quarter of 2023.\n",
      "Final Answer: The EPS of Accenture in the third quarter of 2023 was $3.13.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: The EPS of Accenture in the third quarter of 2023 was $3.13.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE ALL THE TOOLS for ReACT agent! No CHATBOT YET!\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "from langchain.agents import initialize_agent\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Define the Web search tool using SerpAPI\n",
    "web_search_tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    func=web_search,\n",
    "    description=\"Retrieve relevant information using google web search for general or current event questions.\"\n",
    ")\n",
    "\n",
    "# Define tool for vector store retrieval\n",
    "vector_store_tool = Tool(\n",
    "    name=\"VectorStore Retrieval\",\n",
    "    func=retrieve_from_vectorstore,\n",
    "    description=\"Retrieve relevant documents from the vector store for questions about Accenture's earnings, revenue, sales, projects, and employee details.\",\n",
    ")\n",
    "\n",
    "\"\"\" # Define tool for web search (Tavily - not Using it!)\n",
    "web_search_tool = Tool(\n",
    "    name=\"Web Search Retrieval\",\n",
    "    func=web_search,\n",
    "    description=\"Retrieve information using Tavily web search for general or current event questions not covered in the vector store, particularly about competitors or industry updates.\",\n",
    ")\n",
    " \"\"\"\n",
    "# Initialize the ReAct agent with both tools\n",
    "react_agent = initialize_agent(\n",
    "    tools=[vector_store_tool, web_search_tool],\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    llm=chat_model,\n",
    "    verbose=True,\n",
    "    max_iterations=3  # Restrict maximum depth to avoid infinite loops\n",
    ")\n",
    "\n",
    "# Main function to handle the query using the ReAct agent\n",
    "def handle_query_with_agent(query):\n",
    "    # Call the ReAct agent with the query; it will decide which tool to use\n",
    "    response = react_agent({\"input\": query})\n",
    "    return response[\"output\"]\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the revenue of Accenture fourth quarter of 2024?\"\n",
    "response = handle_query_with_agent(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"What is the size of Genai project deals for Accenture in year 2024??\"\n",
    "response = handle_query_with_agent(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"What is the EPS of Accenture in third quarter 2023?\"\n",
    "response = handle_query_with_agent(query)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Accenture Q&A Chatbot! Ask any question about Accenture.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the VectorStore Retrieval tool to find information on Accenture's earnings.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture EPS second quarter 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn the second quarter of fiscal 2024, Accenture reported adjusted earnings per share of $11.67, reflecting a 9% growth over the previous year. The company also exceeded its original guidance for capital allocation by returning $7.2 billion of cash to shareholders and investing approximately $2.5 billion across 25 acquisitions. Additionally, Accenture remains committed to delivering shareholder value and creating value for all stakeholders.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: In the second quarter of 2024, Accenture reported adjusted earnings per share of $11.67.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent: Error parsing response JSON, displaying raw answer instead.\n",
      "Agent (using VectorDB): In the second quarter of 2024, Accenture reported adjusted earnings per share of $11.67.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Agent: Thank you for using the Q&A chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# INTERACTIVE CHAT FUNCTION using ReACT Agent - REFINED 3! Works perfect! TUESDAY\n",
    "\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Initialize chat model and memory\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Interactive chat function with datasource-based source tagging\n",
    "def chatbot_interaction():\n",
    "    print(\"Welcome to the Accenture Q&A Chatbot! Ask any question about Accenture.\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"no\"]:\n",
    "            print(\"Agent: Thank you for using the Q&A chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Determine the datasource\n",
    "        datasource = route_query(user_query)\n",
    "        \n",
    "        # Tag source based on datasource\n",
    "        source_label = \"VectorDB\" if datasource == \"vectorstore\" else \"Google Search\" if datasource == \"websearch\" else \"Unknown Source\"\n",
    "        \n",
    "        try:\n",
    "            # Get response from ReAct agent\n",
    "            response = react_agent({\"input\": user_query})\n",
    "            \n",
    "            # Parse and display response with source tag\n",
    "            if \"output\" in response and isinstance(response[\"output\"], str):\n",
    "                try:\n",
    "                    parsed_response = json.loads(response[\"output\"])\n",
    "                    answer = parsed_response.get(\"answer\", response[\"output\"])\n",
    "                    print(f\"\\nAgent (using {source_label}):\\nQuestion: {user_query}\\nAnswer: {answer}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Agent: Error parsing response JSON, displaying raw answer instead.\")\n",
    "                    print(f\"Agent (using {source_label}): {response['output']}\")\n",
    "            else:\n",
    "                print(\"Agent: Unable to process the request in the expected format. Please try again.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}\")\n",
    "            print(\"Agent: Unable to process the request. Please try again.\")\n",
    "        \n",
    "        print(\"\\nAgent: Do you have more questions?\")\n",
    "\n",
    "# Start the chatbot interaction\n",
    "chatbot_interaction()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://25b2cc2a541bd76cc9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://25b2cc2a541bd76cc9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find specific financial information for Accenture's revenue in the second quarter of 2023.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture revenue Q2 2023\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Q2 2023, Accenture expects revenues to be in the range of 16.1 billion to 16.7 billion, with an estimated 3 to 7% growth in local currency. For the full fiscal year 23, Accenture expects revenue to be in the range of 8 to 10% growth in local currency, with an inorganic contribution of 2%.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe revenue in the second quarter of 2023 for Accenture is estimated to be in the range of 16.1 billion to 16.7 billion, with an estimated growth of 3 to 7% in local currency.\n",
      "Final Answer: The revenue in the second quarter of 2023 for Accenture is estimated to be in the range of 16.1 billion to 16.7 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# GRADIO only with TEXT - REFINED! Works Perfect!\n",
    "\n",
    "import json\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "def gradio_chatbot(user_query):\n",
    "    # Determine the source using the routing function\n",
    "    datasource = route_query(user_query)\n",
    "    \n",
    "    # Tag source based on the datasource returned\n",
    "    source_label = \"VectorDB\" if datasource == \"vectorstore\" else \"Google Search\" if datasource == \"websearch\" else \"Unknown Source\"\n",
    "    \n",
    "    try:\n",
    "        # Get response from the ReAct agent\n",
    "        response = react_agent({\"input\": user_query})\n",
    "\n",
    "        # Check if the response is not empty and parse the response JSON if possible\n",
    "        if response and \"output\" in response:\n",
    "            output_content = response[\"output\"]\n",
    "            \n",
    "            # Attempt to parse JSON response if available\n",
    "            try:\n",
    "                parsed_response = json.loads(output_content) if isinstance(output_content, str) else output_content\n",
    "                answer = parsed_response.get(\"answer\", output_content) if isinstance(parsed_response, dict) else output_content\n",
    "            except json.JSONDecodeError:\n",
    "                answer = output_content  # Fallback to raw output if JSON parsing fails\n",
    "\n",
    "            return f\"Answer (from {source_label}):\\n{answer}\"\n",
    "\n",
    "        else:\n",
    "            return \"Error: Received an empty or unexpected response format from the agent.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capture any other errors\n",
    "        return f\"Error encountered: {str(e)}\"\n",
    "\n",
    "# Create the Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_chatbot,  # Function to call\n",
    "    inputs=\"text\",      # Input type: text\n",
    "    outputs=\"text\",     # Output type: text\n",
    "    title=\"Accenture Q&A Chatbot\",\n",
    "    description=\"Ask any question about Accenture and get answers with sourced information.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 21:32:12.617819: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-05 21:32:12.617915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-05 21:32:12.619119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 21:32:12.626330: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-05 21:32:13.853070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# GISKARD EVALUATION BELOW !!!\n",
    "\n",
    "#!pip install --default-timeout=100 \"giskard[llm]\"\n",
    "from giskard.rag import KnowledgeBase, generate_testset, evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing to Vectorstore...\n",
      "Routing to Web Search...\n",
      "Routing to Web Search...\n",
      "Routing to Web Search...\n",
      "Routing to Web Search...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The revenue of Accenture in the fourth quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The main competitors of Accenture in the consu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture booked $900 million in generative AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture has approximately 774,000 employees ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The revenue of Accenture in the fourth quarter...\n",
       "1  The EPS of Accenture in the fourth quarter of ...\n",
       "2  The main competitors of Accenture in the consu...\n",
       "3  Accenture booked $900 million in generative AI...\n",
       "4  Accenture has approximately 774,000 employees ..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the sample questions to test with `handle_query`\n",
    "# Define the list of queries to retrieve answers for\n",
    "queries = [\n",
    "    \"What is the revenue of Accenture in fourth quarter of 2024?\",\n",
    "    \"What is the EPS of Accenture in fourth quarter of 2024?\",\n",
    "    \"Who is the main competitor of Accenture?\",\n",
    "    \"What is the size of Genai project deals for Accenture in year 2024?\",\n",
    "    \"How many employees does Accenture have worldwide?\"\n",
    "]\n",
    "\n",
    "# Collect answers by running each query through the handle_query function\n",
    "answers = [handle_query(query) for query in queries]\n",
    "\n",
    "# Create a DataFrame with only the answers\n",
    "df_giskard = pd.DataFrame(answers, columns=[\"text\"])\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "df_giskard.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KNOWLEDGEBASE for Giskard\n",
    "\n",
    "kb_giskard = KnowledgeBase(df_giskard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ecafd9b4e84b4e95f9f9c832e0a9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating questions:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Question using Giskard\n",
    "\n",
    "test_questions = generate_testset(\n",
    "    kb_giskard,\n",
    "    num_questions=15,\n",
    "    agent_description=\"Accenture Q&A chat assistant related to Quarterly Earnings, and general information like competition.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_context</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d4a08da1-e913-47b1-9bf4-f6ba5ca90504</th>\n",
       "      <td>Who are the main competitors of Accenture in t...</td>\n",
       "      <td>The main competitors of Accenture in the consu...</td>\n",
       "      <td>Document 2: The main competitors of Accenture ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad126300-2c0e-4fef-bcdd-27a539d7f4f6</th>\n",
       "      <td>What was the EPS of Accenture in the fourth qu...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 1: The EPS of Accenture in the fourth...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faeb8cd3-8366-4673-81d7-c8bea9b4804c</th>\n",
       "      <td>How much did Accenture book in generative AI b...</td>\n",
       "      <td>Accenture booked $900 million in generative AI...</td>\n",
       "      <td>Document 3: Accenture booked $900 million in g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05cdb12f-d525-4922-a74b-7e9fe7a2b2b2</th>\n",
       "      <td>Could you provide me with the Earnings Per Sha...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 0: The revenue of Accenture in the fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732e0592-6400-4d39-b611-812f7de43aa2</th>\n",
       "      <td>Could you provide me with the anticipated rang...</td>\n",
       "      <td>The expected revenue of Accenture in the fourt...</td>\n",
       "      <td>Document 0: The revenue of Accenture in the fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               question  \\\n",
       "id                                                                                        \n",
       "d4a08da1-e913-47b1-9bf4-f6ba5ca90504  Who are the main competitors of Accenture in t...   \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  What was the EPS of Accenture in the fourth qu...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  How much did Accenture book in generative AI b...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  Could you provide me with the Earnings Per Sha...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  Could you provide me with the anticipated rang...   \n",
       "\n",
       "                                                                       reference_answer  \\\n",
       "id                                                                                        \n",
       "d4a08da1-e913-47b1-9bf4-f6ba5ca90504  The main competitors of Accenture in the consu...   \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  The EPS of Accenture in the fourth quarter of ...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  Accenture booked $900 million in generative AI...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  The EPS of Accenture in the fourth quarter of ...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  The expected revenue of Accenture in the fourt...   \n",
       "\n",
       "                                                                      reference_context  \\\n",
       "id                                                                                        \n",
       "d4a08da1-e913-47b1-9bf4-f6ba5ca90504  Document 2: The main competitors of Accenture ...   \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  Document 1: The EPS of Accenture in the fourth...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  Document 3: Accenture booked $900 million in g...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  Document 0: The revenue of Accenture in the fo...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  Document 0: The revenue of Accenture in the fo...   \n",
       "\n",
       "                                     conversation_history  \\\n",
       "id                                                          \n",
       "d4a08da1-e913-47b1-9bf4-f6ba5ca90504                   []   \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6                   []   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c                   []   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2                   []   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2                   []   \n",
       "\n",
       "                                                                               metadata  \n",
       "id                                                                                       \n",
       "d4a08da1-e913-47b1-9bf4-f6ba5ca90504  {'question_type': 'simple', 'seed_document_id'...  \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  {'question_type': 'simple', 'seed_document_id'...  \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  {'question_type': 'simple', 'seed_document_id'...  \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  {'question_type': 'complex', 'seed_document_id...  \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  {'question_type': 'complex', 'seed_document_id...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_questions = test_questions.to_pandas()\n",
    "df_test_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_agent(question, history=None):\n",
    "    response = react_agent({\"input\": question}) # Call the react_agent with question input\n",
    "    return response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48abff95966f4ba4b457084902931413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Asking questions to the agent:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Google Search to find this information.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture main competitors in consulting industry\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture's main competitors in the consulting industry include Infosys, IBM, PwC, Tata Consultancy Services (TCS), Capgemini, Deloitte, Cognizant, SAP, DXC Technology, McKinsey & Co., Boston Consulting Group, Inc., and Bain & Co.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the list of Accenture's main competitors in the consulting industry.\n",
      "Final Answer: Accenture's main competitors in the consulting industry include Infosys, IBM, PwC, Tata Consultancy Services (TCS), Capgemini, Deloitte, Cognizant, SAP, DXC Technology, McKinsey & Co., Boston Consulting Group, Inc., and Bain & Co.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information about Accenture's earnings.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture earnings fourth quarter 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong results for the 4th quarter fiscal 2023, with $65 billion in revenue and significant growth in bookings. They are well positioned for growth in FY25. They expect revenues for the 3rd quarter fiscal 2024 to be in the range of $16.1 billion to $16.7 billion, with estimated 3 to 7% growth in local currency. They expect the impact of foreign exchange rates to be approximately negative 4.5% compared to fiscal 22 for the full fiscal year 2024, with revenue expected to be in the range of 8 to 10% growth in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try a more specific query to find the EPS for the fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture EPS fourth quarter 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the documents provided, Accenture is expecting revenue growth in the range of 8 to 9% in local currency for the full fiscal year 2023. They also expect business optimization actions to impact fiscal 23 gap operating margins by 120 basis points.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Google Search to see if there's any specific information available about Accenture's EPS in the fourth quarter of 2024.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture EPS fourth quarter 2024\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture reported adjusted EPS of $2.79 for the fourth quarter of fiscal year 2024, representing a 3% increase over the previous year.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information about Accenture's generative AI business in Q3 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture generative AI business Q3 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture's generative AI business in Q3 2024 continues to show strong growth and investment. They are working with clients in various industries to implement generative AI solutions to improve customer service, streamline operations, and drive audience engagement. Accenture is positioning itself as a leader in generative AI, with a significant investment of $3 billion to accelerate their clients' reinvention journey. They are focusing on helping clients realize value at scale in 2024 through the customization and management of foundation models to deliver personalization and business relevance. Furthermore, Accenture is leading with responsible AI to ensure their clients mitigate risks while driving value.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know that Accenture invested $3 billion in their generative AI business during Q3 2024.\n",
      "Final Answer: Accenture booked $3 billion in generative AI business during Q3 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find the EPS figure for Accenture during the final quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture EPS Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe EPS for Q4 2024 is expected to be $11.67, reflecting a 9% growth over the EPS for FY22.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the EPS figure for Accenture during the final quarter of 2024.\n",
      "Final Answer: The EPS for Accenture during the final quarter of 2024 is $11.67.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to get the information on Accenture's earnings projections for the last quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture earnings projections Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture projects revenue growth of 8 to 9% in local currency for fiscal year 2023, with an inorganic contribution of 2%. They also expect a negative impact of 4% from foreign exchange rates compared to fiscal year 2022. Additionally, they anticipate business optimization costs of 800 million in fiscal year 2023.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the information on Accenture's earnings projections for Q4 2024.\n",
      "Final Answer: Accenture is projected to generate revenue growth of 8 to 9% in local currency for the last quarter of 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should start by searching for information on Accenture's generative AI business revenue during the third quarter of fiscal year 2024.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture generative AI business revenue Q3 2024\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture achieved $2 billion in Generative AI sales year-to-date and $500 million in revenue for the quarter. Generative AI revenue for the fiscal year stood at $900 million, compared to $100 million the previous year.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the revenue information for Accenture's generative AI business during the third quarter of fiscal year 2024.\n",
      "Final Answer: The recorded revenue for Accenture's generative AI business during the third quarter of fiscal year 2024 was $500 million.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe need specific financial data for Accenture in the fourth quarter of 2024 and its competitors in the consulting industry.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture Q4 2024 EPS, consulting industry competitors\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong growth in FY25, with significant investments in transformative technologies like Gen AI. The company doubled down on its strategy to be the reinvention partner for clients, resulting in full fiscal year bookings of $81 billion. Despite declines in consulting revenues, Accenture extended its leadership position in the market, with growth estimated to be about two times the market average. The company also exceeded its original guidance for capital allocation, returning $7.2 billion to shareholders and investing in 25 acquisitions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe provided information is about Accenture's overall performance in FY25, not specifically about EPS in Q4 2024. Let's try to refine the query.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture Q4 2024 EPS compared to consulting industry competitors\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture's Q4 2024 EPS outperformed its consulting industry competitors, with adjusted earnings per share of $11.67 reflecting 9% growth over the previous year. Additionally, Accenture's revenue grew by 4% in local currency, driven by growth in several industries. Despite declines in consulting and minus services revenues, Accenture extended its leadership position with estimated growth two times the market average compared to its competitors.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information retrieved, Accenture's EPS in the fourth quarter of 2024 outperformed its main competitors in the consulting industry.\n",
      "Final Answer: Accenture's EPS in the fourth quarter of 2024 was $11.67, reflecting 9% growth over the previous year and outperforming its main competitors in the consulting industry.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information on Accenture's earnings for the fourth quarter of 2024 and compare it to its competitors in the consulting industry.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture earnings fourth quarter 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong results for the fourth quarter of fiscal 2023, with significant growth in bookings and revenues. The company is well positioned for growth in fiscal year 2025, with a focus on large-scale transformations and deep client relationships. They expect continued growth in revenues and operating margins for the full fiscal year 2023, driven by market demand and business optimization actions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need more specific information on the EPS for the fourth quarter of 2024 to compare it to competitors.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture EPS fourth quarter 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe EPS for the fourth quarter of 2024 for Accenture is not provided in the given documents.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should now search for the EPS of Accenture in the fourth quarter of 2024 and compare it to its main competitors in the consulting industry.\n",
      "Action: Google Search\n",
      "Action Input: Accenture EPS fourth quarter 2024 comparison competitors consulting industry\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn the fourth quarter of 2024, Accenture's consulting revenues were $8.26 billion, with a 1% increase in U.S. dollars and a 3% increase in local currency compared to the previous year. Overall, Accenture recorded revenue growth across most segments and geographies in Q4.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find out information about Accenture's earnings and revenue for the fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture earnings and revenue Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Q4 2024, Accenture expects revenues to be in the range of 15.75 billion to 16.35 billion, with an estimated 2% to 6% growth in local currency. For the full fiscal year 2024, they anticipate revenue growth of 8 to 9% in local currency over fiscal 2023. They also expect business optimization actions to impact operating margins by 120 basis points in fiscal 2024.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to calculate the EPS based on the revenue range provided.\n",
      "Action: Calculation\n",
      "Action Input: Using the revenue range of $15.85 billion to $16.45 billion and the estimated impact of business optimization actions on operating margins by 120 basis points\u001b[0m\n",
      "Observation: Calculation is not a valid tool, try one of [VectorStore Retrieval, Google Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should use a financial formula to calculate EPS based on the revenue range provided.\n",
      "Action: Google Search\n",
      "Action Input: How to calculate EPS based on revenue range\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mTo calculate EPS based on revenue range, divide the company's net income by the total number of outstanding shares. EPS is a measure of profitability.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Google Search to find a list of main competitors in the consulting industry.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture main competitors in consulting industry\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture's main competitors in the consulting industry include Infosys, IBM, PwC, Tata Consultancy Services, Capgemini, Deloitte, Cognizant, SAP, and DXC Technology. Additionally, the \"Big Three\" consulting firms McKinsey & Co., Boston Consulting Group, Inc., and Bain & Co. are also major competitors.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the main competitors of Accenture in the consulting industry.\n",
      "Final Answer: The main competitors of Accenture in the consulting industry include Infosys, IBM, PwC, Tata Consultancy Services, Capgemini, Deloitte, Cognizant, SAP, DXC Technology, McKinsey & Co., Boston Consulting Group, Inc., and Bain & Co.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information about Accenture's earnings in the fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture fourth quarter 2024 earnings\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong results for the 4th quarter of fiscal 2023 with record bookings of $72 billion and revenues of $64 billion. They also announced a revenue growth expectation of 8-10% in local currency for fiscal 2023. Additionally, they highlighted their significant investments in technology, particularly in Gen AI, positioning them for strong growth in fiscal year 2025.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the specific EPS for Accenture in the fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture fourth quarter 2024 EPS\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture's fourth quarter 2024 EPS was $11.67, reflecting a 9% growth over the previous year.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the EPS for Accenture in the fourth quarter of 2024.\n",
      "Final Answer: Accenture's EPS in the fourth quarter of 2024 was $11.67.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find specific financial details about Accenture's fourth-quarter revenue and EPS.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture fourth quarter 2024 revenue and EPS\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported a 4th quarter fiscal 2023 revenue of $16.1 billion to $16.7 billion, with an expected 8 to 10% growth in local currency over fiscal 2022. Adjusted earnings per share was $11.67, reflecting 9% growth over fiscal year 2022 EPS.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the specific revenue range and EPS growth for Accenture's fourth quarter of 2024.\n",
      "Final Answer: The expected revenue range is $16.1 billion to $16.7 billion, with an EPS of $11.67 for the fourth quarter of 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need specific financial data for Accenture's generative AI business in Q3 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture generative AI business Q3 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture has made significant investments in generative AI, positioning itself as a leader in the technology. They have successfully sold over 100 generative AI projects in the last four months and are focused on helping clients realize value at scale in 2024. The company is working with clients across various industries, such as insurance and broadcasting, to improve customer service, simplify operations, and drive audience engagement using generative AI solutions. Additionally, Accenture is investing $3 billion in AI over three years and expanding their workforce to 80,000 strong to accelerate clients' reinvention journey.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the specific financial data regarding Accenture's generative AI business in Q3 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture generative AI business revenue Q3 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the provided documents, Accenture's generative AI business revenue for Q3 2024 is expected to continue growing as demand for generative AI services accelerates. The company has invested significantly in generative AI and is focused on helping clients realize value at scale in 2024 through specialized services and customization of foundation models. Accenture's early leadership position in generative AI, along with its strong digital engineering capabilities, positions it well to capitalize on the ongoing tech revolution and the opportunities presented by the metaverse.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the total amount booked during the fiscal year for Accenture's generative AI business.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture generative AI business total revenue fiscal year 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe documents do not provide specific information about Accenture's generative AI business total revenue for fiscal year 2024.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Google Search to find information on Accenture's main competitors.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture main competitors\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSome of Accenture's main competitors include IBM, PwC, Tata Consultancy Services, Capgemini, Deloitte, Cognizant, SAP, DXC Technology, McKinsey & Company, Boston Consulting Group, and Bain & Company.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have a list of Accenture's main competitors.\n",
      "Final Answer: Some of Accenture's main competitors include IBM, PwC, Tata Consultancy Services, Capgemini, Deloitte, Cognizant, SAP, DXC Technology, McKinsey & Company, Boston Consulting Group, and Bain & Company.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know more context to determine the best approach.\n",
      "Action: Google Search\n",
      "Action Input: \"Accenture recent news\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAccenture has recently announced an expanded partnership with NVIDIA, as well as the acquisition of Joshua Tree Group. They also unveiled a $4 billion share buyback and reported better-than-expected results for the fourth quarter.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe recent news provides context for further questions about Accenture.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: \"Accenture earnings\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported strong earnings for the fiscal year, with record bookings of $72 billion and revenues of $64 billion, representing 8% growth in local currency. They also expanded adjusted operating margin and delivered adjusted EPS growth of 9%. The company invested significantly in their business and people, with capital deployed across acquisitions, R&D, and training. They generated free cash flow of $9 billion and returned over $7 billion to shareholders. Accenture is well positioned for strong growth in FY25 and continues to focus on large-scale transformations for clients. They prioritize building a strong digital core and leveraging technology to drive growth.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered information on Accenture's recent earnings and performance.\n",
      "Final Answer: Accenture reported strong earnings for the fiscal year, with record bookings of $72 billion and revenues of $64 billion, representing 8% growth in local currency.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97b4033d07a4ec5a9c8be9e19da2385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CorrectnessMetric evaluation:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = evaluate(use_agent, testset=test_questions, knowledge_base=kb_giskard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversational</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distracting element</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>situational</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     correctness\n",
       "question_type                   \n",
       "complex                 0.000000\n",
       "conversational          0.500000\n",
       "distracting element     0.000000\n",
       "double                  0.000000\n",
       "simple                  0.333333\n",
       "situational             0.500000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary with the results.\n",
    "report.correctness_by_question_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_context</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>metadata</th>\n",
       "      <th>agent_answer</th>\n",
       "      <th>correctness</th>\n",
       "      <th>correctness_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ad126300-2c0e-4fef-bcdd-27a539d7f4f6</th>\n",
       "      <td>What was the EPS of Accenture in the fourth qu...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 1: The EPS of Accenture in the fourth...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide any answer to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faeb8cd3-8366-4673-81d7-c8bea9b4804c</th>\n",
       "      <td>How much did Accenture book in generative AI b...</td>\n",
       "      <td>Accenture booked $900 million in generative AI...</td>\n",
       "      <td>Document 3: Accenture booked $900 million in g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>Accenture booked $3 billion in generative AI b...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent stated that Accenture booked $3 bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05cdb12f-d525-4922-a74b-7e9fe7a2b2b2</th>\n",
       "      <td>Could you provide me with the Earnings Per Sha...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 0: The revenue of Accenture in the fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "      <td>The EPS for Accenture during the final quarter...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent stated that the EPS for Accenture du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732e0592-6400-4d39-b611-812f7de43aa2</th>\n",
       "      <td>Could you provide me with the anticipated rang...</td>\n",
       "      <td>The expected revenue of Accenture in the fourt...</td>\n",
       "      <td>Document 0: The revenue of Accenture in the fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "      <td>Accenture is projected to generate revenue gro...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided a percentage growth in reve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69b3e5c3-3b53-493c-bc76-47ab6c509dc2</th>\n",
       "      <td>What was the recorded revenue for Accenture's ...</td>\n",
       "      <td>Accenture booked $900 million in generative AI...</td>\n",
       "      <td>Document 3: Accenture booked $900 million in g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "      <td>The recorded revenue for Accenture's generativ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent stated that the recorded revenue for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd</th>\n",
       "      <td>What was the EPS of Accenture in the fourth qu...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 0: The revenue of Accenture in the fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>Accenture's EPS in the fourth quarter of 2024 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent stated that Accenture's EPS in the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3cca6140-0f19-40ee-8f36-258ad5275253</th>\n",
       "      <td>What was the EPS of Accenture in the fourth qu...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 1: The EPS of Accenture in the fourth...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide any answer to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84bbf30a-6729-4d13-8dbe-85b48d56939c</th>\n",
       "      <td>Considering the expected revenue range of $15....</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 1: The EPS of Accenture in the fourth...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide any answer to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71d20f12-27b2-4080-a549-de474ea3755f</th>\n",
       "      <td>As an investor, I'm trying to understand Accen...</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 1: The EPS of Accenture in the fourth...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'situational', 'seed_documen...</td>\n",
       "      <td>Accenture's EPS in the fourth quarter of 2024 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent stated that Accenture's EPS in the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c7d4310e-1030-41cc-8404-dd79cf7964c3</th>\n",
       "      <td>What is the expected revenue range and the EPS...</td>\n",
       "      <td>The revenue of Accenture in the fourth quarter...</td>\n",
       "      <td>Document 0: The revenue of Accenture in the fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'double', 'original_question...</td>\n",
       "      <td>The expected revenue range is $16.1 billion to...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent stated that the expected revenue ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203ce756-c0f0-40e2-a428-5f8a5b38dd3c</th>\n",
       "      <td>How much did Accenture book in generative AI b...</td>\n",
       "      <td>Accenture booked $900 million in generative AI...</td>\n",
       "      <td>Document 3: Accenture booked $900 million in g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'double', 'original_question...</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide any answer to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84197e17-7fc0-447c-85fc-b3b8dd88114d</th>\n",
       "      <td>What was it?</td>\n",
       "      <td>The EPS of Accenture in the fourth quarter of ...</td>\n",
       "      <td>Document 1: The EPS of Accenture in the fourth...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I am looking for...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>Accenture reported strong earnings for the fis...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent provided information about Accenture...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               question  \\\n",
       "id                                                                                        \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  What was the EPS of Accenture in the fourth qu...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  How much did Accenture book in generative AI b...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  Could you provide me with the Earnings Per Sha...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  Could you provide me with the anticipated rang...   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2  What was the recorded revenue for Accenture's ...   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd  What was the EPS of Accenture in the fourth qu...   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253  What was the EPS of Accenture in the fourth qu...   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c  Considering the expected revenue range of $15....   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f  As an investor, I'm trying to understand Accen...   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3  What is the expected revenue range and the EPS...   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c  How much did Accenture book in generative AI b...   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d                                       What was it?   \n",
       "\n",
       "                                                                       reference_answer  \\\n",
       "id                                                                                        \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  The EPS of Accenture in the fourth quarter of ...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  Accenture booked $900 million in generative AI...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  The EPS of Accenture in the fourth quarter of ...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  The expected revenue of Accenture in the fourt...   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2  Accenture booked $900 million in generative AI...   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd  The EPS of Accenture in the fourth quarter of ...   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253  The EPS of Accenture in the fourth quarter of ...   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c  The EPS of Accenture in the fourth quarter of ...   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f  The EPS of Accenture in the fourth quarter of ...   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3  The revenue of Accenture in the fourth quarter...   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c  Accenture booked $900 million in generative AI...   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d  The EPS of Accenture in the fourth quarter of ...   \n",
       "\n",
       "                                                                      reference_context  \\\n",
       "id                                                                                        \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  Document 1: The EPS of Accenture in the fourth...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  Document 3: Accenture booked $900 million in g...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  Document 0: The revenue of Accenture in the fo...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  Document 0: The revenue of Accenture in the fo...   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2  Document 3: Accenture booked $900 million in g...   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd  Document 0: The revenue of Accenture in the fo...   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253  Document 1: The EPS of Accenture in the fourth...   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c  Document 1: The EPS of Accenture in the fourth...   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f  Document 1: The EPS of Accenture in the fourth...   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3  Document 0: The revenue of Accenture in the fo...   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c  Document 3: Accenture booked $900 million in g...   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d  Document 1: The EPS of Accenture in the fourth...   \n",
       "\n",
       "                                                                   conversation_history  \\\n",
       "id                                                                                        \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6                                                 []   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c                                                 []   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2                                                 []   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2                                                 []   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2                                                 []   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd                                                 []   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253                                                 []   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c                                                 []   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f                                                 []   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3                                                 []   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c                                                 []   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d  [{'role': 'user', 'content': 'I am looking for...   \n",
       "\n",
       "                                                                               metadata  \\\n",
       "id                                                                                        \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  {'question_type': 'simple', 'seed_document_id'...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  {'question_type': 'simple', 'seed_document_id'...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  {'question_type': 'complex', 'seed_document_id...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  {'question_type': 'complex', 'seed_document_id...   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2  {'question_type': 'complex', 'seed_document_id...   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd  {'question_type': 'distracting element', 'seed...   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253  {'question_type': 'distracting element', 'seed...   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c  {'question_type': 'distracting element', 'seed...   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f  {'question_type': 'situational', 'seed_documen...   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3  {'question_type': 'double', 'original_question...   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c  {'question_type': 'double', 'original_question...   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d  {'question_type': 'conversational', 'seed_docu...   \n",
       "\n",
       "                                                                           agent_answer  \\\n",
       "id                                                                                        \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  Agent stopped due to iteration limit or time l...   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  Accenture booked $3 billion in generative AI b...   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  The EPS for Accenture during the final quarter...   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  Accenture is projected to generate revenue gro...   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2  The recorded revenue for Accenture's generativ...   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd  Accenture's EPS in the fourth quarter of 2024 ...   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253  Agent stopped due to iteration limit or time l...   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c  Agent stopped due to iteration limit or time l...   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f  Accenture's EPS in the fourth quarter of 2024 ...   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3  The expected revenue range is $16.1 billion to...   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c  Agent stopped due to iteration limit or time l...   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d  Accenture reported strong earnings for the fis...   \n",
       "\n",
       "                                      correctness  \\\n",
       "id                                                  \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6        False   \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c        False   \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2        False   \n",
       "732e0592-6400-4d39-b611-812f7de43aa2        False   \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2        False   \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd        False   \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253        False   \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c        False   \n",
       "71d20f12-27b2-4080-a549-de474ea3755f        False   \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3        False   \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c        False   \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d        False   \n",
       "\n",
       "                                                                     correctness_reason  \n",
       "id                                                                                       \n",
       "ad126300-2c0e-4fef-bcdd-27a539d7f4f6  The agent did not provide any answer to the us...  \n",
       "faeb8cd3-8366-4673-81d7-c8bea9b4804c  The agent stated that Accenture booked $3 bill...  \n",
       "05cdb12f-d525-4922-a74b-7e9fe7a2b2b2  The agent stated that the EPS for Accenture du...  \n",
       "732e0592-6400-4d39-b611-812f7de43aa2  The agent provided a percentage growth in reve...  \n",
       "69b3e5c3-3b53-493c-bc76-47ab6c509dc2  The agent stated that the recorded revenue for...  \n",
       "7a48e5e2-d9ee-4f4a-8318-d4a9dc9689bd  The agent stated that Accenture's EPS in the f...  \n",
       "3cca6140-0f19-40ee-8f36-258ad5275253  The agent did not provide any answer to the us...  \n",
       "84bbf30a-6729-4d13-8dbe-85b48d56939c  The agent did not provide any answer to the us...  \n",
       "71d20f12-27b2-4080-a549-de474ea3755f  The agent stated that Accenture's EPS in the f...  \n",
       "c7d4310e-1030-41cc-8404-dd79cf7964c3  The agent stated that the expected revenue ran...  \n",
       "203ce756-c0f0-40e2-a428-5f8a5b38dd3c  The agent did not provide any answer to the us...  \n",
       "84197e17-7fc0-447c-85fc-b3b8dd88114d  The agent provided information about Accenture...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the incorrect answers\n",
    "failures = report.get_failures()[:15]\n",
    "failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The agent stated that Accenture's EPS in the fourth quarter of 2024 was $11.67, but the correct answer is $2.66.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giskard explains the reasons why it considers the answers to be incorrect.\n",
    "failures['correctness_reason'].iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper\n",
      "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from whisper) (1.16.0)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41121 sha256=bf6e3521a837bc3321020c65c120c8e8561aa32931ec8168c97d741b37779bd8\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper\n",
      "Successfully installed whisper-1.1.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install openai==0.27.0\n",
    "# !pip install whisper # Install Whisper without OpenAI requirement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* Running on public URL: https://b306e0e2f8f7467908.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b306e0e2f8f7467908.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with local Whisper (/*** NOT using OpenAPI -  Works fine ***/\n",
    "\n",
    "import whisper\n",
    "import gradio as gr\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")  # You can choose \"small\", \"medium\", etc.\n",
    "\n",
    "# Function to transcribe audio locally using Whisper\n",
    "def transcribe_audio_with_whisper(audio_path):\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Gradio Interface for Audio Transcription\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe_audio_with_whisper,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record your question here\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Audio to Text Transcription\",\n",
    "    description=\"Record an audio query and get the transcribed text using Whisper.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* Running on public URL: https://1392029650c18d30ad.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1392029650c18d30ad.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transcribe Audio ONLY!\n",
    "\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "# Function to transcribe audio using Whisper API\n",
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            # Replace \"whisper-1\" with the appropriate Whisper model if needed\n",
    "            response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "            transcription = response.get(\"text\", \"Error: No transcription available.\")\n",
    "            return transcription\n",
    "    except Exception as e:\n",
    "        return f\"Error during transcription: {e}\"\n",
    "\n",
    "# Gradio Interface for Audio Transcription Only\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe_audio,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record your question here\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Audio to Text Transcription\",\n",
    "    description=\"Record an audio query and get the transcribed text using Whisper.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://529a52f742182e5eec.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://529a52f742182e5eec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find the revenue information for Accenture's fourth quarter of 2024.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Accenture revenue Q4 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture reported revenues of $16.4 billion in Q4 2024, representing a 3% increase in US dollars and a 5% increase in local currency.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the final answer.\n",
      "Final Answer: Accenture reported revenues of $16.4 billion in the fourth quarter of 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/__init__.py\", line 20, in init\n",
      "    eng = _activeEngines[driverName]\n",
      "          ~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/weakref.py\", line 136, in __getitem__\n",
      "    o = self.data[key]()\n",
      "        ~~~~~~~~~^^^^^\n",
      "KeyError: None\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1562, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_38/1511344083.py\", line 38, in gradio_chatbot\n",
      "    audio_output_path = text_to_speech(response)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_38/1511344083.py\", line 20, in text_to_speech\n",
      "    tts = pyttsx3.init()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/__init__.py\", line 22, in init\n",
      "    eng = Engine(driverName, debug)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/engine.py\", line 30, in __init__\n",
      "    self.proxy = driver.DriverProxy(weakref.proxy(self), driverName, debug)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/driver.py\", line 50, in __init__\n",
      "    self._module = importlib.import_module(name)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/drivers/espeak.py\", line 12, in <module>\n",
      "    from . import _espeak, fromUtf8, toUtf8\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/drivers/_espeak.py\", line 48, in <module>\n",
      "    raise RuntimeError(\"This means you probably do not have eSpeak or eSpeak-ng installed!\")\n",
      "RuntimeError: This means you probably do not have eSpeak or eSpeak-ng installed!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2025, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1781, in postprocess_data\n",
      "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1736, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: A  function (gradio_chatbot) didn't return enough output values (needed: 2, returned: 1).\n",
      "    Output components:\n",
      "        [textbox, audio]\n",
      "    Output values returned:\n",
      "        [\"Error: No valid input provided. Please either type or speak your question.\"]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2025, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1781, in postprocess_data\n",
      "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1736, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: A  function (gradio_chatbot) didn't return enough output values (needed: 2, returned: 1).\n",
      "    Output components:\n",
      "        [textbox, audio]\n",
      "    Output values returned:\n",
      "        [\"Error: No valid input provided. Please either type or speak your question.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during transcription: \n",
      "\n",
      "You tried to access openai.Audio, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use VectorStore Retrieval to find information about transcription errors in Accenture's earnings reports.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Transcription errors in Accenture's earnings reports\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccenture experienced transcription errors in its earnings reports, with discrepancies in the number of employees mentioned in the documents provided.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should find out more details about the transcription errors in Accenture's earnings reports.\n",
      "Action: VectorStore Retrieval\n",
      "Action Input: Details about transcription errors in Accenture's earnings reports\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThere is no mention of transcription errors in Accenture's earnings reports in the provided documents.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try to search for information about transcription errors in Accenture's earnings reports on Google.\n",
      "Action: Google Search\n",
      "Action Input: Transcription errors in Accenture's earnings reports\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe search results do not directly address transcription errors in Accenture's earnings reports.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/__init__.py\", line 20, in init\n",
      "    eng = _activeEngines[driverName]\n",
      "          ~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/weakref.py\", line 136, in __getitem__\n",
      "    o = self.data[key]()\n",
      "        ~~~~~~~~~^^^^^\n",
      "KeyError: None\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1562, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_38/1511344083.py\", line 38, in gradio_chatbot\n",
      "    audio_output_path = text_to_speech(response)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_38/1511344083.py\", line 20, in text_to_speech\n",
      "    tts = pyttsx3.init()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/__init__.py\", line 22, in init\n",
      "    eng = Engine(driverName, debug)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/engine.py\", line 30, in __init__\n",
      "    self.proxy = driver.DriverProxy(weakref.proxy(self), driverName, debug)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/driver.py\", line 50, in __init__\n",
      "    self._module = importlib.import_module(name)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/drivers/espeak.py\", line 12, in <module>\n",
      "    from . import _espeak, fromUtf8, toUtf8\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyttsx3/drivers/_espeak.py\", line 48, in <module>\n",
      "    raise RuntimeError(\"This means you probably do not have eSpeak or eSpeak-ng installed!\")\n",
      "RuntimeError: This means you probably do not have eSpeak or eSpeak-ng installed!\n"
     ]
    }
   ],
   "source": [
    "# Gradio with Audio input/output\n",
    "\n",
    "import gradio as gr\n",
    "import openai\n",
    "import json\n",
    "import pyttsx3\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Transcription function for audio input using Whisper API\n",
    "def transcribe_audio_with_whisper(audio_path):\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "            transcription = response[\"text\"]\n",
    "            return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transcription: {e}\")\n",
    "        return \"Transcription Error\"\n",
    "\n",
    "# Text-to-speech function for generating audio output\n",
    "def text_to_speech(text):\n",
    "    tts = pyttsx3.init()\n",
    "    tts.save_to_file(text, 'response_audio.mp3')\n",
    "    return 'response_audio.mp3'\n",
    "\n",
    "# Main function to handle both text and audio input\n",
    "def gradio_chatbot(user_query=None, audio_query=None):\n",
    "    if audio_query is not None:\n",
    "        user_query = transcribe_audio_with_whisper(audio_query)\n",
    "        \n",
    "    if not user_query:\n",
    "        return \"Error: No valid input provided. Please either type or speak your question.\"\n",
    "    \n",
    "    # Use the chatbot with LangChain’s ReAct agent setup\n",
    "    datasource = route_query(user_query)\n",
    "    source_label = \"VectorDB\" if datasource == \"vectorstore\" else \"Google Search\" if datasource == \"websearch\" else \"Unknown Source\"\n",
    "    response = handle_query_with_agent(user_query)\n",
    "\n",
    "    # Generate audio response and return both text and audio\n",
    "    audio_output_path = text_to_speech(response)\n",
    "    return f\"Answer (from {source_label}):\\n{response}\", audio_output_path\n",
    "\n",
    "# Gradio interface with both text and audio inputs and outputs\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_chatbot,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Type your question here\"),          # Text input\n",
    "        gr.Audio(type=\"filepath\", label=\"Or speak your question here\")  # Audio input\n",
    "    ],\n",
    "    outputs=[\n",
    "        \"text\",                      # Text output for answer\n",
    "        gr.Audio(label=\"Audio Answer\")   # Audio output for TTS response\n",
    "    ],\n",
    "    title=\"Accenture Q&A Chatbot\",\n",
    "    description=\"Ask any question about Accenture and get answers with sourced information, through text or voice.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3036245762.py:108: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
      "/tmp/ipykernel_40/3036245762.py:109: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipykernel_40/3036245762.py:111: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  react_agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/4: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] 089JqnNmJq0: Downloading webpage\n",
      "[youtube] 089JqnNmJq0: Downloading ios player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading mweb player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading player 4e23410d\n",
      "[youtube] 089JqnNmJq0: Downloading m3u8 information\n",
      "[info] 089JqnNmJq0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of   49.02MiB in 00:00:01 at 43.39MiB/s    \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 181MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of video 1\n",
      "Completed chunk 1 for video 1\n",
      "Processing chunk 2 of video 1\n",
      "Completed chunk 2 for video 1\n",
      "Processing chunk 3 of video 1\n",
      "Completed chunk 3 for video 1\n",
      "Processing chunk 4 of video 1\n",
      "Completed chunk 4 for video 1\n",
      "Processing chunk 5 of video 1\n",
      "Completed chunk 5 for video 1\n",
      "Processing chunk 6 of video 1\n",
      "Completed chunk 6 for video 1\n",
      "Processing chunk 7 of video 1\n",
      "Completed chunk 7 for video 1\n",
      "Processing chunk 8 of video 1\n",
      "Completed chunk 8 for video 1\n",
      "Processing chunk 9 of video 1\n",
      "Completed chunk 9 for video 1\n",
      "Processing chunk 10 of video 1\n",
      "Completed chunk 10 for video 1\n",
      "Processing chunk 11 of video 1\n",
      "Completed chunk 11 for video 1\n",
      "Processing chunk 12 of video 1\n",
      "Completed chunk 12 for video 1\n",
      "Processing chunk 13 of video 1\n",
      "Completed chunk 13 for video 1\n",
      "Processing chunk 14 of video 1\n",
      "Completed chunk 14 for video 1\n",
      "Processing chunk 15 of video 1\n",
      "Completed chunk 15 for video 1\n",
      "Processing chunk 16 of video 1\n",
      "Completed chunk 16 for video 1\n",
      "Processing chunk 17 of video 1\n",
      "Completed chunk 17 for video 1\n",
      "Processing chunk 18 of video 1\n",
      "Completed chunk 18 for video 1\n",
      "Processing chunk 19 of video 1\n",
      "Completed chunk 19 for video 1\n",
      "Processing chunk 20 of video 1\n",
      "Completed chunk 20 for video 1\n",
      "Processing chunk 21 of video 1\n",
      "Completed chunk 21 for video 1\n",
      "Processing chunk 22 of video 1\n",
      "Completed chunk 22 for video 1\n",
      "Processing chunk 23 of video 1\n",
      "Completed chunk 23 for video 1\n",
      "Processing chunk 24 of video 1\n",
      "Completed chunk 24 for video 1\n",
      "Processing chunk 25 of video 1\n",
      "Completed chunk 25 for video 1\n",
      "Processing chunk 26 of video 1\n",
      "Completed chunk 26 for video 1\n",
      "Processing chunk 27 of video 1\n",
      "Completed chunk 27 for video 1\n",
      "Processing chunk 28 of video 1\n",
      "Completed chunk 28 for video 1\n",
      "Processing chunk 29 of video 1\n",
      "Completed chunk 29 for video 1\n",
      "Processing chunk 30 of video 1\n",
      "Completed chunk 30 for video 1\n",
      "Processing chunk 31 of video 1\n",
      "Completed chunk 31 for video 1\n",
      "Processing chunk 32 of video 1\n",
      "Completed chunk 32 for video 1\n",
      "Processing chunk 33 of video 1\n",
      "Completed chunk 33 for video 1\n",
      "Processing chunk 34 of video 1\n",
      "Completed chunk 34 for video 1\n",
      "Processing chunk 35 of video 1\n",
      "Completed chunk 35 for video 1\n",
      "Processing chunk 36 of video 1\n",
      "Completed chunk 36 for video 1\n",
      "Processing chunk 37 of video 1\n",
      "Completed chunk 37 for video 1\n",
      "Processing chunk 38 of video 1\n",
      "Completed chunk 38 for video 1\n",
      "Processing video 2/4: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] IskUO7MoV2s: Downloading webpage\n",
      "[youtube] IskUO7MoV2s: Downloading ios player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading mweb player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading m3u8 information\n",
      "[info] IskUO7MoV2s: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   48.50MiB in 00:00:01 at 31.16MiB/s    \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n",
      "Processing chunk 1 of video 2\n",
      "Completed chunk 1 for video 2\n",
      "Processing chunk 2 of video 2\n",
      "Completed chunk 2 for video 2\n",
      "Processing chunk 3 of video 2\n",
      "Completed chunk 3 for video 2\n",
      "Processing chunk 4 of video 2\n",
      "Completed chunk 4 for video 2\n",
      "Processing chunk 5 of video 2\n",
      "Completed chunk 5 for video 2\n",
      "Processing chunk 6 of video 2\n",
      "Completed chunk 6 for video 2\n",
      "Processing chunk 7 of video 2\n",
      "Completed chunk 7 for video 2\n",
      "Processing chunk 8 of video 2\n",
      "Completed chunk 8 for video 2\n",
      "Processing chunk 9 of video 2\n",
      "Completed chunk 9 for video 2\n",
      "Processing chunk 10 of video 2\n",
      "Completed chunk 10 for video 2\n",
      "Processing chunk 11 of video 2\n",
      "Completed chunk 11 for video 2\n",
      "Processing chunk 12 of video 2\n",
      "Completed chunk 12 for video 2\n",
      "Processing chunk 13 of video 2\n",
      "Completed chunk 13 for video 2\n",
      "Processing chunk 14 of video 2\n",
      "Completed chunk 14 for video 2\n",
      "Processing chunk 15 of video 2\n",
      "Completed chunk 15 for video 2\n",
      "Processing chunk 16 of video 2\n",
      "Completed chunk 16 for video 2\n",
      "Processing chunk 17 of video 2\n",
      "Completed chunk 17 for video 2\n",
      "Processing chunk 18 of video 2\n",
      "Completed chunk 18 for video 2\n",
      "Processing chunk 19 of video 2\n",
      "Completed chunk 19 for video 2\n",
      "Processing chunk 20 of video 2\n",
      "Completed chunk 20 for video 2\n",
      "Processing chunk 21 of video 2\n",
      "Completed chunk 21 for video 2\n",
      "Processing chunk 22 of video 2\n",
      "Completed chunk 22 for video 2\n",
      "Processing chunk 23 of video 2\n",
      "Completed chunk 23 for video 2\n",
      "Processing chunk 24 of video 2\n",
      "Completed chunk 24 for video 2\n",
      "Processing chunk 25 of video 2\n",
      "Completed chunk 25 for video 2\n",
      "Processing chunk 26 of video 2\n",
      "Completed chunk 26 for video 2\n",
      "Processing chunk 27 of video 2\n",
      "Completed chunk 27 for video 2\n",
      "Processing chunk 28 of video 2\n",
      "Completed chunk 28 for video 2\n",
      "Processing chunk 29 of video 2\n",
      "Completed chunk 29 for video 2\n",
      "Processing chunk 30 of video 2\n",
      "Completed chunk 30 for video 2\n",
      "Processing chunk 31 of video 2\n",
      "Completed chunk 31 for video 2\n",
      "Processing chunk 32 of video 2\n",
      "Completed chunk 32 for video 2\n",
      "Processing chunk 33 of video 2\n",
      "Completed chunk 33 for video 2\n",
      "Processing chunk 34 of video 2\n",
      "Completed chunk 34 for video 2\n",
      "Processing chunk 35 of video 2\n",
      "Completed chunk 35 for video 2\n",
      "Processing chunk 36 of video 2\n",
      "Completed chunk 36 for video 2\n",
      "Processing chunk 37 of video 2\n",
      "Completed chunk 37 for video 2\n",
      "Processing chunk 38 of video 2\n",
      "Completed chunk 38 for video 2\n",
      "Processing video 3/4: https://www.youtube.com/watch?v=BbqwBMct8-0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=BbqwBMct8-0\n",
      "[youtube] BbqwBMct8-0: Downloading webpage\n",
      "[youtube] BbqwBMct8-0: Downloading ios player API JSON\n",
      "[youtube] BbqwBMct8-0: Downloading mweb player API JSON\n",
      "[youtube] BbqwBMct8-0: Downloading m3u8 information\n",
      "[info] BbqwBMct8-0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_2\n",
      "[download] 100% of   50.65MiB in 00:00:02 at 17.72MiB/s    \n",
      "[ExtractAudio] Destination: audio_2.mp3\n",
      "Deleting original file audio_2 (pass -k to keep)\n",
      "Processing chunk 1 of video 3\n",
      "Completed chunk 1 for video 3\n",
      "Processing chunk 2 of video 3\n",
      "Completed chunk 2 for video 3\n",
      "Processing chunk 3 of video 3\n",
      "Completed chunk 3 for video 3\n",
      "Processing chunk 4 of video 3\n",
      "Completed chunk 4 for video 3\n",
      "Processing chunk 5 of video 3\n",
      "Completed chunk 5 for video 3\n",
      "Processing chunk 6 of video 3\n",
      "Completed chunk 6 for video 3\n",
      "Processing chunk 7 of video 3\n",
      "Completed chunk 7 for video 3\n",
      "Processing chunk 8 of video 3\n",
      "Completed chunk 8 for video 3\n",
      "Processing chunk 9 of video 3\n",
      "Completed chunk 9 for video 3\n",
      "Processing chunk 10 of video 3\n",
      "Completed chunk 10 for video 3\n",
      "Processing chunk 11 of video 3\n",
      "Completed chunk 11 for video 3\n",
      "Processing chunk 12 of video 3\n",
      "Completed chunk 12 for video 3\n",
      "Processing chunk 13 of video 3\n",
      "Completed chunk 13 for video 3\n",
      "Processing chunk 14 of video 3\n",
      "Completed chunk 14 for video 3\n",
      "Processing chunk 15 of video 3\n",
      "Completed chunk 15 for video 3\n",
      "Processing chunk 16 of video 3\n",
      "Completed chunk 16 for video 3\n",
      "Processing chunk 17 of video 3\n",
      "Completed chunk 17 for video 3\n",
      "Processing chunk 18 of video 3\n",
      "Completed chunk 18 for video 3\n",
      "Processing chunk 19 of video 3\n",
      "Completed chunk 19 for video 3\n",
      "Processing chunk 20 of video 3\n",
      "Completed chunk 20 for video 3\n",
      "Processing chunk 21 of video 3\n",
      "Completed chunk 21 for video 3\n",
      "Processing chunk 22 of video 3\n",
      "Completed chunk 22 for video 3\n",
      "Processing chunk 23 of video 3\n",
      "Completed chunk 23 for video 3\n",
      "Processing chunk 24 of video 3\n",
      "Completed chunk 24 for video 3\n",
      "Processing chunk 25 of video 3\n",
      "Completed chunk 25 for video 3\n",
      "Processing chunk 26 of video 3\n",
      "Completed chunk 26 for video 3\n",
      "Processing chunk 27 of video 3\n",
      "Completed chunk 27 for video 3\n",
      "Processing chunk 28 of video 3\n",
      "Completed chunk 28 for video 3\n",
      "Processing chunk 29 of video 3\n",
      "Completed chunk 29 for video 3\n",
      "Processing chunk 30 of video 3\n",
      "Completed chunk 30 for video 3\n",
      "Processing chunk 31 of video 3\n",
      "Completed chunk 31 for video 3\n",
      "Processing chunk 32 of video 3\n",
      "Completed chunk 32 for video 3\n",
      "Processing chunk 33 of video 3\n",
      "Completed chunk 33 for video 3\n",
      "Processing chunk 34 of video 3\n",
      "Completed chunk 34 for video 3\n",
      "Processing chunk 35 of video 3\n",
      "Completed chunk 35 for video 3\n",
      "Processing chunk 36 of video 3\n",
      "Completed chunk 36 for video 3\n",
      "Processing chunk 37 of video 3\n",
      "Completed chunk 37 for video 3\n",
      "Processing video 4/4: https://www.youtube.com/watch?v=hQGtKBQc_iE\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=hQGtKBQc_iE\n",
      "[youtube] hQGtKBQc_iE: Downloading webpage\n",
      "[youtube] hQGtKBQc_iE: Downloading ios player API JSON\n",
      "[youtube] hQGtKBQc_iE: Downloading mweb player API JSON\n",
      "[youtube] hQGtKBQc_iE: Downloading m3u8 information\n",
      "[info] hQGtKBQc_iE: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_3\n",
      "[download] 100% of   60.94MiB in 00:00:03 at 18.03MiB/s    \n",
      "[ExtractAudio] Destination: audio_3.mp3\n",
      "Deleting original file audio_3 (pass -k to keep)\n",
      "Processing chunk 1 of video 4\n",
      "Completed chunk 1 for video 4\n",
      "Processing chunk 2 of video 4\n",
      "Completed chunk 2 for video 4\n",
      "Processing chunk 3 of video 4\n",
      "Completed chunk 3 for video 4\n",
      "Processing chunk 4 of video 4\n",
      "Completed chunk 4 for video 4\n",
      "Processing chunk 5 of video 4\n",
      "Completed chunk 5 for video 4\n",
      "Processing chunk 6 of video 4\n",
      "Completed chunk 6 for video 4\n",
      "Processing chunk 7 of video 4\n",
      "Completed chunk 7 for video 4\n",
      "Processing chunk 8 of video 4\n",
      "Completed chunk 8 for video 4\n",
      "Processing chunk 9 of video 4\n",
      "Completed chunk 9 for video 4\n",
      "Processing chunk 10 of video 4\n",
      "Completed chunk 10 for video 4\n",
      "Processing chunk 11 of video 4\n",
      "Completed chunk 11 for video 4\n",
      "Processing chunk 12 of video 4\n",
      "Completed chunk 12 for video 4\n",
      "Processing chunk 13 of video 4\n",
      "Completed chunk 13 for video 4\n",
      "Processing chunk 14 of video 4\n",
      "Completed chunk 14 for video 4\n",
      "Processing chunk 15 of video 4\n",
      "Completed chunk 15 for video 4\n",
      "Processing chunk 16 of video 4\n",
      "Completed chunk 16 for video 4\n",
      "Processing chunk 17 of video 4\n",
      "Completed chunk 17 for video 4\n",
      "Processing chunk 18 of video 4\n",
      "Completed chunk 18 for video 4\n",
      "Processing chunk 19 of video 4\n",
      "Completed chunk 19 for video 4\n",
      "Processing chunk 20 of video 4\n",
      "Completed chunk 20 for video 4\n",
      "Processing chunk 21 of video 4\n",
      "Completed chunk 21 for video 4\n",
      "Processing chunk 22 of video 4\n",
      "Completed chunk 22 for video 4\n",
      "Processing chunk 23 of video 4\n",
      "Completed chunk 23 for video 4\n",
      "Processing chunk 24 of video 4\n",
      "Completed chunk 24 for video 4\n",
      "Processing chunk 25 of video 4\n",
      "Completed chunk 25 for video 4\n",
      "Processing chunk 26 of video 4\n",
      "Completed chunk 26 for video 4\n",
      "Processing chunk 27 of video 4\n",
      "Completed chunk 27 for video 4\n",
      "Processing chunk 28 of video 4\n",
      "Completed chunk 28 for video 4\n",
      "Processing chunk 29 of video 4\n",
      "Completed chunk 29 for video 4\n",
      "Processing chunk 30 of video 4\n",
      "Completed chunk 30 for video 4\n",
      "Processing chunk 31 of video 4\n",
      "Completed chunk 31 for video 4\n",
      "Processing chunk 32 of video 4\n",
      "Completed chunk 32 for video 4\n",
      "Processing chunk 33 of video 4\n",
      "Completed chunk 33 for video 4\n",
      "Processing chunk 34 of video 4\n",
      "Completed chunk 34 for video 4\n",
      "Processing chunk 35 of video 4\n",
      "Completed chunk 35 for video 4\n",
      "Processing chunk 36 of video 4\n",
      "Completed chunk 36 for video 4\n",
      "Processing chunk 37 of video 4\n",
      "Completed chunk 37 for video 4\n",
      "Processing chunk 38 of video 4\n",
      "Completed chunk 38 for video 4\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3036245762.py:123: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = react_agent({\"input\": user_query, \"transcriptions\": transcriptions})  # Send entire list to agent once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI should transcribe all the earnings podcasts from the YouTube links provided to consolidate the results.\n",
      "Action: TranscribeAllVideos\n",
      "Action Input: List of YouTube links to earnings podcasts\u001b[0mProcessing video 1/4: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] 089JqnNmJq0: Downloading webpage\n",
      "[youtube] 089JqnNmJq0: Downloading ios player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading mweb player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading m3u8 information\n",
      "[info] 089JqnNmJq0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of   49.02MiB in 00:00:01 at 43.23MiB/s    \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n",
      "Processing chunk 1 of video 1\n",
      "Completed chunk 1 for video 1\n",
      "Processing chunk 2 of video 1\n",
      "Completed chunk 2 for video 1\n",
      "Processing chunk 3 of video 1\n",
      "Completed chunk 3 for video 1\n",
      "Processing chunk 4 of video 1\n",
      "Completed chunk 4 for video 1\n",
      "Processing chunk 5 of video 1\n",
      "Completed chunk 5 for video 1\n",
      "Processing chunk 6 of video 1\n",
      "Completed chunk 6 for video 1\n",
      "Processing chunk 7 of video 1\n",
      "Completed chunk 7 for video 1\n",
      "Processing chunk 8 of video 1\n",
      "Completed chunk 8 for video 1\n",
      "Processing chunk 9 of video 1\n",
      "Completed chunk 9 for video 1\n",
      "Processing chunk 10 of video 1\n",
      "Completed chunk 10 for video 1\n",
      "Processing chunk 11 of video 1\n",
      "Completed chunk 11 for video 1\n",
      "Processing chunk 12 of video 1\n",
      "Completed chunk 12 for video 1\n",
      "Processing chunk 13 of video 1\n",
      "Completed chunk 13 for video 1\n",
      "Processing chunk 14 of video 1\n",
      "Completed chunk 14 for video 1\n",
      "Processing chunk 15 of video 1\n",
      "Completed chunk 15 for video 1\n",
      "Processing chunk 16 of video 1\n",
      "Completed chunk 16 for video 1\n",
      "Processing chunk 17 of video 1\n",
      "Completed chunk 17 for video 1\n",
      "Processing chunk 18 of video 1\n",
      "Completed chunk 18 for video 1\n",
      "Processing chunk 19 of video 1\n",
      "Completed chunk 19 for video 1\n",
      "Processing chunk 20 of video 1\n",
      "Completed chunk 20 for video 1\n",
      "Processing chunk 21 of video 1\n",
      "Completed chunk 21 for video 1\n",
      "Processing chunk 22 of video 1\n",
      "Completed chunk 22 for video 1\n",
      "Processing chunk 23 of video 1\n",
      "Completed chunk 23 for video 1\n",
      "Processing chunk 24 of video 1\n",
      "Completed chunk 24 for video 1\n",
      "Processing chunk 25 of video 1\n",
      "Completed chunk 25 for video 1\n",
      "Processing chunk 26 of video 1\n",
      "Completed chunk 26 for video 1\n",
      "Processing chunk 27 of video 1\n",
      "Completed chunk 27 for video 1\n",
      "Processing chunk 28 of video 1\n",
      "Completed chunk 28 for video 1\n",
      "Processing chunk 29 of video 1\n",
      "Completed chunk 29 for video 1\n",
      "Processing chunk 30 of video 1\n",
      "Completed chunk 30 for video 1\n",
      "Processing chunk 31 of video 1\n",
      "Completed chunk 31 for video 1\n",
      "Processing chunk 32 of video 1\n",
      "Completed chunk 32 for video 1\n",
      "Processing chunk 33 of video 1\n",
      "Completed chunk 33 for video 1\n",
      "Processing chunk 34 of video 1\n",
      "Completed chunk 34 for video 1\n",
      "Processing chunk 35 of video 1\n",
      "Completed chunk 35 for video 1\n",
      "Processing chunk 36 of video 1\n",
      "Completed chunk 36 for video 1\n",
      "Processing chunk 37 of video 1\n",
      "Completed chunk 37 for video 1\n",
      "Processing chunk 38 of video 1\n",
      "Completed chunk 38 for video 1\n",
      "Processing video 2/4: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] IskUO7MoV2s: Downloading webpage\n",
      "[youtube] IskUO7MoV2s: Downloading ios player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading mweb player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading m3u8 information\n",
      "[info] IskUO7MoV2s: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   48.50MiB in 00:00:02 at 17.96MiB/s    \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 132\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m\"\"\" def perform_transcription_task():\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    user_query = \"Transcribe all earnings podcasts from the provided YouTube links.\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    response = react_agent({\"input\": user_query})\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    print(\"Agent's Transcription:\", response[\"output\"]) \"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Start the transcription task\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[43mperform_transcription_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 123\u001b[0m, in \u001b[0;36mperform_transcription_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribe all earnings podcasts from the provided YouTube links.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m transcriptions \u001b[38;5;241m=\u001b[39m transcribe_all_videos()  \u001b[38;5;66;03m# Get transcriptions directly\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mreact_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranscriptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscriptions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Send entire list to agent once\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Transcription:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1639\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1420\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1442\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1450\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py:689\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    688\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    690\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    691\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py:657\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[1;32m    656\u001b[0m     tool_kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 657\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/simple.py:92\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     91\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mtranscribe_all_videos\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(video_links)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m download_audio(video_url, AUDIO_OUTPUT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m---> 70\u001b[0m full_transcription \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_whisper\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m transcription_chunks \u001b[38;5;241m=\u001b[39m chunk_text(full_transcription)  \u001b[38;5;66;03m# Divide transcription\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transcription_chunks):\n",
      "Cell \u001b[0;32mIn[7], line 44\u001b[0m, in \u001b[0;36mtranscribe_audio_with_whisper\u001b[0;34m(audio_path, model_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_with_whisper\u001b[39m(audio_path, model_name\u001b[38;5;241m=\u001b[39mWHISPER_MODEL):\n\u001b[1;32m     43\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model(model_name)\n\u001b[0;32m---> 44\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:279\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    276\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    278\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 279\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:195\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    192\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    194\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m--> 195\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    199\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    201\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:242\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    239\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 242\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    245\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    246\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:169\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    167\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_ln(x), mask\u001b[38;5;241m=\u001b[39mmask, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m--> 169\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    170\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_ln(x))\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:112\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    109\u001b[0m     v \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue]\n\u001b[1;32m    111\u001b[0m wv, qk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv_attention(q, k, v, mask)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwv\u001b[49m\u001b[43m)\u001b[49m, qk\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:45\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLinear\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mLinear):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\n\u001b[1;32m     47\u001b[0m             x,\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     50\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# New Code 11PM SATURDAY # THIS CODE worked using ReAct agent for Transcription, but went in Infinite LOOOOP\n",
    "\n",
    "\"\"\" import os\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# Default configurations\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"  # File with YouTube links\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}\"  # Template for audio file names without .mp3 extension\n",
    "WHISPER_MODEL = \"base\"  # Whisper model for transcription\n",
    "\n",
    "# Load YouTube links from the file\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        video_links = [link.strip() for link in file.readlines() if link.strip()]\n",
    "    return video_links\n",
    "\n",
    "# Download audio from YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': output_name,  # Filename with .mp3 extension\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return f\"{output_name}.mp3\"\n",
    "\n",
    "# Transcribe audio using Whisper\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# ReAct Tool for downloading and transcribing all videos\n",
    "# Split transcriptions into chunks below the token limit - Process in Batches!\n",
    "def chunk_text(text, max_length=1500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "    for word in words:\n",
    "        chunk.append(word)\n",
    "        if len(\" \".join(chunk)) >= max_length:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = []\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks\n",
    "\n",
    "# Process each transcription in chunks\n",
    "def transcribe_all_videos(input_data=None): # Accept an optional argument\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "    all_transcriptions = []\n",
    "    \n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        full_transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        transcription_chunks = chunk_text(full_transcription)  # Divide transcription\n",
    "        \n",
    "        for j, chunk in enumerate(transcription_chunks):\n",
    "            # print(f\"Processing chunk {j+1} of video {i+1}\")\n",
    "            # Send chunk to the ReAct agent\n",
    "            # response = react_agent({\"input\": chunk}) /* Don't call Agent each time */\n",
    "            all_transcriptions.append({\"title\": f\"Video {i+1} - Chunk {j+1}\", \"transcription\": chunk})\n",
    "            print(f\"Completed chunk {j+1} for video {i+1}\")\n",
    "        \n",
    "    return all_transcriptions\n",
    "\n",
    "\n",
    "def transcribe_all_videos(input_data=None):  # Accept an optional argument\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "    all_transcriptions = []\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        all_transcriptions.append({\"title\": f\"Video {i+1}\", \"transcription\": transcription})\n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "    return all_transcriptions\n",
    "\n",
    "# Define structured output for better organization\n",
    "response_schema = [\n",
    "    ResponseSchema(name=\"transcription\", description=\"Transcribed text from each video in structured format.\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "# Define tool for the agent\n",
    "transcription_tool = Tool(\n",
    "    name=\"TranscribeAllVideos\",\n",
    "    func=transcribe_all_videos,\n",
    "    description=\"Transcribes all videos in the provided list and consolidates results.\"\n",
    ")\n",
    "\n",
    "# Initialize the ReAct agent with transcription tool\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=[transcription_tool],\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run agent to perform transcription\n",
    "def perform_transcription_task():\n",
    "    user_query = \"Transcribe all earnings podcasts from the provided YouTube links.\"\n",
    "    transcriptions = transcribe_all_videos()  # Get transcriptions directly\n",
    "    response = react_agent({\"input\": user_query, \"transcriptions\": transcriptions})  # Send entire list to agent once\n",
    "    print(\"Agent's Transcription:\", response[\"output\"])\n",
    "\n",
    "def perform_transcription_task():\n",
    "    user_query = \"Transcribe all earnings podcasts from the provided YouTube links.\"\n",
    "    response = react_agent({\"input\": user_query})\n",
    "    print(\"Agent's Transcription:\", response[\"output\"])\n",
    "\n",
    "# Start the transcription task\n",
    "perform_transcription_task()\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
