{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.1.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper) (8.10.0)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.13.1)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803319 sha256=2998781d880d62c077ed4a215d10f34e5d1f249fadade7b71d4e1aaa2d502f2c\n",
      "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: llvmlite, tiktoken, numba, openai-whisper\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0 openai-whisper-20240930 tiktoken-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain\n",
      "  Downloading langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.9.1)\n",
      "Collecting langchain-core<0.4.0,>=0.3.14 (from langchain)\n",
      "  Downloading langchain_core-0.3.14-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.138-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.3)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.14->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain) (4.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain) (2.4)\n",
      "Downloading langchain-0.3.6-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.14-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.1-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.138-py3-none-any.whl (299 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.0/299.0 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, pydantic-core, orjson, jsonpatch, h11, annotated-types, pydantic, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.14\n",
      "    Uninstalling pydantic-1.10.14:\n",
      "      Successfully uninstalled pydantic-1.10.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 langchain-0.3.6 langchain-core-0.3.14 langchain-text-splitters-0.3.1 langsmith-0.1.138 orjson-3.10.10 pydantic-2.9.2 pydantic-core-2.23.4 tenacity-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai\n",
      "  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, jiter, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jiter-0.6.1 openai-1.53.0 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytube\n",
    "!pip install openai-whisper\n",
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, torch\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import langchain.output_parsers as parsers\\ndir(parsers) '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many Parsers Langchain has for use!\n",
    "\"\"\" import langchain.output_parsers as parsers\n",
    "dir(parsers) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from pytube import YouTube\\n\\ndef download_audio_from_youtube(url):\\n    yt = YouTube(url)\\n    audio_stream = yt.streams.filter(only_audio=True).first()\\n    audio_path = audio_stream.download(filename=\"audio.mp3\")\\n    return audio_path\\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from pytube import YouTube\n",
    "\n",
    "def download_audio_from_youtube(url):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    audio_path = audio_stream.download(filename=\"audio.mp3\")\n",
    "    return audio_path\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import whisper\\n\\ndef transcribe_audio_with_whisper(audio_path):\\n    model = whisper.load_model(\"base\")  # or \"small\", \"medium\", \"large\" depending on needs\\n    transcription = model.transcribe(audio_path)\\n    return transcription[\\'text\\'] '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import whisper\n",
    "\n",
    "def transcribe_audio_with_whisper(audio_path):\n",
    "    model = whisper.load_model(\"base\")  # or \"small\", \"medium\", \"large\" depending on needs\n",
    "    transcription = model.transcribe(audio_path)\n",
    "    return transcription['text'] \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from langchain.tools import Tool\\n\\ndef youtube_to_text_tool(url):\\n    audio_path = download_audio_from_youtube(url)\\n    transcription = transcribe_audio_with_whisper(audio_path)\\n    return transcription\\n\\nyoutube_transcription_tool = Tool(\\n    name=\"YouTubeTranscriptionTool\",\\n    func=youtube_to_text_tool,\\n    description=\"Converts YouTube video audio to text.\"\\n) '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from langchain.tools import Tool\n",
    "\n",
    "def youtube_to_text_tool(url):\n",
    "    audio_path = download_audio_from_youtube(url)\n",
    "    transcription = transcribe_audio_with_whisper(audio_path)\n",
    "    return transcription\n",
    "\n",
    "youtube_transcription_tool = Tool(\n",
    "    name=\"YouTubeTranscriptionTool\",\n",
    "    func=youtube_to_text_tool,\n",
    "    description=\"Converts YouTube video audio to text.\"\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load Environment Variable\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the environment variable directly in the script\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "#OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "#PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") # or \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the environment variable with os.environ\n",
    "#print(os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting yt-dlp\n",
      "  Downloading yt_dlp-2024.10.22-py3-none-any.whl.metadata (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.6/171.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting brotli (from yt-dlp)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from yt-dlp) (2020.6.20)\n",
      "Collecting mutagen (from yt-dlp)\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt-dlp)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting requests<3,>=2.32.2 (from yt-dlp)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.11/dist-packages (from yt-dlp) (2.0.7)\n",
      "Collecting websockets>=13.0 (from yt-dlp)\n",
      "  Downloading websockets-13.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3)\n",
      "Downloading yt_dlp-2024.10.22-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-13.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m140.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: brotli, websockets, requests, pycryptodomex, mutagen, yt-dlp\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.21.0 requests-2.32.3 websockets-13.1 yt-dlp-2024.10.22\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (1.26.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (9.5.0)\n",
      "Collecting imageio-ffmpeg (from imageio[ffmpeg])\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio-ffmpeg->imageio[ffmpeg]) (69.0.3)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "!pip install imageio[ffmpeg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import os\\nprint(os.environ[\"PATH\"])\\n\\nimport subprocess\\nsubprocess.run([\"ffmpeg\", \"-version\"]) '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DEBUG THE FFMPEG location issue!\n",
    "\n",
    "\"\"\" import os\n",
    "print(os.environ[\"PATH\"])\n",
    "\n",
    "import subprocess\n",
    "subprocess.run([\"ffmpeg\", \"-version\"]) \"\"\"\n",
    "\n",
    "#!apt-get update && apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!which ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/3: https://www.youtube.com/watch?v=kgldqMlCh78https://www.youtube.com/watch?v=YcKqEWQ6zXQ\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=kgldqMlCh78https://www.youtube.com/watch?v=YcKqEWQ6zXQ\n",
      "[youtube] kgldqMlCh78: Downloading webpage\n",
      "[youtube] kgldqMlCh78: Downloading ios player API JSON\n",
      "[youtube] kgldqMlCh78: Downloading mweb player API JSON\n",
      "[youtube] kgldqMlCh78: Downloading m3u8 information\n",
      "[info] kgldqMlCh78: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of    5.10MiB in 00:00:00 at 28.90MiB/s  \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n",
      "Completed transcription for video 1\n",
      "Processing video 2/3: https://www.youtube.com/watch?v=5tPOMVWN78o\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=5tPOMVWN78o\n",
      "[youtube] 5tPOMVWN78o: Downloading webpage\n",
      "[youtube] 5tPOMVWN78o: Downloading ios player API JSON\n",
      "[youtube] 5tPOMVWN78o: Downloading mweb player API JSON\n",
      "[youtube] 5tPOMVWN78o: Downloading m3u8 information\n",
      "[info] 5tPOMVWN78o: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   55.54MiB in 00:00:11 at 4.84MiB/s     \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n",
      "Completed transcription for video 2\n",
      "Processing video 3/3: https://www.youtube.com/watch?v=LR4RXaD2QQ0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=LR4RXaD2QQ0\n",
      "[youtube] LR4RXaD2QQ0: Downloading webpage\n",
      "[youtube] LR4RXaD2QQ0: Downloading ios player API JSON\n",
      "[youtube] LR4RXaD2QQ0: Downloading mweb player API JSON\n",
      "[youtube] LR4RXaD2QQ0: Downloading m3u8 information\n",
      "[info] LR4RXaD2QQ0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_2\n",
      "[download] 100% of   38.67MiB in 00:00:02 at 13.34MiB/s    \n",
      "[ExtractAudio] Destination: audio_2.mp3\n",
      "Deleting original file audio_2 (pass -k to keep)\n",
      "Completed transcription for video 3\n"
     ]
    }
   ],
   "source": [
    "# using TEXT file that has multiple YOUTUBE video links!\n",
    "\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "\n",
    "# Default configurations for easy modification\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"  # Text file with newline-separated YouTube links\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}\"  # Template without .mp3 extension\n",
    "WHISPER_MODEL = \"turbo\"  # Use Whisper turbo for faster processing, if available\n",
    "\n",
    "# Load YouTube links from file with newline separation\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        video_links = [link.strip() for link in file.readlines() if link.strip()]\n",
    "    return video_links\n",
    "\n",
    "# Download audio from a YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': output_name,  # Filename without .mp3 extension\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'  # Update for Paperspace\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return f\"{output_name}.mp3\"  # Return the filename with .mp3 extension\n",
    "\n",
    "# Transcribe audio using Whisper turbo model\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)  # Use turbo model for faster processing\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Process each video link\n",
    "def process_videos(filename=VIDEO_LINKS_FILE):\n",
    "    video_links = load_video_links(filename)\n",
    "    all_transcriptions = []\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, output_name=AUDIO_OUTPUT_TEMPLATE.format(i))  # Use .mp3 extension\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        all_transcriptions.append(transcription)\n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "    return all_transcriptions\n",
    "\n",
    "# Run the process\n",
    "all_transcriptions = process_videos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved as consolidated_transcription_TCS_Earn_long.html\n"
     ]
    }
   ],
   "source": [
    "# Default configuration for consolidated transcription output\n",
    "CONSOLIDATED_TRANSCRIPTION_FILE = \"consolidated_transcription_TCS_Earn_long.html\"  # Name for the HTML file\n",
    "\n",
    "# Save consolidated transcription to a single HTML file\n",
    "def save_consolidated_transcription(transcriptions=all_transcriptions):\n",
    "    with open(CONSOLIDATED_TRANSCRIPTION_FILE, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"<html><body><h1>Consolidated Transcription</h1><ol>\")\n",
    "        for i, transcription in enumerate(transcriptions):\n",
    "            file.write(f\"<h2>Video {i+1}</h2>\")\n",
    "            for line in transcription.splitlines():\n",
    "                file.write(f\"<li>{line}</li>\")\n",
    "        file.write(\"</ol></body></html>\")\n",
    "    print(f\"Transcription saved as {CONSOLIDATED_TRANSCRIPTION_FILE}\")\n",
    "\n",
    "# Save all transcriptions to the consolidated HTML file\n",
    "save_consolidated_transcription()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=rhiYfBctLOI\n",
      "[youtube] rhiYfBctLOI: Downloading webpage\n",
      "[youtube] rhiYfBctLOI: Downloading ios player API JSON\n",
      "[youtube] rhiYfBctLOI: Downloading mweb player API JSON\n",
      "[youtube] rhiYfBctLOI: Downloading player 4e23410d\n",
      "[youtube] rhiYfBctLOI: Downloading m3u8 information\n",
      "[info] rhiYfBctLOI: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_accent_1hr\n",
      "[download] 100% of   51.43MiB in 00:00:01 at 30.88MiB/s    \n",
      "[ExtractAudio] Destination: audio_accent_1hr.mp3\n",
      "Deleting original file audio_accent_1hr (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 179MiB/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # to run it on PAPERSPACE! Youtube link IN-LINE!\n",
    "\n",
    "import yt_dlp\n",
    "\n",
    "def download_audio(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': 'audio_accent_1hr',\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'  # Updated path to ffmpeg on Paperspace\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return 'audio_accent_1hr.mp3'\n",
    "\n",
    "# Assuming transcribe_audio_with_whisper is a function that takes an audio path and transcribes it with Whisper\n",
    "video_url = \"https://www.youtube.com/watch?v=rhiYfBctLOI\"\n",
    "audio_path = download_audio(video_url)\n",
    "transcription = transcribe_audio_with_whisper(audio_path)\n",
    "#print(transcription) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved as HTML.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Save transcription to HTML\n",
    "with open('transcription.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(\"<html><body><h1>Transcription</h1><ol>\")\n",
    "    for line in transcription.splitlines():  # Split by lines if it's a long string\n",
    "        file.write(f\"<li>{line}</li>\")\n",
    "    file.write(\"</ol></body></html>\")\n",
    "\n",
    "print(\"Transcription saved as HTML.\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.9.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.6)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.138)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.3)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.4-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 2.21.0\n",
      "    Uninstalling marshmallow-2.21.0:\n",
      "      Successfully uninstalled marshmallow-2.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\n",
      "gradient 2.0.6 requires marshmallow<3.0, but you have marshmallow 3.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.4 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/905097521.py:10: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete. Ready for storage in a vector database.\n"
     ]
    }
   ],
   "source": [
    "# SEGMENT and VECTORIZE the Transcription with Langchain\n",
    "\n",
    "# Join all transcriptions into a single string (Conversion of List to String)\n",
    "consolidated_text = \"\\n\\n\".join(all_transcriptions)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the OpenAI embedding model \n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=400)\n",
    "segments = text_splitter.split_text(consolidated_text)\n",
    "\n",
    "# Vectorize each segment and store in a list with segment metadata\n",
    "vectorized_segments = []\n",
    "embeddings = embedding_model.embed_documents(segments)  # Generate embeddings for all segments\n",
    "\n",
    "for i, (segment, vector) in enumerate(zip(segments, embeddings)):\n",
    "    vectorized_segments.append({\n",
    "        \"id\": f\"segment_{i}\",\n",
    "        \"text\": segment,\n",
    "        \"embedding\": vector\n",
    "    })\n",
    "\n",
    "print(\"Vectorization complete. Ready for storage in a vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/lib/python3/dist-packages (from pinecone-client) (2020.6.20)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.0.7)\n",
      "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\n",
      "Successfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely fetch OpenAI and Pinecone API keys                    \n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")\n",
    "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ[\"PINECONE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMBEDDINGS OpenAI-ada-002\n",
    "\n",
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Securely fetch OpenAI and Pinecone API keys\n",
    "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OpenAI API key: \")\n",
    "#os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")\n",
    "#os.environ[\"PINECONE_ENV\"] = os.getenv(\"PINECONE_ENV\") or \"us-west1-gcp\"  # Example environment\n",
    "\n",
    "# Initialize OpenAI embeddings model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Initialize Pinecone client with the updated API\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "#spec = ServerlessSpec(cloud=\"aws\", region=\"us-west-1\")  # Specify Pinecone environment\n",
    "index_name = \"transcription-tcs-earn-index\"\n",
    "\n",
    "# Check if the index exists; create if it doesn’t\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI embedding dimension\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for the index to be ready\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for upsertion\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfaff2af12148c6aecc1905b961f74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments upserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# UPSERT embeddings to Pinecone in batches\n",
    "batch_size = 50\n",
    "for i in tqdm(range(0, len(vectorized_segments), batch_size)):\n",
    "    batch = vectorized_segments[i:i + batch_size]\n",
    "    ids = [segment[\"id\"] for segment in batch]\n",
    "    embeds = [segment[\"embedding\"] for segment in batch]\n",
    "    metadatas = [{\"text\": segment[\"text\"]} for segment in batch]\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "\n",
    "print(\"All segments upserted into Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 165}},\n",
       " 'total_vector_count': 165}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Q&A Chatbot! Ask me anything.\n",
      "Agent's Response:\n",
      " Hello! I'm here to assist you with any questions you have or information you need. Just let me know what you're looking for, and I'll do my best to provide you with the help you need. Feel free to ask anything, and I'll be happy to assist you!\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " TCS, or Tata Consultancy Services, is an Indian multinational information technology service and consulting company. It is one of the largest IT services firms in the world and is a part of the Tata Group.\n",
      "\n",
      "Diwali, also known as the Festival of Lights, is a significant Hindu festival celebrated in India and by Hindus worldwide. It symbolizes the victory of light over darkness and good over evil. During Diwali, people light oil lamps called diyas, decorate their homes, exchange gifts, and share festive meals with family and friends. It is a time for spiritual reflection, family gatherings, and joyous celebrations.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " TCS's latest earnings report for the quarter ending September 2020 showed strong performance. They achieved a 4.8% constant currency growth from the previous quarter, hitting an all-time high revenue of 40,135 crores in INR terms. In dollar terms, this translated to 5.42 billion dollars. The operating margin reached 26.2%, and the adjusted net margin was 21%. The company also ended the quarter with a significant amount of cash in hand. Overall, it was a very positive quarter for TCS.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " TCS's latest earnings report for the quarter ending September 2020 showed strong performance with a 4.8% constant currency growth from the previous quarter, hitting an all-time high revenue of 40,135 crores in INR terms. In dollar terms, this translates to 5.42 billion dollars. The company also achieved a 26.2% operating margin and ended the quarter with cash in hand of 58,500 crores. Overall, the report indicates a solid financial performance for TCS.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " I don't have any additional information to highlight at the moment.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Agent: Thank you for using the Q&A chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Create CONVERSATIONALQA AGENT from LANGCHAIN!\n",
    "\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI embedding model and Pinecone vector store\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Wrap Pinecone index with LangChain's Pinecone vector store\n",
    "vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "\n",
    "# Define the response schema for structured output\n",
    "response_schema = [\n",
    "    ResponseSchema(name=\"answer\", description=\"Main response text in a complete paragraph\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "# Prompt template for ensuring JSON-formatted responses\n",
    "response_template = PromptTemplate(\n",
    "    template=(\n",
    "        \"Answer the question below in a complete paragraph and respond in *strict JSON* format:\\n\\n\"\n",
    "        \"{format_instructions}\\n\\n\"\n",
    "        \"Question: {question}\"\n",
    "    ),\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Initialize Conversational Retrieval Chain using Pinecone and memory\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=chat_model,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Interactive chat function with improved parsing logic\n",
    "def interactive_chat():\n",
    "    print(\"Welcome to the Q&A Chatbot! Ask me anything.\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() == \"no\":\n",
    "            print(\"Agent: Thank you for using the Q&A chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Generate response with JSON format instructions\n",
    "        formatted_prompt = response_template.format(question=user_query)\n",
    "        response = qa_chain({\"question\": formatted_prompt})\n",
    "        \n",
    "        # Attempt to parse and format the response as JSON\n",
    "        try:\n",
    "            parsed_response = output_parser.parse(response['answer'])\n",
    "            print(\"Agent's Response:\\n\", parsed_response['answer'])\n",
    "        except Exception:\n",
    "            print(\"Error parsing response, displaying raw answer instead.\")\n",
    "            print(\"Raw Response:\\n\", response['answer'])\n",
    "        \n",
    "        print(\"\\nAgent: Do you have more questions?\")\n",
    "\n",
    "# Start the interactive chat\n",
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [00:53<00:00, 57.4MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " இப்போது புதிய அறிமுகம் அச்சி ஹோட்டல் சாம்பார் 50 கிராம் ரும்பாய் 20 மட்டுமே சென்னை பெருநகர் மற்றும் புரனகரில் சுமார் ஒரு மணி நேரமாக வெளித்து வாங்கும் கணமழை ராயப் பேட்டை, தியாகராய நகர், எழும்பூர், அண்ணாசாலை, அண்ணா நகர் meantime anchor உள்ளிட்ட பகுதிகளில் இடி மின்னவுடன் கொட்டி தீர்க்கும் கணமழை சென்னையில் மேற்கு அண்ணா நகர் பகுதியில் ஒரு மணி நேரத்துயில் 90 cómbing kindergarten அளவிருக்கு கணமழை பதிபு கொளத்தூர் பெரம்பூர் அம்பத்தூர் அமைந்தகரை ஆகிய இடங்கள் அதிக மழை பொழிவு எதிர்க்கொண்டதாக வானிலை மயம் தகவன் பசும்புன் முத்துராமலிங்க தேவரி 117. ஜெயன்தி மற்றும் 62. குருபுஜகி உட்டி முதல்மைச்சர் முக்கு ச்டாலின் மரியாது பசும்புன்னில் உள்ள தேவரி நினிவிடத்தில் மளர்த்தூபி சிலைக்கு மாலை நிவித்த மரியாதை சொல்றினார் பசும்புன்னில் தேவர் வாழ்ந்த இளம் புதுப்பிக்கப்பட்டு 100 ஆண்டு அலங்கाர வளைவு நினைவிடத்தில் அணயா விளக்கு அமைப்பு தேவர் ஜெயன்தியின் போது பசும்புன்னில் கூட நரிசலை தவிர்க தேவர் அரங்கம் திருக்கப்பட்டுள்ளதாக முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி முதலாமைச்சர் முக்கஸ் டாலின் பேட்டி பத்தன்புதாயிரம் கிலோ பட்டாசுகள் பரிவுது தீபாவலி பண்டிகைக்கு பட்டாசு விடிக்க தடி விடிக்கப்பட்டுள நிலையில் சேவித்து வைத்ததால் நடபிடிக்கு வண்ண மின்விளக்குகளால் ஒளிந்த அமரிகாவின் ஞூயார்க் நகரில் உள்ள உலக வர்த்தகமைய கட்டடம் தீபாவலியை உட்டி மின்விளக்குகளால் உலிரூட்டப்பட்ட அமரிகாவின் மிக உயரமான கட்டடம் தீபாவலியை உட்டி அமரிகாவின் ஞூயார்க் நகரில் உள்ள பள்ளிகளுக்கு நவம்பர் ஒண்ராம் தேதி விடுமுரை அறிவிப்ப confidential நியோ யார்க் நகர வரலாட்டில் முதன் முறையாக விடுமுறை அறிவிக்கப்படுவதாக நகரமேயிர் அலுவலகம் தகவுள் நியூஸிலாந்துக்கு எதிரான கடைசி ஒரு நாள் கிரிக்கெட் போட்டிகள் இந்திய மகலிரணி வெற்றி மூன்று போட்டிகள் கொண்ட தொடரை இரண்டுக்கு ஒன்று என்ற கணக்கில் வென்றது இந்தியா திருப்பத்தூர் மாவட்டம் ஆம்பூரருகே அரச தொடர்கப்பட்டி என்றuciónல NFT dzенного சதவிட்டதால் போய்ப்பட்ட<|az|> stata எல்லனும் அலேகம் பேருந்து உட்டுமல்்றும் ஏ öğசி நினைக்கள தீவிறக் கணக்கானிப்பில் ஆதிப commit அரைக்கோணம் ரைல் நிலையத்தில் சிங்ணல் கோலாரு காரணமாக சென்னை மார்க்கத்தில் மின்சார ரைல்கள் தாமதம் ஒரு மணி நேரத்திற்கு மேலாக தாமதமானதால் நிலைய மேலாளர் அளுவலகத்தை முற்றுகையிட்டு வாக்குவாதம் செய்த பயனிகள் அரசு பொக்குவரத்தக்கழகங்களில் גாOohy whilst an அரசு பொக்குவரத்தக்கழகங்களில் காலியாகவுள்ளு 2777 இடங்களை நிறப்பully ஆறப் 움ட்டு நzyst்ல்து Hills பணியாளர்கள் 637 பணியாளர்களை நிற הס்து நடபுடிக்கு ரசிகர் ரெனுகாஸ்வாமி கொலை விழக்கில் கண்ணட நடிகர் pentru இடைகால ஜாமின் ஜாமின்\n"
     ]
    }
   ],
   "source": [
    "# TAMIL TRANSCRIPTION GENERATION \n",
    "\n",
    "\n",
    "\"\"\" from whisper import load_model\n",
    "\n",
    "# Load the Whisper model\n",
    "model1 = load_model(\"large\")  # or use \"small\" or \"base\" for faster processing with lower accuracy\n",
    "\n",
    "\n",
    "# Transcribe the Tamil audio file\n",
    "result = model1.transcribe(\"audio_tamil.mp3\", language=\"ta\")\n",
    "transcription = result[\"text\"]\n",
    "\n",
    "print(transcription) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # to run it on CPU!\\n\\nimport yt_dlp\\n\\ndef download_audio(url):\\n    ydl_opts = {\\n        \\'format\\': \\'bestaudio/best\\',\\n        \\'postprocessors\\': [\\n            {\\n                \\'key\\': \\'FFmpegExtractAudio\\',\\n                \\'preferredcodec\\': \\'mp3\\',\\n                \\'preferredquality\\': \\'192\\',\\n            }\\n        ],\\n        \\'outtmpl\\': \\'audio.mp3\\',\\n        \\'ffmpeg_location\\': \\'C:/Users/KK/AppData/Local/ffmpeg-essentials_build/bin\\'  # Explicit path to ffmpeg\\n    }\\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\\n        ydl.download([url])\\n    return \\'audio.mp3\\'\\n\\n# Assuming transcribe_audio_with_whisper is a function that takes an audio path and transcribes it with Whisper\\nvideo_url = \"https://www.youtube.com/watch?v=RRk9QlCjul0\"\\naudio_path = download_audio(video_url)\\ntranscription = transcribe_audio_with_whisper(audio_path)\\nprint(transcription) '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # to run it on CPU!\n",
    "\n",
    "import yt_dlp\n",
    "\n",
    "def download_audio(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': 'audio.mp3',\n",
    "        'ffmpeg_location': 'C:/Users/KK/AppData/Local/ffmpeg-essentials_build/bin'  # Explicit path to ffmpeg\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return 'audio.mp3'\n",
    "\n",
    "# Assuming transcribe_audio_with_whisper is a function that takes an audio path and transcribes it with Whisper\n",
    "video_url = \"https://www.youtube.com/watch?v=RRk9QlCjul0\"\n",
    "audio_path = download_audio(video_url)\n",
    "transcription = transcribe_audio_with_whisper(audio_path)\n",
    "print(transcription) \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
