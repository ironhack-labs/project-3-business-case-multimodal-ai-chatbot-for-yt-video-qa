{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.1.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper) (8.10.0)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.13.1)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803319 sha256=5873a813b54fa457c9690df31c201160aff19f24090648cee1516defcaa84b4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: llvmlite, tiktoken, numba, openai-whisper\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0 openai-whisper-20240930 tiktoken-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.9.1)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
      "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.139-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.3)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.4)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.139-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, pydantic-core, orjson, jsonpatch, h11, annotated-types, pydantic, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.14\n",
      "    Uninstalling pydantic-1.10.14:\n",
      "      Successfully uninstalled pydantic-1.10.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 langchain-0.3.7 langchain-core-0.3.15 langchain-text-splitters-0.3.2 langsmith-0.1.139 orjson-3.10.11 pydantic-2.9.2 pydantic-core-2.23.4 tenacity-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai\n",
      "  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, jiter, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jiter-0.7.0 openai-1.53.0 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytube\n",
    "!pip install openai-whisper\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.9.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.139)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.3)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 2.21.0\n",
      "    Uninstalling marshmallow-2.21.0:\n",
      "      Successfully uninstalled marshmallow-2.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\n",
      "gradient 2.0.6 requires marshmallow<3.0, but you have marshmallow 3.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.5 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/lib/python3/dist-packages (from pinecone-client) (2020.6.20)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.0.7)\n",
      "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\n",
      "Successfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting yt-dlp\n",
      "  Downloading yt_dlp-2024.11.4-py3-none-any.whl.metadata (172 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yt_dlp-2024.11.4-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2024.11.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (1.26.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (9.5.0)\n",
      "Collecting imageio-ffmpeg (from imageio[ffmpeg])\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio-ffmpeg->imageio[ffmpeg]) (69.0.3)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community\n",
    "!pip install pinecone-client\n",
    "!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "!pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, torch\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load Environment Variable\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the environment variable directly in the script\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "#OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "#PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") # or \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the environment variable with os.environ\n",
    "#print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/4: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] 089JqnNmJq0: Downloading webpage\n",
      "[youtube] 089JqnNmJq0: Downloading ios player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading mweb player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading player 4e23410d\n",
      "[youtube] 089JqnNmJq0: Downloading m3u8 information\n",
      "[info] 089JqnNmJq0: Downloading 1 format(s): 251\n",
      "[download] audio_0.mp3 has already been downloaded\n",
      "[download] 100% of   83.94MiB\n",
      "[ExtractAudio] Not converting audio audio_0.mp3; file is already in target format mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:05<00:00, 26.8MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed transcription for video 1\n",
      "Processing video 2/4: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] IskUO7MoV2s: Downloading webpage\n",
      "[youtube] IskUO7MoV2s: Downloading ios player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading mweb player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading m3u8 information\n",
      "[info] IskUO7MoV2s: Downloading 1 format(s): 251\n",
      "[download] audio_1.mp3 has already been downloaded\n",
      "[download] 100% of   81.06MiB\n",
      "[ExtractAudio] Not converting audio audio_1.mp3; file is already in target format mp3\n",
      "Completed transcription for video 2\n",
      "Processing video 3/4: https://www.youtube.com/watch?v=BbqwBMct8-0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=BbqwBMct8-0\n",
      "[youtube] BbqwBMct8-0: Downloading webpage\n",
      "[youtube] BbqwBMct8-0: Downloading ios player API JSON\n",
      "[youtube] BbqwBMct8-0: Downloading mweb player API JSON\n",
      "[youtube] BbqwBMct8-0: Downloading m3u8 information\n",
      "[info] BbqwBMct8-0: Downloading 1 format(s): 251\n",
      "[download] audio_2.mp3 has already been downloaded\n",
      "[download] 100% of   82.56MiB\n",
      "[ExtractAudio] Not converting audio audio_2.mp3; file is already in target format mp3\n",
      "Completed transcription for video 3\n",
      "Processing video 4/4: https://www.youtube.com/watch?v=hQGtKBQc_iE\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=hQGtKBQc_iE\n",
      "[youtube] hQGtKBQc_iE: Downloading webpage\n",
      "[youtube] hQGtKBQc_iE: Downloading ios player API JSON\n",
      "[youtube] hQGtKBQc_iE: Downloading mweb player API JSON\n",
      "[youtube] hQGtKBQc_iE: Downloading m3u8 information\n",
      "[info] hQGtKBQc_iE: Downloading 1 format(s): 251\n",
      "[download] audio_3.mp3 has already been downloaded\n",
      "[download] 100% of   84.67MiB\n",
      "[ExtractAudio] Not converting audio audio_3.mp3; file is already in target format mp3\n",
      "Completed transcription for video 4\n",
      "Consolidation Complete. Transcriptions are ready for vectorization and further processing.\n"
     ]
    }
   ],
   "source": [
    "# Sunday 3-Nov\n",
    "# STEP 1: Transcription and Consolidation Tasks (without agent to improve the process and reduce the time)\n",
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Default configurations\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}\"\n",
    "WHISPER_MODEL = \"base\"\n",
    "TRANSCRIPT_DIR = \"transcriptions\"\n",
    "\n",
    "# Ensure directory exists for transcriptions\n",
    "os.makedirs(TRANSCRIPT_DIR, exist_ok=True)\n",
    "\n",
    "# Load YouTube links from the file\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        return [link.strip() for link in file.readlines() if link.strip()]\n",
    "\n",
    "# Download audio from YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],\n",
    "        'outtmpl': f\"{output_name}.mp3\",\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return f\"{output_name}.mp3\"\n",
    "\n",
    "# Transcribe audio using Whisper\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Process each video, saving individual transcriptions\n",
    "def transcribe_all_videos():\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "    all_transcriptions = []\n",
    "\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        \n",
    "        # Transcribe in chunks to prevent reprocessing, saving each transcription file\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        transcript_file = os.path.join(TRANSCRIPT_DIR, f\"transcription_{i+1}.txt\")\n",
    "        \n",
    "        with open(transcript_file, 'w') as f:\n",
    "            f.write(transcription)\n",
    "        \n",
    "        all_transcriptions.append({\"title\": f\"Video {i+1}\", \"transcription\": transcription})\n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "\n",
    "    return all_transcriptions\n",
    "\n",
    "# Consolidate transcriptions for LLM analysis\n",
    "def consolidate_transcriptions():\n",
    "    consolidated_text = \"\"\n",
    "    for file in sorted(os.listdir(TRANSCRIPT_DIR)):\n",
    "        file_path = os.path.join(TRANSCRIPT_DIR, file)\n",
    "        \n",
    "        # Check if the file_path is a file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                consolidated_text += f.read() + \"\\n\"\n",
    "    return consolidated_text\n",
    "\n",
    "\n",
    "# Agent analysis task with consolidated data\n",
    "\"\"\" def perform_analysis_task(consolidated_text):\n",
    "    chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    memory = ConversationBufferMemory()\n",
    "\n",
    "    react_agent = initialize_agent(\n",
    "        tools=[],\n",
    "        agent=\"zero-shot-react-description\",\n",
    "        llm=chat_model,\n",
    "        memory=memory,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    user_query = \"Consolidate and analyze the transcriptions of the earnings podcasts.\"\n",
    "    response = react_agent({\"input\": user_query, \"transcriptions\": consolidated_text})\n",
    "    print(\"Agent's Final Output:\", response[\"output\"]) \"\"\"\n",
    "\n",
    "# Execute process\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe_all_videos()\n",
    "    consolidated_text = consolidate_transcriptions()\n",
    "    \"\"\" perform_analysis_task(consolidated_text) \"\"\"\n",
    "    print(\"Consolidation Complete. Transcriptions are ready for vectorization and further processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3392710364.py:14: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
      "/tmp/ipykernel_40/3392710364.py:15: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipykernel_40/3392710364.py:18: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete. Ready for storage in a vector database.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: new with chunk before vectorization no ReAct Agent!\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# Split consolidated text into manageable chunks\n",
    "def split_text_for_vectorization(consolidated_text, max_tokens=1500):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=max_tokens, chunk_overlap=200)\n",
    "    return text_splitter.split_text(consolidated_text)\n",
    "\n",
    "# Function to perform vectorization on each chunk\n",
    "def perform_vectorization_task(consolidated_text):\n",
    "    chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    memory = ConversationBufferMemory()\n",
    "    \n",
    "    # Initialize the embedding model and the agent with vectorization tool\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    chunks = split_text_for_vectorization(consolidated_text)\n",
    "    \n",
    "    vectorized_segments = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # print(f\"Vectorizing chunk {i+1}/{len(chunks)}\")\n",
    "        \n",
    "        # Generate embeddings for this chunk\n",
    "        embeddings = embedding_model.embed_documents([chunk])\n",
    "        \n",
    "        # Store each embedding\n",
    "        vectorized_segments.append({\n",
    "            \"id\": f\"segment_{i}\",\n",
    "            \"text\": chunk,\n",
    "            \"embedding\": embeddings[0]  # embedding_model.embed_documents returns a list\n",
    "        })\n",
    "\n",
    "    print(\"Vectorization complete. Ready for storage in a vector database.\")\n",
    "    return vectorized_segments\n",
    "\n",
    "# Run vectorization task after consolidation\n",
    "if __name__ == \"__main__\":\n",
    "    # consolidated_text = consolidate_transcriptions()\n",
    "    vectorized_segments = perform_vectorization_task(consolidated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - define Pinecone as Vector DB & Define Index & Embeddings.\n",
    "\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely fetch OpenAI and Pinecone API keys                    \n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")\n",
    "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ[\"PINECONE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index statistics: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Create INDEX using EMBEDDINGS OpenAI-ada-002 - creating the Index for 'Accenture Earnings'\n",
    "\n",
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Securely fetch OpenAI and Pinecone API keys\n",
    "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OpenAI API key: \")\n",
    "#os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Enter Pinecone API key: \")\n",
    "#os.environ[\"PINECONE_ENV\"] = os.getenv(\"PINECONE_ENV\") or \"us-west1-gcp\"  # Example environment\n",
    "\n",
    "# Initialize OpenAI embeddings model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Initialize Pinecone client with the updated API\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "#spec = ServerlessSpec(cloud=\"aws\", region=\"us-west-1\")  # Specify Pinecone environment\n",
    "index_name = \"transcription-accnt-earn-index-2\"             # Create New Index\n",
    "\n",
    "# Check if the index exists; create if it doesn’t\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI embedding dimension\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for the index to be ready\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        print(\"Waiting for index to be ready...\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for upsertion\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "print(\"Index statistics:\", index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2508886806724649a702a5215c263495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments upserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5 - UPSERT embeddings to Pinecone in batches\n",
    "batch_size = 50\n",
    "for i in tqdm(range(0, len(vectorized_segments), batch_size)):\n",
    "    batch = vectorized_segments[i:i + batch_size]\n",
    "    ids = [segment[\"id\"] for segment in batch]\n",
    "    embeds = [segment[\"embedding\"] for segment in batch]\n",
    "    metadatas = [{\"text\": segment[\"text\"]} for segment in batch]\n",
    "\n",
    "    # Upsert each batch to Pinecone\n",
    "    try:\n",
    "        index.upsert(vectors=list(zip(ids, embeds, metadatas)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error upserting batch {i // batch_size + 1}: {e}\")\n",
    "\n",
    "print(\"All segments upserted into Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index statistics: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 174}},\n",
      " 'total_vector_count': 174}\n"
     ]
    }
   ],
   "source": [
    "print(\"Index statistics:\", index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.139)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the revenue of Accenture last quarter?\n",
      "Routed to: vectorstore\n",
      "\n",
      "Query: What is the EPS for last quarter?\n",
      "Routed to: vectorstore\n",
      "\n",
      "Query: What is the total no of employee count in Accenture company?\n",
      "Routed to: vectorstore\n",
      "\n",
      "Query: What is the size of Genai project deals for Accenture this year?\n",
      "Routed to: websearch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define ROUTER for query to be passed to VectorDB or Websearch (tavily)\n",
    "\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize LLM in JSON mode (replace 'gpt-3.5-turbo' with any model configured for JSON output)\n",
    "llm_json_mode = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Define the routing instructions\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to Accenture company Earnings results, Revenue, Earnings for last four quarters, sales, digital (cloud and Genai) projects and employee details.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with a single key, \"datasource\", that is either 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Function to route based on the instructions\n",
    "def route_query(query):\n",
    "    routing_response = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=router_instructions), HumanMessage(content=query)]\n",
    "    )\n",
    "    route_decision = json.loads(routing_response.content)\n",
    "    return route_decision[\"datasource\"]\n",
    "\n",
    "# Example queries to test the router\n",
    "test_queries = [\n",
    "    \"What is the revenue of Accenture last quarter?\",\n",
    "    \"What is the EPS for last quarter?\",\n",
    "    \"What is the total no of employee count in Accenture company?\",\n",
    "    \"What is the size of Genai project deals for Accenture this year?\",\n",
    "]\n",
    "\n",
    "# Execute the router on test queries\n",
    "for query in test_queries:\n",
    "    datasource = route_query(query)\n",
    "    print(f\"Query: {query}\\nRouted to: {datasource}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.31.0)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.8.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2023.12.25)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->tavily-python) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->tavily-python) (2020.6.20)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: tavily-python\n",
      "Successfully installed tavily-python-0.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\") or getpass.getpass(\"Enter Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3518613065.py:16: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing to Vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3518613065.py:38: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The revenue of Accenture last quarter was $16 billion.\n",
      "Routing to Vectorstore...\n",
      "Response: The EPS of Accenture last quarter was $2.77.\n",
      "Routing to Web Search...\n",
      "Results: [{'url': 'https://businesschronicler.com/competitors/accenture-competitors-analysis/', 'content': \"List of Accenture's Main Competitors. PwC; Deloitte; EY (Ernst & Young) KPMG; Accenture Business Strategy. Accenture's business strategy focuses on delivering 360-degree value for clients by embracing technological innovations to deliver the best consulting service possible across 19 industries.. The company was founded in 1989 when it was called Andersen Consulting.\"}, {'url': 'https://www.investopedia.com/articles/markets/101615/who-are-accentures-main-competitors.asp', 'content': 'While the company does not divulge the names of its clients, it claims to serve roughly 90 of the top 100 global corporations and more than 80 of the 100 largest U.S.-based companies.\\n Accenture got its start in the 1950s as the business and technology consulting division of Arthur Andersen, then one of the Big Five accounting firms.\\n The company now known as Accenture was created in the 1950s as a technology consulting division of now-defunct Arthur Andersen LLP, once one of the Big Five accounting firms. Who Are the Main Competitors of Accenture (ACN)?\\nAccenture PLC (ACN) is a\\xa0multinational professional technology services company that provides strategic, tactical, digital, and operational consulting support to clients in more than 200 cities across 120 countries.\\n The company has many competitors in the consulting industry, including the so-called \"Big Three:\" McKinsey & Co., Boston Consulting Group, Inc., and Bain & Co.\\n'}, {'url': 'https://fiveknowledge.com/accenture-competitors-analysis/', 'content': 'Capgemini is one of the biggest Accenture Competitors. Both Capgemini and Accenture provide a variety of services including consulting, technology, and outsourcing. 5. Deloitte. Deloitte is one of the Major Accenture competitors UK. Starting in the Year 1845, Deloitte Has More Than 3,45,374 employees with offices in 150+ Countries.'}, {'url': 'https://www.marketing91.com/accenture-competitors/', 'content': 'Due to their wide array of services and their quality Price water house coopers is considered as one of the top Accenture competitors.\\n5) Ernst and Young\\nAlso regarded as one of the top multinational professional services, Ernst and Young (EY) Company is headquartered in London, United Kingdom. Due to their focus on maximizing people’s potential which will help to increase the personal wealth, this company is considered as one of the top Accenture competitors.\\n9) Boston Consultancy group\\nAlso regarded as one of the management consulting firms, Boston Consultancy Group is headquartered in the United States. According to Infosys’s 2023 financial reports the company’s Gross Profit\\xa0 is $1,406 million and operating profit is $961 million.\\n15) Tata Consultancy Services (TCS)\\nTata Consultancy Services (TCS) is an Indian multinational IT services, consulting, and business solutions organization that has been partnering with many of the world’s largest businesses in their transformation journeys for over 50 years. Due to their advancement in technology and their services, McKinsey is considered as one of the top Accenture competitors.\\n4) Price water house coopers\\nPrice water house Coopers (PWC) provides the wide range of business needs to their customers to help them achieve their goals. Cognizant Technology Solutions net income for the quarter ending June 30, 2023 was\\xa0$0.463B. Cognizant Technology Solutions gross profit for the quarter ending June 30, 2023 was\\xa0$1.655B. Cognizant Technology Solutions operating income for the quarter ending June 30, 2023 was\\xa0$0.577B.\\n14) Infosys\\nInfosys is an Indian multinational information technology company that provides business consulting, information technology, and outsourcing services.'}, {'url': 'https://bstrategyhub.com/accenture-competitors-and-alternatives/', 'content': 'In 2021, Accenture reported a 14% increase in revenue to $50.5 billion.[1]\\nAccenture offers its services under four business segments: Strategy and Consulting, Digital and Interactive, Technology, and Operations. [8]\\nThe health of our company depends on the wellbeing of every associate—and we’re dedicated to providing the tools and support they need to #BeWell. And in Apr 2022, it was recognized as a top 10 Great Place to Work in six countries, including the US, Argentina, Brazil, France, Japan, and the Philippines. Top 15 Accenture Competitors and Alternatives\\nAccenture is a professional services company based in Dublin, Ireland, specializing in IT services and consulting. Infosys is one of the top alternatives to Accenture for IT services.[14]\\n.@Telenet started its application #modernization journey with a focus on #cloudmigration to boost the #digitalexperience for its customers.'}]\n",
      "Response: The main competitor of Accenture is considered to be IBM, followed by Deloitte and Capgemini.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "import os\n",
    "\n",
    "# Initialize the embedding model and vector store\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "# Assuming Pinecone index is already set up and embeddings are upserted\n",
    "vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "\n",
    "# Initialize the router instructions\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to Accenture company Earnings results, Revenue, Earnings for last four quarters, sales, digital (cloud and Genai) projects and employee details.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with a single key, \"datasource\", that is either 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Function to route query based on instructions\n",
    "def route_query(query):\n",
    "    routing_response = chat_model.invoke(\n",
    "        [SystemMessage(content=router_instructions), HumanMessage(content=query)]\n",
    "    )\n",
    "    route_decision = json.loads(routing_response.content)\n",
    "    return route_decision[\"datasource\"]\n",
    "\n",
    "# Function to retrieve from vector database\n",
    "def retrieve_from_vectorstore(query):\n",
    "    retriever = vector_store.as_retriever()\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    document_text = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "    # Summarize the retrieved documents using LLM \n",
    "    prompt = (\n",
    "        \"Based on the following documents, provide a concise answer to the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Documents:\\n\"\n",
    "        f\"{document_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    \n",
    "    answer_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return answer_response.content\n",
    "    # return \"\\n\\n\".join([doc.page_content for doc in results]) # can be removed if this modules functions right!\n",
    "\n",
    "# Function to perform web search (e.g., using Tavily)\n",
    "def web_search(query):\n",
    "    # Fetch results using Tavily\n",
    "    results = web_search_tool.run(query)\n",
    "    print(\"Results:\", results)  # Inspect the structure\n",
    "    combined_text = \"\\n\".join(result.get('text', 'No text available') for result in results if 'text' in result)\n",
    "\n",
    "    # Summarize results if multiple documents are returned\n",
    "    prompt = (\n",
    "        f\"Summarize the following web search results to answer the question:\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Results:\\n{combined_text}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    summary_response = chat_model.invoke([HumanMessage(content=prompt)])\n",
    "    return summary_response.content\n",
    "    \n",
    "\n",
    "# Main function to handle the query routing and retrieval\n",
    "def handle_query(query):\n",
    "    datasource = route_query(query)\n",
    "    \n",
    "    if datasource == \"vectorstore\":\n",
    "        print(\"Routing to Vectorstore...\")\n",
    "        return retrieve_from_vectorstore(query)\n",
    "    elif datasource == \"websearch\":\n",
    "        print(\"Routing to Web Search...\")\n",
    "        return web_search(query)\n",
    "    else:\n",
    "        return \"Unknown data source. Please check the router configuration.\"\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the revenue of Accenture last quarter??\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"What is the EPS of Accenture last quarter?\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n",
    "\n",
    "query = \"Who is the main competitor of Accenture?\"\n",
    "response = handle_query(query)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Q&A Chatbot! Ask me anything.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Answer Questions tool to find the total employee count in Accenture.\n",
      "Action: Answer Questions\n",
      "Action Input: total employee count in Accenture\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"As of the latest data available, the total employee count in Accenture is approximately 624,000 worldwide. Accenture is a global professional services company that operates in more than 200 cities across 50 countries, offering a wide range of services in consulting, technology, and outsourcing.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 81, 'total_tokens': 149, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-88a5b4fd-37e6-4a5d-84f1-6fd813587b9c-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe total employee count in Accenture is approximately 624,000 worldwide.\n",
      "Final Answer: 624,000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " 624,000\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the full fiscal year booking value.\n",
      "Action: Answer Questions\n",
      "Action Input: full fiscal year booking value\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"The full fiscal year booking value refers to the total amount of revenue generated from bookings made by customers over the course of an entire fiscal year. This value is important for businesses to track as it provides insight into the overall financial performance and growth potential of the company. By analyzing the full fiscal year booking value, businesses can make informed decisions about future investments, budget allocations, and strategic planning to drive further success.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 80, 'total_tokens': 172, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-8c2aaec5-cd78-423a-821e-06cf0c9e91d6-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe full fiscal year booking value refers to the total amount of revenue generated from bookings made by customers over the course of an entire fiscal year.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to provide a proper format for the next set of actions.\n",
      "Action: Answer Questions\n",
      "Action Input: full fiscal year booking value\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"The full fiscal year booking value refers to the total amount of sales or revenue generated by a company over the course of its entire fiscal year. This value includes all the bookings or sales made by the company, whether through product sales, services rendered, or any other revenue-generating activities. It is an important metric for measuring the financial performance and growth of a company over a specific period of time.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 80, 'total_tokens': 170, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f3a48235-e9dd-477d-b43c-1b7615a6d8f9-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe full fiscal year booking value refers to the total amount of sales or revenue generated by a company over the course of its entire fiscal year.\n",
      "Final Answer: The full fiscal year booking value refers to the total amount of sales or revenue generated by a company over the course of its entire fiscal year.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " The full fiscal year booking value refers to the total amount of sales or revenue generated by a company over the course of its entire fiscal year.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the provided tools to answer the question.\n",
      "Action: Answer Questions\n",
      "Action Input: \"What are the symptoms of COVID-19?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"The symptoms of COVID-19 can vary widely but commonly include fever, cough, shortness of breath, fatigue, body aches, loss of taste or smell, sore throat, and headache. Some individuals may also experience gastrointestinal symptoms like nausea, vomiting, or diarrhea. It is important to note that not everyone infected with the virus will display symptoms, and the severity of symptoms can range from mild to severe, with some cases leading to hospitalization or even death.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 84, 'total_tokens': 188, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9c4a3651-8f7a-4a6e-89da-f04de85c46ab-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved information about the symptoms of COVID-19.\n",
      "Final Answer: The symptoms of COVID-19 can vary widely but commonly include fever, cough, shortness of breath, fatigue, body aches, loss of taste or smell, sore throat, and headache. Some individuals may also experience gastrointestinal symptoms like nausea, vomiting, or diarrhea.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " The symptoms of COVID-19 can vary widely but commonly include fever, cough, shortness of breath, fatigue, body aches, loss of taste or smell, sore throat, and headache. Some individuals may also experience gastrointestinal symptoms like nausea, vomiting, or diarrhea.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for information on Accenture's full fiscal year booking.\n",
      "Action: Answer Questions\n",
      "Action Input: Accenture full fiscal year booking\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"Accenture\\'s full fiscal year booking refers to the total amount of revenue generated by the company over its entire fiscal year, typically consisting of four quarters. This figure includes income from various services provided by Accenture, such as consulting, technology, and outsourcing. By analyzing the full fiscal year booking, investors and analysts can gain insights into the company\\'s financial performance and growth trajectory. It is an important metric used to evaluate Accenture\\'s overall business health and success.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 81, 'total_tokens': 184, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f6e57ea3-7057-4547-9503-86b9433def3f-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe information provided explains what Accenture's full fiscal year booking represents. \n",
      "Final Answer: Accenture's full fiscal year booking refers to the total amount of revenue generated by the company over its entire fiscal year, typically consisting of four quarters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " Accenture's full fiscal year booking refers to the total amount of revenue generated by the company over its entire fiscal year, typically consisting of four quarters.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the tool to find the information related to Genai's sales and revenue in the fourth quarter of 2024.\n",
      "Action: Answer Questions\n",
      "Action Input: Genai sales and revenue fourth quarter 2024\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"The Genai sales and revenue for the fourth quarter of 2024 exceeded expectations, with a significant increase compared to previous quarters. This growth can be attributed to successful product launches, effective marketing strategies, and strong customer demand. The company\\'s financial performance in Q4 2024 reflects a positive trend, indicating a promising future for Genai in the market.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 85, 'total_tokens': 168, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-ea8de672-b553-4d89-b450-c9f74be7855e-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe information provided indicates that Genai's sales and revenue for the fourth quarter of 2024 exceeded expectations due to various factors.\n",
      "Final Answer: The Genai sales and revenue for the fourth quarter of 2024 exceeded expectations, reflecting a positive trend for the company.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " The Genai sales and revenue for the fourth quarter of 2024 exceeded expectations, reflecting a positive trend for the company.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm ready to start answering questions\n",
      "Action: Answer Questions\n",
      "Action Input: \"What is the capital of France?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent='```json\\n{\\n\\t\"answer\": \"The capital of France is Paris. Paris is not only the capital but also the largest city in France. It is known for its rich history, art, fashion, and culture, making it one of the most popular tourist destinations in the world.\"\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 82, 'total_tokens': 142, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-dd6d846d-e7d9-41b6-97fd-245769b3d9fd-0'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the answer to the first question.\n",
      "Final Answer: The capital of France is Paris.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Error parsing response, displaying raw answer instead.\n",
      "Raw Response:\n",
      " The capital of France is Paris.\n",
      "\n",
      "Agent: Do you have more questions?\n",
      "Agent: Thank you for using the Q&A chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: SETUP Conversational Agent using Langchain using ConversationalRetrievalChain, QA Tool, LLM (gpt 3.5-turbo) and ReAct Agent\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#from langchain.retrievers import VectorStoreRetriever\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "import json\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from getpass import getpass\n",
    "import pinecone\n",
    "\n",
    "# Initialize the OpenAI embedding model and Pinecone vector store\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Wrap Pinecone index with LangChain's Pinecone vector store\n",
    "vector_store = Pinecone(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "\n",
    "# Define the response schema for structured output\n",
    "response_schema = [\n",
    "    ResponseSchema(name=\"answer\", description=\"Main response text in a complete paragraph\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "# Prompt template for ensuring JSON-formatted responses\n",
    "response_template = PromptTemplate(\n",
    "    template=(\n",
    "        \"Answer the question below in a complete paragraph and respond in *strict JSON* format:\\n\\n\"\n",
    "        \"{format_instructions}\\n\\n\"\n",
    "        \"Question: {question}\"\n",
    "    ),\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Define the retrieval tool for the ReAct agent\n",
    "def retrieval_tool(query):\n",
    "    retriever = vector_store.as_retriever()\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "# Define the tool for the ReAct agent\n",
    "qa_tool = Tool(\n",
    "    name=\"Answer Questions\",\n",
    "    func=lambda query: chat_model.invoke([HumanMessage(content=response_template.format(question=query))]),\n",
    "    description=\"Use this tool to answer questions based on the retrieved documents.\"\n",
    ")\n",
    "\n",
    "# Initialize ReAct agent with the QA tool\n",
    "react_agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Interactive chat function with improved parsing logic\n",
    "def interactive_chat():\n",
    "    print(\"Welcome to the Q&A Chatbot! Ask me anything.\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() == \"no\":\n",
    "            print(\"Agent: Thank you for using the Q&A chatbot. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Generate response with JSON format instructions\n",
    "        response = react_agent({\"input\": user_query})\n",
    "        \n",
    "        # Attempt to parse and format the response as JSON\n",
    "        try:\n",
    "            parsed_response = output_parser.parse(response[\"output\"])\n",
    "            print(\"Agent's Response:\\n\", parsed_response[\"answer\"])\n",
    "        except Exception:\n",
    "            print(\"Error parsing response, displaying raw answer instead.\")\n",
    "            print(\"Raw Response:\\n\", response[\"output\"])\n",
    "        \n",
    "        print(\"\\nAgent: Do you have more questions?\")\n",
    "\n",
    "# Start the interactive chat\n",
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monday - Finetune Retrieval and QA and Chatbot!\n",
    "\n",
    "# Check Next code, separated for finetuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 47049 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# transcribe_all_videos() # already part of Step1 above\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     consolidated_text \u001b[38;5;241m=\u001b[39m consolidate_transcriptions()\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mperform_vectorization_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsolidated_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 50\u001b[0m, in \u001b[0;36mperform_vectorization_task\u001b[0;34m(consolidated_text)\u001b[0m\n\u001b[1;32m     48\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorize the consolidated transcriptions for storage in a vector database.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m input_content \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconsolidated_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}               \u001b[38;5;66;03m# single input to the React Agent\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mreact_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#response = react_agent({\"input\": user_query, \"consolidated_text\": consolidated_text})\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Vectorization Output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1639\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1363\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:809\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    808\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 809\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfull_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py:318\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/openai.py:475\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    474\u001b[0m }\n\u001b[0;32m--> 475\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/openai.py:386\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1067\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 47049 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# DON'T WORK! Error! 2: Define the ReAct agent for vectorization as a tool\n",
    "\n",
    "\"\"\" from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Function to perform vectorization\n",
    "def vectorize_text(consolidated_text):\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=400)\n",
    "    segments = text_splitter.split_text(consolidated_text)\n",
    "\n",
    "    vectorized_segments = []\n",
    "    embeddings = embedding_model.embed_documents(segments)\n",
    "\n",
    "    for i, (segment, vector) in enumerate(zip(segments, embeddings)):\n",
    "        vectorized_segments.append({\n",
    "            \"id\": f\"segment_{i}\",\n",
    "            \"text\": segment,\n",
    "            \"embedding\": vector\n",
    "        })\n",
    "\n",
    "    return vectorized_segments\n",
    "\n",
    "# Define the vectorization tool\n",
    "vectorization_tool = Tool(\n",
    "    name=\"VectorizeText\",\n",
    "    func=vectorize_text,\n",
    "    description=\"Segments and vectorizes consolidated transcriptions for storage in a vector database.\"\n",
    ")\n",
    "\n",
    "# Initialize the agent with the vectorization tool\n",
    "def perform_vectorization_task(consolidated_text):\n",
    "    chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    memory = ConversationBufferMemory()\n",
    "\n",
    "    react_agent = initialize_agent(\n",
    "        tools=[vectorization_tool],\n",
    "        agent=\"zero-shot-react-description\",\n",
    "        llm=chat_model,\n",
    "        memory=memory,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # User query for vectorization\n",
    "    user_query = \"Vectorize the consolidated transcriptions for storage in a vector database.\"\n",
    "    input_content = {\"input\": f\"{user_query}\\n\\n{consolidated_text}\"}               # single input to the React Agent\n",
    "    response = react_agent(input_content)\n",
    "    #response = react_agent({\"input\": user_query, \"consolidated_text\": consolidated_text})\n",
    "    print(\"Agent's Vectorization Output:\", response[\"output\"])\n",
    "\n",
    "# Run vectorization task after consolidation\n",
    "if __name__ == \"__main__\":\n",
    "    # transcribe_all_videos() # already part of Step1 above\n",
    "    consolidated_text = consolidate_transcriptions()\n",
    "    perform_vectorization_task(consolidated_text)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3036245762.py:108: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
      "/tmp/ipykernel_40/3036245762.py:109: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipykernel_40/3036245762.py:111: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  react_agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/4: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] 089JqnNmJq0: Downloading webpage\n",
      "[youtube] 089JqnNmJq0: Downloading ios player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading mweb player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading player 4e23410d\n",
      "[youtube] 089JqnNmJq0: Downloading m3u8 information\n",
      "[info] 089JqnNmJq0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of   49.02MiB in 00:00:01 at 43.39MiB/s    \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 181MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of video 1\n",
      "Completed chunk 1 for video 1\n",
      "Processing chunk 2 of video 1\n",
      "Completed chunk 2 for video 1\n",
      "Processing chunk 3 of video 1\n",
      "Completed chunk 3 for video 1\n",
      "Processing chunk 4 of video 1\n",
      "Completed chunk 4 for video 1\n",
      "Processing chunk 5 of video 1\n",
      "Completed chunk 5 for video 1\n",
      "Processing chunk 6 of video 1\n",
      "Completed chunk 6 for video 1\n",
      "Processing chunk 7 of video 1\n",
      "Completed chunk 7 for video 1\n",
      "Processing chunk 8 of video 1\n",
      "Completed chunk 8 for video 1\n",
      "Processing chunk 9 of video 1\n",
      "Completed chunk 9 for video 1\n",
      "Processing chunk 10 of video 1\n",
      "Completed chunk 10 for video 1\n",
      "Processing chunk 11 of video 1\n",
      "Completed chunk 11 for video 1\n",
      "Processing chunk 12 of video 1\n",
      "Completed chunk 12 for video 1\n",
      "Processing chunk 13 of video 1\n",
      "Completed chunk 13 for video 1\n",
      "Processing chunk 14 of video 1\n",
      "Completed chunk 14 for video 1\n",
      "Processing chunk 15 of video 1\n",
      "Completed chunk 15 for video 1\n",
      "Processing chunk 16 of video 1\n",
      "Completed chunk 16 for video 1\n",
      "Processing chunk 17 of video 1\n",
      "Completed chunk 17 for video 1\n",
      "Processing chunk 18 of video 1\n",
      "Completed chunk 18 for video 1\n",
      "Processing chunk 19 of video 1\n",
      "Completed chunk 19 for video 1\n",
      "Processing chunk 20 of video 1\n",
      "Completed chunk 20 for video 1\n",
      "Processing chunk 21 of video 1\n",
      "Completed chunk 21 for video 1\n",
      "Processing chunk 22 of video 1\n",
      "Completed chunk 22 for video 1\n",
      "Processing chunk 23 of video 1\n",
      "Completed chunk 23 for video 1\n",
      "Processing chunk 24 of video 1\n",
      "Completed chunk 24 for video 1\n",
      "Processing chunk 25 of video 1\n",
      "Completed chunk 25 for video 1\n",
      "Processing chunk 26 of video 1\n",
      "Completed chunk 26 for video 1\n",
      "Processing chunk 27 of video 1\n",
      "Completed chunk 27 for video 1\n",
      "Processing chunk 28 of video 1\n",
      "Completed chunk 28 for video 1\n",
      "Processing chunk 29 of video 1\n",
      "Completed chunk 29 for video 1\n",
      "Processing chunk 30 of video 1\n",
      "Completed chunk 30 for video 1\n",
      "Processing chunk 31 of video 1\n",
      "Completed chunk 31 for video 1\n",
      "Processing chunk 32 of video 1\n",
      "Completed chunk 32 for video 1\n",
      "Processing chunk 33 of video 1\n",
      "Completed chunk 33 for video 1\n",
      "Processing chunk 34 of video 1\n",
      "Completed chunk 34 for video 1\n",
      "Processing chunk 35 of video 1\n",
      "Completed chunk 35 for video 1\n",
      "Processing chunk 36 of video 1\n",
      "Completed chunk 36 for video 1\n",
      "Processing chunk 37 of video 1\n",
      "Completed chunk 37 for video 1\n",
      "Processing chunk 38 of video 1\n",
      "Completed chunk 38 for video 1\n",
      "Processing video 2/4: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] IskUO7MoV2s: Downloading webpage\n",
      "[youtube] IskUO7MoV2s: Downloading ios player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading mweb player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading m3u8 information\n",
      "[info] IskUO7MoV2s: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   48.50MiB in 00:00:01 at 31.16MiB/s    \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n",
      "Processing chunk 1 of video 2\n",
      "Completed chunk 1 for video 2\n",
      "Processing chunk 2 of video 2\n",
      "Completed chunk 2 for video 2\n",
      "Processing chunk 3 of video 2\n",
      "Completed chunk 3 for video 2\n",
      "Processing chunk 4 of video 2\n",
      "Completed chunk 4 for video 2\n",
      "Processing chunk 5 of video 2\n",
      "Completed chunk 5 for video 2\n",
      "Processing chunk 6 of video 2\n",
      "Completed chunk 6 for video 2\n",
      "Processing chunk 7 of video 2\n",
      "Completed chunk 7 for video 2\n",
      "Processing chunk 8 of video 2\n",
      "Completed chunk 8 for video 2\n",
      "Processing chunk 9 of video 2\n",
      "Completed chunk 9 for video 2\n",
      "Processing chunk 10 of video 2\n",
      "Completed chunk 10 for video 2\n",
      "Processing chunk 11 of video 2\n",
      "Completed chunk 11 for video 2\n",
      "Processing chunk 12 of video 2\n",
      "Completed chunk 12 for video 2\n",
      "Processing chunk 13 of video 2\n",
      "Completed chunk 13 for video 2\n",
      "Processing chunk 14 of video 2\n",
      "Completed chunk 14 for video 2\n",
      "Processing chunk 15 of video 2\n",
      "Completed chunk 15 for video 2\n",
      "Processing chunk 16 of video 2\n",
      "Completed chunk 16 for video 2\n",
      "Processing chunk 17 of video 2\n",
      "Completed chunk 17 for video 2\n",
      "Processing chunk 18 of video 2\n",
      "Completed chunk 18 for video 2\n",
      "Processing chunk 19 of video 2\n",
      "Completed chunk 19 for video 2\n",
      "Processing chunk 20 of video 2\n",
      "Completed chunk 20 for video 2\n",
      "Processing chunk 21 of video 2\n",
      "Completed chunk 21 for video 2\n",
      "Processing chunk 22 of video 2\n",
      "Completed chunk 22 for video 2\n",
      "Processing chunk 23 of video 2\n",
      "Completed chunk 23 for video 2\n",
      "Processing chunk 24 of video 2\n",
      "Completed chunk 24 for video 2\n",
      "Processing chunk 25 of video 2\n",
      "Completed chunk 25 for video 2\n",
      "Processing chunk 26 of video 2\n",
      "Completed chunk 26 for video 2\n",
      "Processing chunk 27 of video 2\n",
      "Completed chunk 27 for video 2\n",
      "Processing chunk 28 of video 2\n",
      "Completed chunk 28 for video 2\n",
      "Processing chunk 29 of video 2\n",
      "Completed chunk 29 for video 2\n",
      "Processing chunk 30 of video 2\n",
      "Completed chunk 30 for video 2\n",
      "Processing chunk 31 of video 2\n",
      "Completed chunk 31 for video 2\n",
      "Processing chunk 32 of video 2\n",
      "Completed chunk 32 for video 2\n",
      "Processing chunk 33 of video 2\n",
      "Completed chunk 33 for video 2\n",
      "Processing chunk 34 of video 2\n",
      "Completed chunk 34 for video 2\n",
      "Processing chunk 35 of video 2\n",
      "Completed chunk 35 for video 2\n",
      "Processing chunk 36 of video 2\n",
      "Completed chunk 36 for video 2\n",
      "Processing chunk 37 of video 2\n",
      "Completed chunk 37 for video 2\n",
      "Processing chunk 38 of video 2\n",
      "Completed chunk 38 for video 2\n",
      "Processing video 3/4: https://www.youtube.com/watch?v=BbqwBMct8-0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=BbqwBMct8-0\n",
      "[youtube] BbqwBMct8-0: Downloading webpage\n",
      "[youtube] BbqwBMct8-0: Downloading ios player API JSON\n",
      "[youtube] BbqwBMct8-0: Downloading mweb player API JSON\n",
      "[youtube] BbqwBMct8-0: Downloading m3u8 information\n",
      "[info] BbqwBMct8-0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_2\n",
      "[download] 100% of   50.65MiB in 00:00:02 at 17.72MiB/s    \n",
      "[ExtractAudio] Destination: audio_2.mp3\n",
      "Deleting original file audio_2 (pass -k to keep)\n",
      "Processing chunk 1 of video 3\n",
      "Completed chunk 1 for video 3\n",
      "Processing chunk 2 of video 3\n",
      "Completed chunk 2 for video 3\n",
      "Processing chunk 3 of video 3\n",
      "Completed chunk 3 for video 3\n",
      "Processing chunk 4 of video 3\n",
      "Completed chunk 4 for video 3\n",
      "Processing chunk 5 of video 3\n",
      "Completed chunk 5 for video 3\n",
      "Processing chunk 6 of video 3\n",
      "Completed chunk 6 for video 3\n",
      "Processing chunk 7 of video 3\n",
      "Completed chunk 7 for video 3\n",
      "Processing chunk 8 of video 3\n",
      "Completed chunk 8 for video 3\n",
      "Processing chunk 9 of video 3\n",
      "Completed chunk 9 for video 3\n",
      "Processing chunk 10 of video 3\n",
      "Completed chunk 10 for video 3\n",
      "Processing chunk 11 of video 3\n",
      "Completed chunk 11 for video 3\n",
      "Processing chunk 12 of video 3\n",
      "Completed chunk 12 for video 3\n",
      "Processing chunk 13 of video 3\n",
      "Completed chunk 13 for video 3\n",
      "Processing chunk 14 of video 3\n",
      "Completed chunk 14 for video 3\n",
      "Processing chunk 15 of video 3\n",
      "Completed chunk 15 for video 3\n",
      "Processing chunk 16 of video 3\n",
      "Completed chunk 16 for video 3\n",
      "Processing chunk 17 of video 3\n",
      "Completed chunk 17 for video 3\n",
      "Processing chunk 18 of video 3\n",
      "Completed chunk 18 for video 3\n",
      "Processing chunk 19 of video 3\n",
      "Completed chunk 19 for video 3\n",
      "Processing chunk 20 of video 3\n",
      "Completed chunk 20 for video 3\n",
      "Processing chunk 21 of video 3\n",
      "Completed chunk 21 for video 3\n",
      "Processing chunk 22 of video 3\n",
      "Completed chunk 22 for video 3\n",
      "Processing chunk 23 of video 3\n",
      "Completed chunk 23 for video 3\n",
      "Processing chunk 24 of video 3\n",
      "Completed chunk 24 for video 3\n",
      "Processing chunk 25 of video 3\n",
      "Completed chunk 25 for video 3\n",
      "Processing chunk 26 of video 3\n",
      "Completed chunk 26 for video 3\n",
      "Processing chunk 27 of video 3\n",
      "Completed chunk 27 for video 3\n",
      "Processing chunk 28 of video 3\n",
      "Completed chunk 28 for video 3\n",
      "Processing chunk 29 of video 3\n",
      "Completed chunk 29 for video 3\n",
      "Processing chunk 30 of video 3\n",
      "Completed chunk 30 for video 3\n",
      "Processing chunk 31 of video 3\n",
      "Completed chunk 31 for video 3\n",
      "Processing chunk 32 of video 3\n",
      "Completed chunk 32 for video 3\n",
      "Processing chunk 33 of video 3\n",
      "Completed chunk 33 for video 3\n",
      "Processing chunk 34 of video 3\n",
      "Completed chunk 34 for video 3\n",
      "Processing chunk 35 of video 3\n",
      "Completed chunk 35 for video 3\n",
      "Processing chunk 36 of video 3\n",
      "Completed chunk 36 for video 3\n",
      "Processing chunk 37 of video 3\n",
      "Completed chunk 37 for video 3\n",
      "Processing video 4/4: https://www.youtube.com/watch?v=hQGtKBQc_iE\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=hQGtKBQc_iE\n",
      "[youtube] hQGtKBQc_iE: Downloading webpage\n",
      "[youtube] hQGtKBQc_iE: Downloading ios player API JSON\n",
      "[youtube] hQGtKBQc_iE: Downloading mweb player API JSON\n",
      "[youtube] hQGtKBQc_iE: Downloading m3u8 information\n",
      "[info] hQGtKBQc_iE: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_3\n",
      "[download] 100% of   60.94MiB in 00:00:03 at 18.03MiB/s    \n",
      "[ExtractAudio] Destination: audio_3.mp3\n",
      "Deleting original file audio_3 (pass -k to keep)\n",
      "Processing chunk 1 of video 4\n",
      "Completed chunk 1 for video 4\n",
      "Processing chunk 2 of video 4\n",
      "Completed chunk 2 for video 4\n",
      "Processing chunk 3 of video 4\n",
      "Completed chunk 3 for video 4\n",
      "Processing chunk 4 of video 4\n",
      "Completed chunk 4 for video 4\n",
      "Processing chunk 5 of video 4\n",
      "Completed chunk 5 for video 4\n",
      "Processing chunk 6 of video 4\n",
      "Completed chunk 6 for video 4\n",
      "Processing chunk 7 of video 4\n",
      "Completed chunk 7 for video 4\n",
      "Processing chunk 8 of video 4\n",
      "Completed chunk 8 for video 4\n",
      "Processing chunk 9 of video 4\n",
      "Completed chunk 9 for video 4\n",
      "Processing chunk 10 of video 4\n",
      "Completed chunk 10 for video 4\n",
      "Processing chunk 11 of video 4\n",
      "Completed chunk 11 for video 4\n",
      "Processing chunk 12 of video 4\n",
      "Completed chunk 12 for video 4\n",
      "Processing chunk 13 of video 4\n",
      "Completed chunk 13 for video 4\n",
      "Processing chunk 14 of video 4\n",
      "Completed chunk 14 for video 4\n",
      "Processing chunk 15 of video 4\n",
      "Completed chunk 15 for video 4\n",
      "Processing chunk 16 of video 4\n",
      "Completed chunk 16 for video 4\n",
      "Processing chunk 17 of video 4\n",
      "Completed chunk 17 for video 4\n",
      "Processing chunk 18 of video 4\n",
      "Completed chunk 18 for video 4\n",
      "Processing chunk 19 of video 4\n",
      "Completed chunk 19 for video 4\n",
      "Processing chunk 20 of video 4\n",
      "Completed chunk 20 for video 4\n",
      "Processing chunk 21 of video 4\n",
      "Completed chunk 21 for video 4\n",
      "Processing chunk 22 of video 4\n",
      "Completed chunk 22 for video 4\n",
      "Processing chunk 23 of video 4\n",
      "Completed chunk 23 for video 4\n",
      "Processing chunk 24 of video 4\n",
      "Completed chunk 24 for video 4\n",
      "Processing chunk 25 of video 4\n",
      "Completed chunk 25 for video 4\n",
      "Processing chunk 26 of video 4\n",
      "Completed chunk 26 for video 4\n",
      "Processing chunk 27 of video 4\n",
      "Completed chunk 27 for video 4\n",
      "Processing chunk 28 of video 4\n",
      "Completed chunk 28 for video 4\n",
      "Processing chunk 29 of video 4\n",
      "Completed chunk 29 for video 4\n",
      "Processing chunk 30 of video 4\n",
      "Completed chunk 30 for video 4\n",
      "Processing chunk 31 of video 4\n",
      "Completed chunk 31 for video 4\n",
      "Processing chunk 32 of video 4\n",
      "Completed chunk 32 for video 4\n",
      "Processing chunk 33 of video 4\n",
      "Completed chunk 33 for video 4\n",
      "Processing chunk 34 of video 4\n",
      "Completed chunk 34 for video 4\n",
      "Processing chunk 35 of video 4\n",
      "Completed chunk 35 for video 4\n",
      "Processing chunk 36 of video 4\n",
      "Completed chunk 36 for video 4\n",
      "Processing chunk 37 of video 4\n",
      "Completed chunk 37 for video 4\n",
      "Processing chunk 38 of video 4\n",
      "Completed chunk 38 for video 4\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/3036245762.py:123: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = react_agent({\"input\": user_query, \"transcriptions\": transcriptions})  # Send entire list to agent once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI should transcribe all the earnings podcasts from the YouTube links provided to consolidate the results.\n",
      "Action: TranscribeAllVideos\n",
      "Action Input: List of YouTube links to earnings podcasts\u001b[0mProcessing video 1/4: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=089JqnNmJq0\n",
      "[youtube] 089JqnNmJq0: Downloading webpage\n",
      "[youtube] 089JqnNmJq0: Downloading ios player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading mweb player API JSON\n",
      "[youtube] 089JqnNmJq0: Downloading m3u8 information\n",
      "[info] 089JqnNmJq0: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_0\n",
      "[download] 100% of   49.02MiB in 00:00:01 at 43.23MiB/s    \n",
      "[ExtractAudio] Destination: audio_0.mp3\n",
      "Deleting original file audio_0 (pass -k to keep)\n",
      "Processing chunk 1 of video 1\n",
      "Completed chunk 1 for video 1\n",
      "Processing chunk 2 of video 1\n",
      "Completed chunk 2 for video 1\n",
      "Processing chunk 3 of video 1\n",
      "Completed chunk 3 for video 1\n",
      "Processing chunk 4 of video 1\n",
      "Completed chunk 4 for video 1\n",
      "Processing chunk 5 of video 1\n",
      "Completed chunk 5 for video 1\n",
      "Processing chunk 6 of video 1\n",
      "Completed chunk 6 for video 1\n",
      "Processing chunk 7 of video 1\n",
      "Completed chunk 7 for video 1\n",
      "Processing chunk 8 of video 1\n",
      "Completed chunk 8 for video 1\n",
      "Processing chunk 9 of video 1\n",
      "Completed chunk 9 for video 1\n",
      "Processing chunk 10 of video 1\n",
      "Completed chunk 10 for video 1\n",
      "Processing chunk 11 of video 1\n",
      "Completed chunk 11 for video 1\n",
      "Processing chunk 12 of video 1\n",
      "Completed chunk 12 for video 1\n",
      "Processing chunk 13 of video 1\n",
      "Completed chunk 13 for video 1\n",
      "Processing chunk 14 of video 1\n",
      "Completed chunk 14 for video 1\n",
      "Processing chunk 15 of video 1\n",
      "Completed chunk 15 for video 1\n",
      "Processing chunk 16 of video 1\n",
      "Completed chunk 16 for video 1\n",
      "Processing chunk 17 of video 1\n",
      "Completed chunk 17 for video 1\n",
      "Processing chunk 18 of video 1\n",
      "Completed chunk 18 for video 1\n",
      "Processing chunk 19 of video 1\n",
      "Completed chunk 19 for video 1\n",
      "Processing chunk 20 of video 1\n",
      "Completed chunk 20 for video 1\n",
      "Processing chunk 21 of video 1\n",
      "Completed chunk 21 for video 1\n",
      "Processing chunk 22 of video 1\n",
      "Completed chunk 22 for video 1\n",
      "Processing chunk 23 of video 1\n",
      "Completed chunk 23 for video 1\n",
      "Processing chunk 24 of video 1\n",
      "Completed chunk 24 for video 1\n",
      "Processing chunk 25 of video 1\n",
      "Completed chunk 25 for video 1\n",
      "Processing chunk 26 of video 1\n",
      "Completed chunk 26 for video 1\n",
      "Processing chunk 27 of video 1\n",
      "Completed chunk 27 for video 1\n",
      "Processing chunk 28 of video 1\n",
      "Completed chunk 28 for video 1\n",
      "Processing chunk 29 of video 1\n",
      "Completed chunk 29 for video 1\n",
      "Processing chunk 30 of video 1\n",
      "Completed chunk 30 for video 1\n",
      "Processing chunk 31 of video 1\n",
      "Completed chunk 31 for video 1\n",
      "Processing chunk 32 of video 1\n",
      "Completed chunk 32 for video 1\n",
      "Processing chunk 33 of video 1\n",
      "Completed chunk 33 for video 1\n",
      "Processing chunk 34 of video 1\n",
      "Completed chunk 34 for video 1\n",
      "Processing chunk 35 of video 1\n",
      "Completed chunk 35 for video 1\n",
      "Processing chunk 36 of video 1\n",
      "Completed chunk 36 for video 1\n",
      "Processing chunk 37 of video 1\n",
      "Completed chunk 37 for video 1\n",
      "Processing chunk 38 of video 1\n",
      "Completed chunk 38 for video 1\n",
      "Processing video 2/4: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=IskUO7MoV2s\n",
      "[youtube] IskUO7MoV2s: Downloading webpage\n",
      "[youtube] IskUO7MoV2s: Downloading ios player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading mweb player API JSON\n",
      "[youtube] IskUO7MoV2s: Downloading m3u8 information\n",
      "[info] IskUO7MoV2s: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_1\n",
      "[download] 100% of   48.50MiB in 00:00:02 at 17.96MiB/s    \n",
      "[ExtractAudio] Destination: audio_1.mp3\n",
      "Deleting original file audio_1 (pass -k to keep)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 132\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m\"\"\" def perform_transcription_task():\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    user_query = \"Transcribe all earnings podcasts from the provided YouTube links.\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    response = react_agent({\"input\": user_query})\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    print(\"Agent's Transcription:\", response[\"output\"]) \"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Start the transcription task\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[43mperform_transcription_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 123\u001b[0m, in \u001b[0;36mperform_transcription_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribe all earnings podcasts from the provided YouTube links.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m transcriptions \u001b[38;5;241m=\u001b[39m transcribe_all_videos()  \u001b[38;5;66;03m# Get transcriptions directly\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mreact_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranscriptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscriptions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Send entire list to agent once\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Transcription:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1639\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1420\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py:1442\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1450\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py:689\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    688\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    690\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    691\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py:657\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[1;32m    656\u001b[0m     tool_kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 657\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/simple.py:92\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     91\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mtranscribe_all_videos\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(video_links)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m download_audio(video_url, AUDIO_OUTPUT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m---> 70\u001b[0m full_transcription \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_whisper\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m transcription_chunks \u001b[38;5;241m=\u001b[39m chunk_text(full_transcription)  \u001b[38;5;66;03m# Divide transcription\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transcription_chunks):\n",
      "Cell \u001b[0;32mIn[7], line 44\u001b[0m, in \u001b[0;36mtranscribe_audio_with_whisper\u001b[0;34m(audio_path, model_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_with_whisper\u001b[39m(audio_path, model_name\u001b[38;5;241m=\u001b[39mWHISPER_MODEL):\n\u001b[1;32m     43\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model(model_name)\n\u001b[0;32m---> 44\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:279\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    276\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    278\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 279\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:195\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    192\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    194\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m--> 195\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    199\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    201\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:242\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    239\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 242\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    245\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    246\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:169\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    167\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_ln(x), mask\u001b[38;5;241m=\u001b[39mmask, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m--> 169\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    170\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_ln(x))\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:112\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    109\u001b[0m     v \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue]\n\u001b[1;32m    111\u001b[0m wv, qk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv_attention(q, k, v, mask)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwv\u001b[49m\u001b[43m)\u001b[49m, qk\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py:45\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLinear\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mLinear):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\n\u001b[1;32m     47\u001b[0m             x,\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     50\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# New Code 11PM SATURDAY # THIS CODE worked using ReAct agent for Transcription, but went in Infinite LOOOOP\n",
    "\n",
    "\"\"\" import os\n",
    "import yt_dlp\n",
    "from whisper import load_model\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# Default configurations\n",
    "VIDEO_LINKS_FILE = \"video_links.txt\"  # File with YouTube links\n",
    "AUDIO_OUTPUT_TEMPLATE = \"audio_{}\"  # Template for audio file names without .mp3 extension\n",
    "WHISPER_MODEL = \"base\"  # Whisper model for transcription\n",
    "\n",
    "# Load YouTube links from the file\n",
    "def load_video_links(filename=VIDEO_LINKS_FILE):\n",
    "    with open(filename, 'r') as file:\n",
    "        video_links = [link.strip() for link in file.readlines() if link.strip()]\n",
    "    return video_links\n",
    "\n",
    "# Download audio from YouTube video\n",
    "def download_audio(url, output_name):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [\n",
    "            {\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }\n",
    "        ],\n",
    "        'outtmpl': output_name,  # Filename with .mp3 extension\n",
    "        'ffmpeg_location': '/usr/bin/ffmpeg'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return f\"{output_name}.mp3\"\n",
    "\n",
    "# Transcribe audio using Whisper\n",
    "def transcribe_audio_with_whisper(audio_path, model_name=WHISPER_MODEL):\n",
    "    model = load_model(model_name)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# ReAct Tool for downloading and transcribing all videos\n",
    "# Split transcriptions into chunks below the token limit - Process in Batches!\n",
    "def chunk_text(text, max_length=1500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "    for word in words:\n",
    "        chunk.append(word)\n",
    "        if len(\" \".join(chunk)) >= max_length:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = []\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks\n",
    "\n",
    "# Process each transcription in chunks\n",
    "def transcribe_all_videos(input_data=None): # Accept an optional argument\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "    all_transcriptions = []\n",
    "    \n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        full_transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        transcription_chunks = chunk_text(full_transcription)  # Divide transcription\n",
    "        \n",
    "        for j, chunk in enumerate(transcription_chunks):\n",
    "            # print(f\"Processing chunk {j+1} of video {i+1}\")\n",
    "            # Send chunk to the ReAct agent\n",
    "            # response = react_agent({\"input\": chunk}) /* Don't call Agent each time */\n",
    "            all_transcriptions.append({\"title\": f\"Video {i+1} - Chunk {j+1}\", \"transcription\": chunk})\n",
    "            print(f\"Completed chunk {j+1} for video {i+1}\")\n",
    "        \n",
    "    return all_transcriptions\n",
    "\n",
    "\n",
    "def transcribe_all_videos(input_data=None):  # Accept an optional argument\n",
    "    video_links = load_video_links(VIDEO_LINKS_FILE)\n",
    "    all_transcriptions = []\n",
    "    for i, video_url in enumerate(video_links):\n",
    "        print(f\"Processing video {i+1}/{len(video_links)}: {video_url}\")\n",
    "        audio_path = download_audio(video_url, AUDIO_OUTPUT_TEMPLATE.format(i))\n",
    "        transcription = transcribe_audio_with_whisper(audio_path)\n",
    "        all_transcriptions.append({\"title\": f\"Video {i+1}\", \"transcription\": transcription})\n",
    "        print(f\"Completed transcription for video {i+1}\")\n",
    "    return all_transcriptions\n",
    "\n",
    "# Define structured output for better organization\n",
    "response_schema = [\n",
    "    ResponseSchema(name=\"transcription\", description=\"Transcribed text from each video in structured format.\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "# Define tool for the agent\n",
    "transcription_tool = Tool(\n",
    "    name=\"TranscribeAllVideos\",\n",
    "    func=transcribe_all_videos,\n",
    "    description=\"Transcribes all videos in the provided list and consolidates results.\"\n",
    ")\n",
    "\n",
    "# Initialize the ReAct agent with transcription tool\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=[transcription_tool],\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run agent to perform transcription\n",
    "def perform_transcription_task():\n",
    "    user_query = \"Transcribe all earnings podcasts from the provided YouTube links.\"\n",
    "    transcriptions = transcribe_all_videos()  # Get transcriptions directly\n",
    "    response = react_agent({\"input\": user_query, \"transcriptions\": transcriptions})  # Send entire list to agent once\n",
    "    print(\"Agent's Transcription:\", response[\"output\"])\n",
    "\n",
    "def perform_transcription_task():\n",
    "    user_query = \"Transcribe all earnings podcasts from the provided YouTube links.\"\n",
    "    response = react_agent({\"input\": user_query})\n",
    "    print(\"Agent's Transcription:\", response[\"output\"])\n",
    "\n",
    "# Start the transcription task\n",
    "perform_transcription_task()\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
