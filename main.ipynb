{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from sentence_transformers import SentenceTransformer # Import SentenceTransformer\n",
    "import pinecone\n",
    "import time\n",
    "import os # Import os module for environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve Pinecone API key from environment\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize Pinecone with the hardcoded API key\n",
    "pc = pinecone.Pinecone(api_key=api_key)\n",
    "\n",
    "# Define index parameters\n",
    "index_name = \"youtube-index\"\n",
    "dimension = 768\n",
    "metric = \"cosine\"\n",
    "\n",
    "# Create Pinecone index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=metric,\n",
    "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(f\"Created Pinecone index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Pinecone index '{index_name}' already exists\")\n",
    "\n",
    "# Wait for the Pinecone index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Successfully connected to Pinecone index: {index_name}\")\n",
    "\n",
    "# Initialize the SentenceTransformer model # Define and initialize the model\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Load metadata from JSON file\n",
    "with open(\"videos_metadata.json\", \"r\") as f:\n",
    "    video_metadata = json.load(f)\n",
    "\n",
    "\n",
    "# Convert metadata into a dictionary indexed by video_id for easy lookup\n",
    "video_metadata_dict = {\n",
    "    item['videoId']: {\n",
    "        **item,\n",
    "        \"video_id\": item['videoId'],\n",
    "        \"video_title\": item.get('title', 'Unknown Title'),  # Adding video_title\n",
    "        \"publishedAt\": item.get('publishedAt', 'Unknown Date'),  # Adding publishedAt if available\n",
    "        \"thumbnail\": item.get('thumbnail', 'No Thumbnail Available')  # Adding thumbnail if available\n",
    "    }\n",
    "    for item in video_metadata\n",
    "}\n",
    "\n",
    "def get_video_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        transcript_text = \" \".join([item['text'] for item in transcript if 'text' in item])\n",
    "        return transcript_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving transcript for video {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def chunk_and_embed_text(text, chunk_size=50):\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    embeddings = model.encode(chunks)\n",
    "    return chunks, embeddings\n",
    "\n",
    "def upsert_to_pinecone(video_id, metadata, chunks, embeddings):\n",
    "    batch_size = 50\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        chunk_ids = [f\"{video_id}-{j}\" for j in range(i, min(i + batch_size, len(chunks)))]\n",
    "        \n",
    "        # Metadata including chunk text and video metadata\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"video_id\": video_id,\n",
    "                \"video_title\": metadata.get(\"title\", f\"Title for {video_id}\"),\n",
    "                \"published_at\": metadata.get(\"publishedAt\"),\n",
    "                \"thumbnail\": metadata.get(\"thumbnail\"),\n",
    "                \"text\": chunks[k]\n",
    "            }\n",
    "            for k in range(i, min(i + batch_size, len(chunks)))\n",
    "        ]\n",
    "\n",
    "        vectors_with_metadata = []\n",
    "        for j in range(len(chunk_ids)):\n",
    "            vector = {\n",
    "                \"id\": chunk_ids[j],\n",
    "                \"values\": embeddings[i + j].tolist(),\n",
    "                \"metadata\": metadata_list[j]\n",
    "            }\n",
    "            vectors_with_metadata.append(vector)\n",
    "\n",
    "        index.upsert(vectors=vectors_with_metadata)\n",
    "\n",
    "def process_video(video_id):\n",
    "    print(f\"Processing video: {video_id}\")\n",
    "    transcript_text = get_video_transcript(video_id)\n",
    "    if transcript_text:\n",
    "        print(f\"Transcript for video {video_id}:\")\n",
    "        print(transcript_text)\n",
    "        chunks, embeddings = chunk_and_embed_text(transcript_text)\n",
    "        \n",
    "        # Get the metadata for the video\n",
    "        metadata = video_metadata_dict.get(video_id, {})\n",
    "        \n",
    "        # Upsert data to Pinecone\n",
    "        upsert_to_pinecone(video_id, metadata, chunks, embeddings)\n",
    "\n",
    "# Process all videos\n",
    "video_ids = [\n",
    "    'gvck7ssg9dE',\n",
    "    'djzKCZHeVjY',\n",
    "    'puXKFn-nKis',\n",
    "    'pvRY3r-b0QI',\n",
    "    'SUMLKweFAYk',\n",
    "    'UOuxo6SA8Uc',\n",
    "]\n",
    "\n",
    "for video_id in video_ids:\n",
    "    process_video(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# Import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# Import PromptTemplate from langchain.prompts\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Import LLMChain\n",
    "from langchain.chains import LLMChain\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "# Import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Import tiktoken for token counting\n",
    "import tiktoken\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "#import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "import pinecone\n",
    "\n",
    "# 'index' is already defined from the previous code\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize HuggingFace embeddings with the same model used to create the index\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# Use the HuggingFaceEmbeddings for the Pinecone vectorstore\n",
    "vectorstore = Pinecone(index, embeddings.embed_query, \"text\")\n",
    "\n",
    "# Initialize language model and QA chain\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "# Define a prompt template for summarizing the video transcript\n",
    "summary_template = \"\"\"\n",
    "Please provide a concise summary of the following YouTube video transcript:\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"transcript\"],\n",
    "    template=summary_template\n",
    ")\n",
    "\n",
    "# Define a prompt template for answering questions about the video\n",
    "qa_template = \"\"\"\n",
    "Use the following summary to answer the question about the YouTube video:\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"question\"],\n",
    "    template=qa_template\n",
    ")\n",
    "\n",
    "def get_video_summary(video_id):\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    transcript_text = \" \".join([item['text'] for item in transcript if 'text' in item])\n",
    "\n",
    "    # Initialize RecursiveCharacterTextSplitter with a suitable chunk size and overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,  # Adjust chunk size as needed\n",
    "        chunk_overlap=100  # Adjust overlap as needed\n",
    "    )\n",
    "\n",
    "    # Split the transcript into smaller chunks\n",
    "    chunks = text_splitter.split_text(transcript_text)\n",
    "\n",
    "    # Generate summaries for each chunk and combine them\n",
    "    summary = \"\"\n",
    "    for chunk in chunks:\n",
    "        # Generate summary using LLMChain\n",
    "        summary_chain = LLMChain(llm=llm, prompt=SUMMARY_PROMPT)\n",
    "        chunk_summary = summary_chain.run(transcript=chunk)\n",
    "        summary += chunk_summary + \" \"  # Combine summaries with a space\n",
    "\n",
    "    return summary\n",
    "\n",
    "def ask_question(question, video_id, show_context=False):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    max_context_tokens = 10000\n",
    "\n",
    "    # 1. Get the summary for the given video_id\n",
    "    summary = get_video_summary(video_id)\n",
    "\n",
    "    # 2. Build a retriever\n",
    "    retriever = RunnableLambda(vectorstore.similarity_search).bind(k=3)\n",
    "\n",
    "    # 3. Invoke the retriever to fetch documents before using them\n",
    "    docs = retriever.invoke(question) # Invoke to get the documents\n",
    "\n",
    "    # 4. Concatenate the retrieved documents to form the context\n",
    "    context = \"\"\n",
    "    total_tokens = 0\n",
    "    for doc in docs:\n",
    "        doc_tokens = len(tokenizer.encode(doc.page_content))\n",
    "        if total_tokens + doc_tokens <= max_context_tokens:\n",
    "            context += doc.page_content + \" \"\n",
    "            total_tokens += doc_tokens\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 5. Format the context to be included in the prompt\n",
    "    formatted_context = f\"Context: {context}\"  # Add \"Context:\" for clarity\n",
    "\n",
    "    # 6. Create a QA chain using the retrieved context, summary, and question\n",
    "    # Modified: Directly pass summary and question to QA_PROMPT\n",
    "    qa_chain = QA_PROMPT | llm\n",
    "\n",
    "    # 6. Create a QA chain using the retrieved context, summary, and question\n",
    "    # Note: the 'context' key in the rag_chain should be 'retriever', not the actual docs\n",
    "    # rag_chain={}\n",
    "    # Modified to pass 'question' as input and summary and retriever in the prompt\n",
    "    #rag_chain={\"context\": retriever,\"summary\": RunnablePassthrough()} | QA_PROMPT | llm\n",
    "    #rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | QA_PROMPT | llm\n",
    "    #rag_chain = {\"question\": RunnablePassthrough()} | QA_PROMPT.bind(question=question, context=retriever) | llm\n",
    "    #rag_chain = {\"question\": RunnablePassthrough()} | QA_PROMPT.bind(summary=summary, context=retriever) | llm\n",
    "\n",
    "    # 7. Pass the summary, question to the chain and access the content\n",
    "    answer = qa_chain.invoke({\"summary\": summary, \"question\": question})\n",
    "\n",
    "    # Return only the content of the answer\n",
    "    return answer.content  # Access the content attribut\n",
    "\n",
    "    # 8. Optionally display the relevant context\n",
    "    if show_context:\n",
    "        print(\"Relevant Context:\")\n",
    "        print(context)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Interactive loop for asking questions\n",
    "while True:\n",
    "    question = input(\"Enter your question (or 'q' to quit): \")\n",
    "    if question.lower() == 'q':\n",
    "        print(\"Exiting the program. Goodbye!\")\n",
    "        break\n",
    "    elif not question.strip():\n",
    "        print(\"Please enter a valid question.\")\n",
    "        continue\n",
    "\n",
    "    video_id = input(\"Enter the YouTube video ID (or 'q' to quit): \")\n",
    "    if video_id.lower() == 'q':\n",
    "        print(\"Exiting the program. Goodbye!\")\n",
    "        break\n",
    "    elif not video_id.strip():\n",
    "        print(\"Please enter a valid YouTube video ID.\")\n",
    "        continue\n",
    "\n",
    "    answer = ask_question(question, video_id)\n",
    "    print(answer)\n",
    "\n",
    "# Video IDs for the dropdown\n",
    "video_ids = [\n",
    "    'gvck7ssg9dE',\n",
    "    'djzKCZHeVjY',\n",
    "    'puXKFn-nKis',\n",
    "    'pvRY3r-b0QI',\n",
    "    'SUMLKweFAYk',\n",
    "    'UOuxo6SA8Uc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "import base64\n",
    "import socket\n",
    "\n",
    "\n",
    "# Load video metadata\n",
    "json_file_path = 'videos_metadata.json'  # Replace with the actual path\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    video_metadata = json.load(json_file)\n",
    "\n",
    "# Extract video IDs and titles for the dropdown\n",
    "video_choices = {video_data[\"title\"]: video_data[\"videoId\"] for video_data in video_metadata}\n",
    "\n",
    "# Define the Gradio interface with event listeners\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"## ClipVerse YT, just do IT !?\")\n",
    "\n",
    "    # Dropdown for video selection (no initial value)\n",
    "    video_dropdown = gr.Dropdown(\n",
    "        choices=list(video_choices.keys()),\n",
    "        label=\"Pick Your Adventure\",\n",
    "        value=None  # Start with no selection\n",
    "    )\n",
    "\n",
    "    # Components to display metadata (initially hidden)\n",
    "    with gr.Row(visible=False) as metadata_row:\n",
    "        title_textbox = gr.Textbox(label=\"Title\")\n",
    "        thumbnail_image = gr.Image(label=\"Thumbnail\")  # Specify type as \"url\"\n",
    "        published_at_textbox = gr.Textbox(label=\"Published At\")\n",
    "\n",
    "    # Question textbox\n",
    "    question_textbox = gr.Textbox(lines=2, placeholder=\"Enter your question here...\", label=\"Dare to Discover?\")\n",
    "\n",
    "    # Answer textbox\n",
    "    answer_textbox = gr.Textbox(label=\"Take a Leap!\")\n",
    "\n",
    "    # Button to ask questions with custom CSS\n",
    "    ask_button = gr.Button(\"Show me the Magic\", variant=\"primary\") # Use variant for styling\n",
    "\n",
    "    # Restart button with custom CSS\n",
    "    restart_button = gr.Button(\"Give more Magic\", variant=\"secondary\") # Use variant for styling\n",
    "\n",
    "    # Function to update metadata and make them visible\n",
    "    def update_metadata_fields(selected_title):\n",
    "        selected_video_id = video_choices.get(selected_title)\n",
    "        if selected_video_id:\n",
    "            selected_video_data = next(\n",
    "                (item for item in video_metadata if item[\"videoId\"] == selected_video_id),\n",
    "                None\n",
    "            )\n",
    "            if selected_video_data:\n",
    "                # Load image from URL and encode as base64\n",
    "                image_url = selected_video_data.get(\"thumbnail\")\n",
    "                if image_url:\n",
    "                    print(f\"Fetching thumbnail from: {image_url}\")\n",
    "                    try:\n",
    "                        # If it's a local file path, use open() instead of requests.get()\n",
    "                        if os.path.isfile(image_url):\n",
    "                            with open(image_url, \"rb\") as image_file:\n",
    "                                image_content = image_file.read()\n",
    "                        else:  # If it's a URL, use requests.get()\n",
    "                            response = requests.get(image_url, stream=True)\n",
    "                            response.raise_for_status()\n",
    "                            image_content = response.content\n",
    "\n",
    "                        # Use PIL to load and resize the image\n",
    "                        image = PILImage.open(io.BytesIO(image_content))\n",
    "                        # Calculate new dimensions while preserving aspect ratio\n",
    "                        width, height = image.size\n",
    "                        target_size = (200, 200)  # Desired size\n",
    "\n",
    "                        if width > height:\n",
    "                            new_width = target_size[0]\n",
    "                            new_height = int(height * (target_size[0] / width))\n",
    "                        else:\n",
    "                            new_height = target_size[1]\n",
    "                            new_width = int(width * (target_size[1] / height))\n",
    "\n",
    "                        # Resize using LANCZOS for better quality\n",
    "                        image = image.resize((new_width, new_height), PILImage.LANCZOS)\n",
    "\n",
    "                        # Update: Directly return the PIL Image object\n",
    "                        return {\n",
    "                            metadata_row: gr.update(visible=True),\n",
    "                            title_textbox: gr.update(value=selected_video_data[\"title\"]),\n",
    "                            thumbnail_image: gr.update(value=image),  # Return PIL Image\n",
    "                            published_at_textbox: gr.update(value=selected_video_data[\"publishedAt\"]),\n",
    "                        }\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading thumbnail: {e}\")\n",
    "                        # Handle the case where image loading fails (e.g., invalid URL)\n",
    "                        return {\n",
    "                            metadata_row: gr.update(visible=True),  # Still show metadata\n",
    "                            title_textbox: gr.update(value=selected_video_data[\"title\"]),\n",
    "                            thumbnail_image: gr.update(value=None),  # Set thumbnail to None\n",
    "                            published_at_textbox: gr.update(value=selected_video_data[\"publishedAt\"]),\n",
    "                        }\n",
    "                else:\n",
    "                    print(f\"Thumbnail URL not found for video ID: {selected_video_id}\")\n",
    "            else:\n",
    "                print(f\"Video data not found for video ID: {selected_video_id}\")\n",
    "        return {\n",
    "            metadata_row: gr.update(visible=False),\n",
    "            title_textbox: gr.update(value=\"\"),\n",
    "            thumbnail_image: gr.update(value=None),\n",
    "            published_at_textbox: gr.update(value=\"\"),\n",
    "        }\n",
    "\n",
    "\n",
    "    # Event listener for video dropdown change\n",
    "    video_dropdown.change(\n",
    "        fn=update_metadata_fields,\n",
    "        inputs=video_dropdown,\n",
    "        outputs=[metadata_row, title_textbox, thumbnail_image, published_at_textbox],\n",
    "    )\n",
    "\n",
    "    # Function to handle question asking\n",
    "    def ask_question_gradio(question, selected_title):\n",
    "        video_id = video_choices.get(selected_title)\n",
    "        if not video_id:\n",
    "            return \"Please select a video first.\"\n",
    "        try:\n",
    "            answer = ask_question(question, video_id)  # Assuming 'ask_question' is defined elsewhere\n",
    "        except Exception as e:\n",
    "            return f\"Error: Could not answer the question. {e}\"\n",
    "        return answer\n",
    "\n",
    "    # Event trigger for the ask button\n",
    "    ask_button.click(\n",
    "        fn=ask_question_gradio,\n",
    "        inputs=[question_textbox, video_dropdown],\n",
    "        outputs=answer_textbox,\n",
    "    )\n",
    "\n",
    "    # Function to reset the interface\n",
    "    def restart_interface():\n",
    "        return {\n",
    "            video_dropdown: gr.update(value=None),\n",
    "            metadata_row: gr.update(visible=False),\n",
    "            title_textbox: gr.update(value=\"\"),\n",
    "            thumbnail_image: gr.update(value=None),\n",
    "            published_at_textbox: gr.update(value=\"\"),\n",
    "            question_textbox: gr.update(value=\"\"),\n",
    "            answer_textbox: gr.update(value=\"\"),\n",
    "        }\n",
    "\n",
    "    # Event listener for video dropdown change\n",
    "    video_dropdown.change(\n",
    "        fn=update_metadata_fields,\n",
    "        inputs=video_dropdown,\n",
    "        outputs=[metadata_row, title_textbox, thumbnail_image, published_at_textbox],\n",
    "    )\n",
    "\n",
    "    # Event trigger for the ask button\n",
    "    ask_button.click(\n",
    "        fn=lambda question, selected_title: ask_question_gradio(\n",
    "            question, video_choices.get(selected_title)\n",
    "        ),\n",
    "        inputs=[question_textbox, video_dropdown],\n",
    "        outputs=answer_textbox,\n",
    "    )\n",
    "\n",
    "    # Function to reset the interface\n",
    "    def restart_interface():\n",
    "        return {\n",
    "            video_dropdown: gr.update(value=None),\n",
    "            metadata_row: gr.update(visible=False),\n",
    "            title_textbox: gr.update(value=\"\"),\n",
    "            thumbnail_image: gr.update(value=None),\n",
    "            published_at_textbox: gr.update(value=\"\"),\n",
    "            question_textbox: gr.update(value=\"\"),\n",
    "            answer_textbox: gr.update(value=\"\"),\n",
    "        }\n",
    "\n",
    "    # Insert ask_question_gradio here\n",
    "    def ask_question_gradio(question, video_id):\n",
    "        # 1. Check if video_id is valid\n",
    "        if not video_id:\n",
    "            return \"Please select a video first.\"\n",
    "\n",
    "        # 2. Call your existing ask_question function\n",
    "        try:\n",
    "            answer = ask_question(question, video_id)\n",
    "        except Exception as e:\n",
    "            return f\"Error: Could not answer the question. {e}\"\n",
    "\n",
    "        return answer\n",
    "\n",
    "\n",
    "    # Event trigger for the restart button\n",
    "    restart_button.click(\n",
    "        fn=restart_interface,\n",
    "        outputs=[\n",
    "            video_dropdown,\n",
    "            metadata_row,\n",
    "            title_textbox,\n",
    "            thumbnail_image,\n",
    "            published_at_textbox,\n",
    "            question_textbox,\n",
    "            answer_textbox,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True, server_port=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
